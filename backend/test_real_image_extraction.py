#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
Real Image Text Extraction Test
"""

import os
import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime
import base64

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    import pytesseract
    from PIL import Image
    HAS_OCR = True
    print("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…ÙƒØªØ¨Ø§Øª OCR Ø¨Ù†Ø¬Ø§Ø­")
except ImportError:
    HAS_OCR = False
    print("âš ï¸ Ù…ÙƒØªØ¨Ø§Øª OCR ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")

from app.services.gemini_service import GeminiService

async def extract_text_with_ocr(image_path: str) -> dict:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR"""
    if not HAS_OCR:
        return {
            "success": False,
            "error": "Ù…ÙƒØªØ¨Ø§Øª OCR ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© - pip install pytesseract pillow",
            "text": "",
            "confidence": 0
        }
    
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(image_path)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract
        # ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
        try:
            text_ar = pytesseract.image_to_string(image, lang='ara')
            if text_ar.strip():
                confidence = 0.8
                extracted_text = text_ar
                language = "Arabic"
            else:
                raise Exception("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ø¹Ø±Ø¨ÙŠ")
        except:
            # ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙƒØ¨Ø¯ÙŠÙ„
            try:
                text_en = pytesseract.image_to_string(image, lang='eng')
                extracted_text = text_en
                confidence = 0.7
                language = "English"
            except:
                # ØªØ¬Ø±Ø¨Ø© Ø¨Ø¯ÙˆÙ† ØªØ­Ø¯ÙŠØ¯ Ù„ØºØ©
                extracted_text = pytesseract.image_to_string(image)
                confidence = 0.6
                language = "Auto"
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
        cleaned_text = extracted_text.strip()
        
        return {
            "success": True,
            "text": cleaned_text,
            "confidence": confidence,
            "language": language,
            "character_count": len(cleaned_text),
            "word_count": len(cleaned_text.split()),
            "lines": cleaned_text.split('\n')
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "text": "",
            "confidence": 0
        }

async def analyze_image_content(image_path: str) -> dict:
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙˆØ±Ø© Ø¨ØµØ±ÙŠØ§Ù‹"""
    try:
        image = Image.open(image_path)
        
        return {
            "width": image.width,
            "height": image.height,
            "mode": image.mode,
            "format": image.format,
            "size_bytes": os.path.getsize(image_path),
            "aspect_ratio": round(image.width / image.height, 2)
        }
    except Exception as e:
        return {"error": str(e)}

async def test_real_image_extraction():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©"""
    
    # Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
    image_path = Path("../103.jpg")
    if not image_path.exists():
        print(f"âŒ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image_path.absolute()}")
        return False
    
    print(f"ğŸ–¼ï¸ Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©: {image_path.absolute()}")
    
    try:
        # 1. ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØ±Ø©
        print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØ±Ø©...")
        image_info = await analyze_image_content(image_path)
        print(f"ğŸ“ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯: {image_info.get('width')}x{image_info.get('height')}")
        print(f"ğŸ“¦ Ø§Ù„Ø­Ø¬Ù…: {image_info.get('size_bytes', 0) / 1024 / 1024:.2f} MB")
        print(f"ğŸ¨ Ø§Ù„ØµÙŠØºØ©: {image_info.get('format')}")
        print(f"ğŸ“ Ù†Ø³Ø¨Ø© Ø§Ù„Ø¹Ø±Ø¶ Ù„Ù„Ø§Ø±ØªÙØ§Ø¹: {image_info.get('aspect_ratio')}")
        
        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR
        print("\nğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR...")
        start_time = datetime.now()
        
        ocr_result = await extract_text_with_ocr(str(image_path.absolute()))
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        if not ocr_result["success"]:
            print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {ocr_result['error']}")
            return False
        
        extracted_text = ocr_result["text"]
        print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù: {ocr_result['character_count']}")
        print(f"ğŸ“ Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {ocr_result['word_count']}")
        print(f"ğŸŒ Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {ocr_result['language']}")
        print(f"ğŸ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {ocr_result['confidence']:.2f}")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        print(f"\nğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
        print("=" * 50)
        print(extracted_text)
        print("=" * 50)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        ocr_result_file = "real_ocr_result.json"
        full_result = {
            "image_info": image_info,
            "ocr_result": ocr_result,
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat(),
            "source_file": "103.jpg"
        }
        
        with open(ocr_result_file, 'w', encoding='utf-8') as f:
            json.dump(full_result, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© OCR ÙÙŠ: {ocr_result_file}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Markdown Ù„Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        markdown_content = f"""# Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
- **Ø§Ù„Ù…Ù„Ù**: 103.jpg
- **Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯**: {image_info.get('width')}x{image_info.get('height')}
- **Ø§Ù„Ø­Ø¬Ù…**: {image_info.get('size_bytes', 0) / 1024 / 1024:.2f} MB
- **Ø§Ù„ØµÙŠØºØ©**: {image_info.get('format')}

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
- **Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬**: Tesseract OCR
- **Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©**: {ocr_result['language']}
- **Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©**: {ocr_result['confidence']:.2f}
- **ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©
- **Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù**: {ocr_result['character_count']}
- **Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª**: {ocr_result['word_count']}

## Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬

```
{extracted_text}
```

---
*ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© ÙÙŠ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        markdown_file = "real_extracted_text.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
        print(f"ğŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Øµ ÙÙŠ: {markdown_file}")
        
        # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªÙˆÙØ±Ø§Ù‹)
        if extracted_text.strip():
            print("\nğŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini...")
            try:
                gemini = GeminiService()
                
                analysis_prompt = f"""
                ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† ØµÙˆØ±Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©:
                
                Ø§Ù„Ù†Øµ:
                {extracted_text}
                
                ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ…:
                1. ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (ÙƒØªØ§Ø¨ Ù…Ø¯Ø±Ø³ÙŠØŒ Ù…Ù‚Ø§Ù„ØŒ Ø¥Ø¹Ù„Ø§Ù†ØŒ Ø¥Ù„Ø®)
                2. Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©
                3. Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
                4. Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©
                5. ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
                6. Ø£ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø£Ø®Ø±Ù‰
                
                ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
                """
                
                gemini_analysis = await gemini.analyze_text(extracted_text, analysis_prompt)
                
                print("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
                
                # Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Gemini
                gemini_result = {
                    "original_text": extracted_text,
                    "analysis": gemini_analysis,
                    "ocr_info": ocr_result,
                    "image_info": image_info,
                    "timestamp": datetime.now().isoformat()
                }
                
                gemini_file = "real_gemini_analysis.json"
                with open(gemini_file, 'w', encoding='utf-8') as f:
                    json.dump(gemini_result, f, ensure_ascii=False, indent=2)
                print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ ØªØ­Ù„ÙŠÙ„ Gemini ÙÙŠ: {gemini_file}")
                
                # ØªÙ‚Ø±ÙŠØ± ØªØ­Ù„ÙŠÙ„ Gemini
                analysis_report = f"""# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ - Gemini AI

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±
- **Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ**: 103.jpg (Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©)
- **Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬**: Tesseract OCR
- **ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
- **Ø§Ù„Ù„ØºØ© Ø§Ù„Ù…ÙƒØªØ´ÙØ©**: {ocr_result['language']}
- **Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©**: {ocr_result['confidence']:.2f}
- **Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù**: {ocr_result['character_count']}
- **Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª**: {ocr_result['word_count']}

## Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
```
{extracted_text}
```

## ØªØ­Ù„ÙŠÙ„ Gemini AI
{gemini_analysis}

---
*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ø­Ù‚ÙŠÙ‚ÙŠ*
"""
                
                analysis_file = "real_gemini_analysis.md"
                with open(analysis_file, 'w', encoding='utf-8') as f:
                    f.write(analysis_report)
                print(f"ğŸ“‹ ØªÙ… Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ: {analysis_file}")
                
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Gemini: {e}")
        
        # 4. Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print(f"\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
        print("ğŸ“‹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø©:")
        print(f"   - {ocr_result_file}")
        print(f"   - {markdown_file}")
        if 'gemini_file' in locals():
            print(f"   - {gemini_file}")
            print(f"   - {analysis_file}")
        
        print(f"\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print(f"   - OCR: âœ… Ø§Ø³ØªØ®Ø±Ø¬ {ocr_result['character_count']} Ø­Ø±Ù")
        print(f"   - Ø§Ù„Ù„ØºØ©: {ocr_result['language']}")
        print(f"   - Ø§Ù„Ø«Ù‚Ø©: {ocr_result['confidence']:.2f}")
        if 'gemini_analysis' in locals():
            print(f"   - Gemini: âœ… Ø­Ù„Ù„ Ø§Ù„Ù†Øµ ÙˆÙ‚Ø¯Ù… ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}")
        import traceback
        print(f"ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„: {traceback.format_exc()}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©...")
    print("=" * 60)
    
    if not HAS_OCR:
        print("âŒ Ù…ÙƒØªØ¨Ø§Øª OCR ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©!")
        print("Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:")
        print("pip install pytesseract pillow")
        print("ÙˆØªØ­Ù…ÙŠÙ„ Tesseract Ù…Ù†: https://github.com/UB-Mannheim/tesseract/wiki")
    else:
        asyncio.run(test_real_image_extraction()) 