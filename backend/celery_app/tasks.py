"""
Ù…Ù‡Ø§Ù… Celery Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
Celery Tasks for Parallel Processing
"""

from celery import current_task
from celery_app.worker import celery_app
from loguru import logger
import asyncio
import os
import sys
from datetime import datetime
from typing import Dict, Any, List

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.config import get_settings
from app.api.endpoints.websocket import notify_progress, notify_stage_change, notify_error, notify_completion
from app.models.schemas import ProcessingStage

settings = get_settings()

# In-memory store for file paths
file_id_to_path_store = {}


@celery_app.task(bind=True)
def process_file_comparison(self, job_id: str, session_id: str, old_files: List[str], new_files: List[str]) -> Dict[str, Any]:
    """
    Ù…Ù‡Ù…Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
    Main task for processing file comparison
    """
    try:
        logger.info(f"ğŸš€ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© - Job: {job_id}")
        
        total_files = min(len(old_files), len(new_files))
        results = []
        
        base_progress = 80
        progress_range = 15 # from 80% to 95%
        
        for i, (old_file, new_file) in enumerate(zip(old_files, new_files)):
            try:
                # 1. Ù…Ø±Ø­Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
                current_progress = base_progress + int(((i + 1) / total_files) * (progress_range / 3))
                message = f"Ù…Ù„Ù {i+1}/{total_files}: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…"
                self.update_state(state='PROGRESS', meta={'progress': current_progress, 'message': message, 'current_file': old_file, 'current_stage': ProcessingStage.OCR_EXTRACTION.value})
                
                old_file_path = file_id_to_path_store.get(old_file)
                new_file_path = file_id_to_path_store.get(new_file)
                if not old_file_path or not new_file_path:
                    raise Exception(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù Ù„Ù€ {old_file} Ø£Ùˆ {new_file}")

                old_text_result = extract_text_from_image.delay(old_file_path, job_id)
                
                message = f"Ù…Ù„Ù {i+1}/{total_files}: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯"
                self.update_state(state='PROGRESS', meta={'progress': current_progress, 'message': message, 'current_file': new_file, 'current_stage': ProcessingStage.OCR_EXTRACTION.value})
                new_text_result = extract_text_from_image.delay(new_file_path, job_id)
                
                old_text = old_text_result.get(timeout=300)
                new_text = new_text_result.get(timeout=300)
                if not old_text or not new_text:
                    raise Exception("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø£Ø­Ø¯ Ø§Ù„Ù…Ù„ÙÙŠÙ† Ø£Ùˆ ÙƒÙ„ÙŠÙ‡Ù…Ø§")
                
                # 2. Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©
                current_progress = base_progress + int(((i + 1) / total_files) * (2 * progress_range / 3))
                message = f"Ù…Ù„Ù {i+1}/{total_files}: Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©"
                self.update_state(state='PROGRESS', meta={'progress': current_progress, 'message': message, 'current_file': new_file, 'current_stage': ProcessingStage.VISUAL_ANALYSIS.value})
                
                visual_result = compare_images_visually.delay(old_file_path, new_file_path, job_id)
                visual_comparison = visual_result.get(timeout=180)

                # 3. Ù…Ø±Ø­Ù„Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ
                current_progress = base_progress + int(((i + 1) / total_files) * progress_range)
                message = f"Ù…Ù„Ù {i+1}/{total_files}: ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
                self.update_state(state='PROGRESS', meta={'progress': current_progress, 'message': message, 'current_file': new_file, 'current_stage': ProcessingStage.TEXT_COMPARISON.value})

                text_result = compare_texts_ai.delay(old_text["text"], new_text["text"], job_id)
                text_comparison = text_result.get(timeout=300)
                
                # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                file_result = {
                    "old_file": old_file,
                    "new_file": new_file,
                    "old_extraction": old_text,
                    "new_extraction": new_text,
                    "visual_comparison": visual_comparison,
                    "text_comparison": text_comparison,
                    "overall_similarity": (visual_comparison["similarity"] + text_comparison["similarity"]) / 2,
                    "processed_at": datetime.now().isoformat()
                }
                
                results.append(file_result)
                logger.info(f"âœ… ØªÙ…Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {i+1}: {new_file}")
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {new_file}: {e}")
                # Ø¥Ø¶Ø§ÙØ© Ù†ØªÙŠØ¬Ø© Ø®Ø·Ø£
                results.append({
                    "old_file": old_file,
                    "new_file": new_file,
                    "error": str(e),
                    "status": "failed"
                })
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù… Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        self.update_state(state='PROGRESS', meta={'progress': 95, 'message': "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ", 'current_stage': ProcessingStage.REPORT_GENERATION.value})
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        final_result = {
            "job_id": job_id,
            "session_id": session_id,
            "total_files": total_files,
            "processed_files": len([r for r in results if "error" not in r]),
            "failed_files": len([r for r in results if "error" in r]),
            "results": results,
            "summary": {
                "average_visual_similarity": sum(r.get("visual_comparison", {}).get("similarity", 0) for r in results if "error" not in r) / max(len([r for r in results if "error" not in r]), 1),
                "average_text_similarity": sum(r.get("text_comparison", {}).get("similarity", 0) for r in results if "error" not in r) / max(len([r for r in results if "error" not in r]), 1),
            },
            "completed_at": datetime.now().isoformat()
        }
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„Ø§ÙƒØªÙ…Ø§Ù„ (Ø§Ù„Ø­Ø§Ù„Ø© Ø³ØªØµØ¨Ø­ SUCCESS ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ return)
        # asyncio.run is problematic in Celery tasks, better to avoid if possible
        # asyncio.run(notify_completion(job_id, final_result))
        # asyncio.run(notify_progress(job_id, 100, None, "Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­"))
        
        logger.info(f"ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© - Job: {job_id}")
        return final_result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© {job_id}: {e}")
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙƒÙ€ FAILURE
        self.update_state(state='FAILURE', meta={'progress': 0, 'message': str(e), 'current_stage': 'FAILED'})
        # asyncio.run(notify_error(job_id, f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"))
        raise


@celery_app.task(bind=True)
def extract_text_from_image(self, image_path: str, job_id: str = None) -> Dict[str, Any]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LandingAI
    Extract text from image using LandingAI
    """
    try:
        logger.info(f"ğŸ“„ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù†: {image_path}")
        
        if job_id:
            asyncio.run(notify_stage_change(job_id, "OCR", f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† {os.path.basename(image_path)}"))
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø®Ø¯Ù…Ø© LandingAI
        from app.services.landing_ai_service import landing_ai_service
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LandingAI Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        loop = asyncio.get_event_loop()
        
        extraction_result = loop.run_until_complete(
            landing_ai_service.extract_from_file(image_path, job_id=job_id)
        )
        
        if not extraction_result.success:
            raise Exception(f"ÙØ´Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ LandingAI: {extraction_result.error_message}")
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        result = {
            "text": extraction_result.markdown_content,
            "confidence": extraction_result.confidence_score,
            "word_count": len(extraction_result.markdown_content.split()),
            "processing_time": extraction_result.processing_time,
            "service": "LandingAI_Real",
            "image_path": image_path,
            "structured_analysis": extraction_result.structured_analysis.dict() if extraction_result.structured_analysis else None,
            "total_chunks": extraction_result.total_chunks,
            "chunks_by_type": extraction_result.chunks_by_type,
            "visual_groundings": extraction_result.visual_groundings
        }
        
        logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù†: {image_path}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† {image_path}: {e}")
        raise


@celery_app.task(bind=True)
def compare_images_visually(self, old_image: str, new_image: str, job_id: str = None) -> Dict[str, Any]:
    """
    Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØµØ±ÙŠØ© Ù„Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… SSIM + pHash + CLIP
    Visual comparison using SSIM + pHash + CLIP
    """
    try:
        logger.info(f"ğŸ–¼ï¸ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {old_image} vs {new_image}")
        
        if job_id:
            asyncio.run(notify_stage_change(job_id, "VISUAL_COMPARISON", "Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©"))
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©
        import time
        import random
        time.sleep(random.uniform(3, 7))
        
        # Ù†ØªØ§Ø¦Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        ssim_score = random.uniform(0.6, 0.95)
        phash_score = random.uniform(0.5, 0.9)
        clip_score = random.uniform(0.7, 0.95)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© Ø¨Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        weights = {"ssim": 0.4, "phash": 0.2, "clip": 0.4}
        overall_similarity = (
            ssim_score * weights["ssim"] + 
            phash_score * weights["phash"] + 
            clip_score * weights["clip"]
        ) * 100
        
        result = {
            "similarity": overall_similarity,
            "details": {
                "ssim": ssim_score,
                "phash": phash_score,
                "clip": clip_score,
            },
            "service": "VisualMock"
        }
        
        logger.info(f"âœ… ØªÙ…Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {e}")
        if job_id:
            asyncio.run(notify_error(job_id, f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {str(e)}"))
        raise


@celery_app.task(bind=True)
def compare_texts_ai(self, old_text: str, new_text: str, job_id: str = None, context: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI
    Text comparison using Gemini AI
    """
    try:
        logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI")
        
        if job_id:
            asyncio.run(notify_stage_change(job_id, "AI_COMPARISON", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"))
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø®Ø¯Ù…Ø© Gemini
        from app.services.gemini_service import gemini_service
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        loop = asyncio.get_event_loop()
        
        comparison_result = loop.run_until_complete(
            gemini_service.compare_texts(old_text, new_text, context)
        )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        result = {
            "similarity": comparison_result.similarity_percentage,
            "content_changes": comparison_result.content_changes,
            "questions_changes": comparison_result.questions_changes,
            "examples_changes": comparison_result.examples_changes,
            "major_differences": comparison_result.major_differences,
            "added_content": comparison_result.added_content,
            "removed_content": comparison_result.removed_content,
            "modified_content": comparison_result.modified_content,
            "summary": comparison_result.summary,
            "recommendation": comparison_result.recommendation,
            "detailed_analysis": comparison_result.detailed_analysis,
            "processing_time": comparison_result.processing_time,
            "service": "Gemini_Real",
            "confidence_score": comparison_result.confidence_score,
            "old_text_length": comparison_result.old_text_length,
            "new_text_length": comparison_result.new_text_length,
            "common_words_count": comparison_result.common_words_count,
            "unique_old_words": comparison_result.unique_old_words,
            "unique_new_words": comparison_result.unique_new_words
        }
        
        logger.info(f"âœ… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ: {comparison_result.similarity_percentage:.1f}% ØªØ·Ø§Ø¨Ù‚")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ: {e}")
        # if job_id:
        #     asyncio.run(notify_error(job_id, f"ÙØ´Ù„ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ: {str(e)}"))
        raise


@celery_app.task(bind=True)
def generate_report(self, job_id: str, comparison_results: Dict[str, Any], format: str = "html") -> Dict[str, Any]:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    Generate final report
    """
    try:
        logger.info(f"ğŸ“Š Ø¨Ø¯Ø¡ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±")
        
        if job_id:
            asyncio.run(notify_stage_change(job_id, "REPORT_GENERATION", "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±"))

        # Ù…Ø­Ø§ÙƒØ§Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        import time
        time.sleep(random.uniform(2, 4))
        
        report_path = f"./uploads/reports/{job_id}_report.{format}"
        
        # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ: Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ¹Ù„ÙŠ
        result = {
            "report_path": report_path,
            "format": format,
            "job_id": job_id,
            "file_size": random.randint(500000, 2000000),  # Ø­Ø¬Ù… ØªØ¬Ø±ÙŠØ¨ÙŠ
            "pages": random.randint(5, 15),
            "generated_at": datetime.now().isoformat(),
            "download_url": f"/api/v1/reports/download/{job_id}",
            "expires_at": (datetime.now().timestamp() + 3600 * 24),  # 24 Ø³Ø§Ø¹Ø©
        }
        
        logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨Ù†Ø¬Ø§Ø­")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
        if job_id:
            asyncio.run(notify_error(job_id, f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"))
        raise


# Ù…Ù‡Ù…Ø© ØªÙ†Ø¸ÙŠÙ Ø¯ÙˆØ±ÙŠØ©
@celery_app.task
def cleanup_old_files():
    """
    Ù…Ù‡Ù…Ø© Ø¯ÙˆØ±ÙŠØ© Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
    Periodic task to cleanup old files
    """
    try:
        logger.info("ğŸ§¹ Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©")
        
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† CLEANUP_AFTER_DAYS
        from datetime import timedelta
        cutoff_date = datetime.now() - timedelta(days=settings.CLEANUP_AFTER_DAYS)
        
        # ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ù† Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        logger.info(f"âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø£Ù‚Ø¯Ù… Ù…Ù† {cutoff_date}")
        
        return {"status": "success", "cutoff_date": cutoff_date.isoformat()}
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª: {e}")
        raise 