#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¨Ø§Ø´Ø± Ù„Ù€ LandingAI API Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract
Direct LandingAI API Test - No Tesseract Fallback
"""

import asyncio
import aiohttp
import aiofiles
import json
import os
from datetime import datetime
import sys
import logging

# Add the parent directory to the path so we can import from config
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.core.config import get_settings
from app.services.landing_ai_service import LandingAIService

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ensure the API key is set in environment variables
VISION_AGENT_API_KEY = os.environ.get("VISION_AGENT_API_KEY", "")
# Temporarily bypass API key check for testing
# if not VISION_AGENT_API_KEY:
#     logger.warning("VISION_AGENT_API_KEY not set. Please set it before running the test.")
#     exit(1)

def test_landingai_extraction():
    """Test direct extraction using LandingAI API with agentic-doc library."""
    logger.info("Starting LandingAI direct API test")
    
    # Initialize the service
    service = LandingAIService()
    if not service.is_enabled():
        logger.error("LandingAI service is not enabled. Check API key and agentic-doc installation.")
        return
    
    # Test files provided by the user
    test_files = [
        r"D:\ezz\compair\edu-compare-wizard\backend\103.jpg",
        r"C:\Users\ezz\Downloads\elkheta-content-compare-pro-main\elkheta-content-compare-pro-main\Ù…Ù‚Ø¯Ù…Ø© ØªÙ…Ù‡ÙŠØ¯ÙŠØ©.pdf"
    ]
    
    # Create a temporary directory for results
    output_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "test_landingai_direct_output")
    os.makedirs(output_dir, exist_ok=True)
    logger.info(f"Output directory created at: {output_dir}")
    
    # Process each file
    for file_path in test_files:
        if not os.path.exists(file_path):
            logger.error(f"File not found: {file_path}")
            continue
        
        logger.info(f"Processing file: {file_path}")
        result = service.extract_text_from_image(file_path, output_dir)
        
        if "error" in result:
            logger.error(f"Failed to process {file_path}: {result['error']}")
        else:
            logger.info(f"Successfully processed {file_path}")
            # Save the result to a JSON file
            output_file = os.path.join(output_dir, f"result_{os.path.basename(file_path).replace('.', '_')}.json")
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            logger.info(f"Results saved to: {output_file}")
    
    logger.info("LandingAI direct API test completed")

async def test_landingai_direct():
    """Ø§Ø®ØªØ¨Ø§Ø± LandingAI API Ù…Ø¨Ø§Ø´Ø±Ø©"""
    
    print("="*60)
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± LandingAI API Ù…Ø¨Ø§Ø´Ø±")
    print("="*60)
    
    # Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    api_key = "ZzhobnJ6Z3J3cm1maW83Mnd3YW1sOmlCdGdzRVJWNDJSODNQSzdHbWNzVEdhZkFxSGNaWmdH"
    api_endpoint = "https://api.va.landing.ai/v1/tools/agentic-document-analysis"
    test_image = "103.jpg"
    
    print(f"ğŸ”‘ API Key: {api_key[:30]}...")
    print(f"ğŸŒ Endpoint: {api_endpoint}")
    print(f"ğŸ“ Test Image: {test_image}")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
    if not os.path.exists(test_image):
        print(f"âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {test_image}")
        return False
    
    file_size = os.path.getsize(test_image) / 1024  # KB
    print(f"ğŸ“ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {file_size:.1f} KB")
    
    try:
        print("\nğŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬...")
        start_time = datetime.now()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ headers
        headers = {
            'Authorization': f'Basic {api_key}'
        }
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data = aiohttp.FormData()
        data.add_field('include_marginalia', 'true')
        data.add_field('include_metadata_in_markdown', 'true')
        
        # Ù‚Ø±Ø§Ø¡Ø© ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„Ù
        async with aiofiles.open(test_image, 'rb') as f:
            file_content = await f.read()
            data.add_field('file', file_content, filename=test_image, content_type='application/octet-stream')
        
        print(f"ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ LandingAI...")
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
        timeout = aiohttp.ClientTimeout(total=600)  # 10 Ø¯Ù‚Ø§Ø¦Ù‚
        async with aiohttp.ClientSession(timeout=timeout) as session:
            async with session.post(api_endpoint, headers=headers, data=data) as response:
                print(f"ğŸ“¡ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø®Ø§Ø¯Ù…: {response.status}")
                
                if response.status == 200:
                    result_data = await response.json()
                    end_time = datetime.now()
                    processing_time = (end_time - start_time).total_seconds()
                    
                    print("âœ… Ù†Ø¬Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬!")
                    print(f"â±ï¸  ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                    data_section = result_data.get('data', {})
                    markdown_content = data_section.get('markdown', '')
                    chunks = data_section.get('chunks', [])
                    extracted_schema = data_section.get('extracted_schema', {})
                    
                    print(f"ğŸ“„ Ø·ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {len(markdown_content)} Ø­Ø±Ù")
                    print(f"ğŸ”¢ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø·Ø¹: {len(chunks)}")
                    
                    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù‚Ø·Ø¹
                    chunk_types = {}
                    for chunk in chunks:
                        chunk_type = chunk.get('chunk_type', 'unknown')
                        chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1
                    
                    print(f"\nğŸ“Š ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù‚Ø·Ø¹:")
                    for chunk_type, count in chunk_types.items():
                        print(f"  â€¢ {chunk_type}: {count}")
                    
                    # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰
                    if markdown_content:
                        print(f"\nğŸ“ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬:")
                        print("â”€" * 50)
                        preview = markdown_content[:300] + "..." if len(markdown_content) > 300 else markdown_content
                        print(preview)
                        print("â”€" * 50)
                    
                    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    results_dir = f"landingai_test_{timestamp}"
                    os.makedirs(results_dir, exist_ok=True)
                    
                    # Ø­ÙØ¸ JSON Ø§Ù„ÙƒØ§Ù…Ù„
                    json_file = os.path.join(results_dir, "full_result.json")
                    async with aiofiles.open(json_file, 'w', encoding='utf-8') as f:
                        await f.write(json.dumps(result_data, ensure_ascii=False, indent=2))
                    
                    # Ø­ÙØ¸ Markdown
                    if markdown_content:
                        md_file = os.path.join(results_dir, "extracted_content.md")
                        async with aiofiles.open(md_file, 'w', encoding='utf-8') as f:
                            await f.write(markdown_content)
                    
                    print(f"\nğŸ’¾ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {results_dir}")
                    print(f"  â€¢ JSON: {json_file}")
                    if markdown_content:
                        print(f"  â€¢ Markdown: {md_file}")
                    
                    print("\n" + "="*60)
                    print("ğŸ‰ Ù†Ø¬Ø­ Ø§Ø®ØªØ¨Ø§Ø± LandingAI API!")
                    print("="*60)
                    
                    return True
                    
                else:
                    error_text = await response.text()
                    print(f"âŒ Ø®Ø·Ø£ Ù…Ù† LandingAI: {response.status}")
                    print(f"ğŸ“ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {error_text}")
                    return False
                    
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
        import traceback
        traceback.print_exc()
        return False

async def test_gemini_direct():
    """Ø§Ø®ØªØ¨Ø§Ø± Gemini API Ù…Ø¨Ø§Ø´Ø±"""
    
    print("="*60)
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Gemini API Ù…Ø¨Ø§Ø´Ø±") 
    print("="*60)
    
    import google.generativeai as genai
    
    api_key = "AIzaSyCDO-0puQQN79BJ4u503O31g16ww8CAycg"
    model_name = "gemini-1.5-flash"  # Ù†Ù…ÙˆØ°Ø¬ Ø£Ø³Ø±Ø¹ Ù…Ø¹ Ø­Ø¯ÙˆØ¯ Ø£ÙƒØ¨Ø±
    
    print(f"ğŸ”‘ API Key: {api_key[:30]}...")
    print(f"ğŸ¤– Model: {model_name}")
    
    try:
        # ØªÙƒÙˆÙŠÙ† Gemini
        genai.configure(api_key=api_key)
        
        generation_config = {
            "temperature": 0.3,
            "top_p": 0.8,
            "top_k": 40,
            "max_output_tokens": 2048,
        }
        
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config=generation_config
        )
        
        print("âœ… ØªÙ… ØªÙƒÙˆÙŠÙ† Gemini Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø³ÙŠØ· Ø£ÙˆÙ„Ø§Ù‹
        print("\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§ØªØµØ§Ù„ Ø¨Ø³ÙŠØ·...")
        simple_prompt = "Ù‚Ù„ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
        
        start_time = datetime.now()
        response = await asyncio.to_thread(model.generate_content, simple_prompt)
        end_time = datetime.now()
        
        if response.text:
            print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø³ÙŠØ·!")
            print(f"â±ï¸  ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {(end_time - start_time).total_seconds():.2f} Ø«Ø§Ù†ÙŠØ©")
            print(f"ğŸ“ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.text}")
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ
            print("\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ...")
            
            comparison_prompt = """
Ù‚Ø§Ø±Ù† Ø¨ÙŠÙ† Ø§Ù„Ù†ØµÙŠÙ† Ø§Ù„ØªØ§Ù„ÙŠÙŠÙ† ÙˆØ§ÙƒØªØ¨ ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹:

Ø§Ù„Ù†Øµ Ø§Ù„Ø£ÙˆÙ„:
Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡
- Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ù‚ÙˆØ©
- Ù‚Ø§Ù†ÙˆÙ† Ù†ÙŠÙˆØªÙ† Ø§Ù„Ø£ÙˆÙ„

Ø§Ù„Ù†Øµ Ø§Ù„Ø«Ø§Ù†ÙŠ:  
Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠØ©
- Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ù‚ÙˆØ© ÙˆØ§Ù„ÙƒØªÙ„Ø©
- Ù‚Ø§Ù†ÙˆÙ† Ù†ÙŠÙˆØªÙ† Ø§Ù„Ø£ÙˆÙ„ ÙˆØ§Ù„Ø«Ø§Ù†ÙŠ
- ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¹Ù…Ù„ÙŠØ©

Ø§ÙƒØªØ¨ Ù…Ù„Ø®ØµØ§Ù‹ Ù‚ØµÙŠØ±Ø§Ù‹ Ù„Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª.
"""
            
            start_time = datetime.now()
            comparison_response = await asyncio.to_thread(model.generate_content, comparison_prompt)
            end_time = datetime.now()
            
            if comparison_response.text:
                print(f"âœ… Ù†Ø¬Ø­Øª Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ!")
                print(f"â±ï¸  ÙˆÙ‚Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {(end_time - start_time).total_seconds():.2f} Ø«Ø§Ù†ÙŠØ©")
                print(f"ğŸ“Š Ø·ÙˆÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {len(comparison_response.text)} Ø­Ø±Ù")
                
                print(f"\nğŸ“ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:")
                print("â”€" * 50)
                print(comparison_response.text)
                print("â”€" * 50)
                
                print("\n" + "="*60)
                print("ğŸ‰ Ù†Ø¬Ø­ Ø§Ø®ØªØ¨Ø§Ø± Gemini API!")
                print("="*60)
                
                return True
            else:
                print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©")
                return False
        else:
            print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨Ø³ÙŠØ·")
            return False
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Gemini: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©"""
    
    print("ğŸ¯ Ø§Ø®ØªØ¨Ø§Ø± APIs Ù…Ø¨Ø§Ø´Ø±Ø© - Ø¨Ø¯ÙˆÙ† Tesseract")
    print("ğŸ”§ LandingAI + Gemini ÙÙ‚Ø·")
    
    results = []
    
    # Ø§Ø®ØªØ¨Ø§Ø± LandingAI Ù…Ø¨Ø§Ø´Ø±
    print("\n" + "ğŸ”·" * 20 + " LANDINGAI " + "ğŸ”·" * 20)
    landingai_success = await test_landingai_direct()
    results.append(("LandingAI API", landingai_success))
    
    await asyncio.sleep(3)  # Ø§Ø³ØªØ±Ø§Ø­Ø©
    
    # Ø§Ø®ØªØ¨Ø§Ø± Gemini Ù…Ø¨Ø§Ø´Ø±
    print("\n" + "ğŸ”¶" * 20 + " GEMINI " + "ğŸ”¶" * 20)
    gemini_success = await test_gemini_direct()
    results.append(("Gemini API", gemini_success))
    
    # ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\n" + "="*60)
    print("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
    print("="*60)
    
    all_success = True
    for service_name, success in results:
        status = "âœ… Ù†Ø¬Ø­" if success else "âŒ ÙØ´Ù„"
        print(f"{status} {service_name}")
        if not success:
            all_success = False
    
    print("\n" + "="*60)
    if all_success:
        print("ğŸ‰ Ø¬Ù…ÙŠØ¹ APIs ØªØ¹Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­! Ù„Ø§ Ø­Ø§Ø¬Ø© Ù„Ù€ Tesseract")
        print("ğŸš€ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©")
    else:
        print("âš ï¸ Ø¨Ø¹Ø¶ APIs ÙØ´Ù„Øª - ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„Ø§ØªØµØ§Ù„")
    print("="*60)
    
    return all_success

if __name__ == "__main__":
    test_landingai_extraction()
    success = asyncio.run(main())
    exit(0 if success else 1) 