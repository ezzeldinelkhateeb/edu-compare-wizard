#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¹Ù„Ù‰ ÙƒØ´Ù ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙˆØµ
Test Visual Similarity's Ability to Detect Text Content Changes
"""

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import json
from pathlib import Path
import os
from datetime import datetime

class TextChangeDetectionTester:
    def __init__(self):
        self.results = []
        self.test_images_dir = Path("text_change_test_images")
        self.test_images_dir.mkdir(exist_ok=True)
        
    def create_test_image(self, text_content, filename, font_size=40):
        """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Øµ Ù…Ø­Ø¯Ø¯"""
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
        width, height = 800, 600
        background_color = (255, 255, 255)  # Ø£Ø¨ÙŠØ¶
        text_color = (0, 0, 0)  # Ø£Ø³ÙˆØ¯
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±Ø©
        image = Image.new('RGB', (width, height), background_color)
        draw = ImageDraw.Draw(image)
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø¹Ø±Ø¨ÙŠØŒ Ø£Ùˆ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ
        try:
            font = ImageFont.truetype("arial.ttf", font_size)
        except:
            try:
                font = ImageFont.load_default()
            except:
                font = None
        
        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ÙˆØ§Ù† Ø«Ø§Ø¨Øª
        title = "Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†Øµ"
        draw.text((50, 50), title, fill=text_color, font=font)
        
        # Ø¥Ø¶Ø§ÙØ© Ø®Ø· ÙØ§ØµÙ„
        draw.line([(50, 100), (750, 100)], fill=(200, 200, 200), width=2)
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªØºÙŠØ±
        y_position = 150
        lines = text_content.split('\n')
        for line in lines:
            draw.text((50, y_position), line, fill=text_color, font=font)
            y_position += font_size + 10
        
        # Ø¥Ø¶Ø§ÙØ© Ø¥Ø·Ø§Ø± Ø«Ø§Ø¨Øª
        draw.rectangle([(30, 30), (770, 570)], outline=(100, 100, 100), width=3)
        
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
        image_path = self.test_images_dir / filename
        image.save(image_path)
        return str(image_path)
    
    def calculate_visual_similarity(self, img1_path, img2_path):
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¨ØµØ±ÙŠ Ø¨ÙŠÙ† ØµÙˆØ±ØªÙŠÙ†"""
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±
            img1 = cv2.imread(img1_path, cv2.IMREAD_GRAYSCALE)
            img2 = cv2.imread(img2_path, cv2.IMREAD_GRAYSCALE)
            
            if img1 is None or img2 is None:
                return {"error": "ÙØ´Ù„ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±"}
            
            # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
            height = min(img1.shape[0], img2.shape[0])
            width = min(img1.shape[1], img2.shape[1])
            
            img1_resized = cv2.resize(img1, (width, height))
            img2_resized = cv2.resize(img2, (width, height))
            
            # 1. Ø­Ø³Ø§Ø¨ MSE Ùˆ PSNR
            mse = np.mean((img1_resized - img2_resized) ** 2)
            if mse == 0:
                psnr_similarity = 1.0
            else:
                psnr = 20 * np.log10(255.0 / np.sqrt(mse))
                psnr_similarity = min(1.0, psnr / 50.0)
            
            # 2. Ø­Ø³Ø§Ø¨ Structural Similarity (Ù…Ø¨Ø³Ø·)
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø· ÙˆØ§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ
            mu1 = np.mean(img1_resized)
            mu2 = np.mean(img2_resized)
            sigma1 = np.std(img1_resized)
            sigma2 = np.std(img2_resized)
            sigma12 = np.mean((img1_resized - mu1) * (img2_resized - mu2))
            
            # Ø«ÙˆØ§Ø¨Øª SSIM
            c1 = (0.01 * 255) ** 2
            c2 = (0.03 * 255) ** 2
            
            ssim = ((2 * mu1 * mu2 + c1) * (2 * sigma12 + c2)) / ((mu1**2 + mu2**2 + c1) * (sigma1**2 + sigma2**2 + c2))
            ssim_similarity = (ssim + 1) / 2  # ØªØ­ÙˆÙŠÙ„ Ù…Ù† [-1,1] Ø¥Ù„Ù‰ [0,1]
            
            # 3. Ø­Ø³Ø§Ø¨ Histogram Similarity
            hist1 = cv2.calcHist([img1_resized], [0], None, [256], [0, 256])
            hist2 = cv2.calcHist([img2_resized], [0], None, [256], [0, 256])
            hist_similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            
            # 4. Ø­Ø³Ø§Ø¨ Pixel Difference Analysis
            diff_pixels = np.sum(img1_resized != img2_resized)
            total_pixels = img1_resized.shape[0] * img1_resized.shape[1]
            pixel_similarity = 1.0 - (diff_pixels / total_pixels)
            
            # 5. Ø­Ø³Ø§Ø¨ Edge Detection Similarity
            edges1 = cv2.Canny(img1_resized, 50, 150)
            edges2 = cv2.Canny(img2_resized, 50, 150)
            edge_diff = np.sum(edges1 != edges2)
            edge_total = edges1.shape[0] * edges1.shape[1]
            edge_similarity = 1.0 - (edge_diff / edge_total)
            
            # Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
            combined_similarity = (
                psnr_similarity * 0.25 +
                ssim_similarity * 0.30 +
                hist_similarity * 0.20 +
                pixel_similarity * 0.15 +
                edge_similarity * 0.10
            )
            
            return {
                "psnr_similarity": round(psnr_similarity, 4),
                "ssim_similarity": round(ssim_similarity, 4),
                "histogram_similarity": round(hist_similarity, 4),
                "pixel_similarity": round(pixel_similarity, 4),
                "edge_similarity": round(edge_similarity, 4),
                "combined_similarity": round(combined_similarity, 4),
                "mse": round(mse, 2),
                "different_pixels": diff_pixels,
                "total_pixels": total_pixels,
                "diff_percentage": round((diff_pixels / total_pixels) * 100, 2)
            }
            
        except Exception as e:
            return {"error": f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨: {str(e)}"}
    
    def run_text_change_tests(self):
        """ØªØ´ØºÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªØºÙŠÙŠØ± Ø§Ù„Ù†Øµ"""
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ù‚Ø¯Ø±Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¹Ù„Ù‰ ÙƒØ´Ù ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙˆØµ")
        print("="*70)
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        test_cases = [
            {
                "name": "Ù†ÙØ³ Ø§Ù„Ù†Øµ ØªÙ…Ø§Ù…Ø§Ù‹",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "description": "Ù†Øµ Ù…ØªØ·Ø§Ø¨Ù‚ 100% - ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹"
            },
            {
                "name": "ØªØºÙŠÙŠØ± ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø¯Ù…ÙŠØ§Ø·",
                "description": "ØªØºÙŠÙŠØ± Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø­Ø¯Ø© (Ø§Ù„Ø£Ù‚ØµØ± â†’ Ø¯Ù…ÙŠØ§Ø·)"
            },
            {
                "name": "ØªØºÙŠÙŠØ± Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "description": "ØªØºÙŠÙŠØ± Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„ ÙÙ‚Ø· (Ø§Ù„Ø£ÙˆÙ„ â†’ Ø§Ù„Ø«Ø§Ù†ÙŠ)"
            },
            {
                "name": "ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø¤Ø§Ù„ ÙƒØ§Ù…Ù„Ø§Ù‹",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø£ÙƒØ¨Ø± ÙƒÙˆÙƒØ¨ØŸ\nØ£) Ø§Ù„Ø£Ø±Ø¶\nØ¨) Ø§Ù„Ù…Ø´ØªØ±ÙŠ\nØ¬) Ø²Ø­Ù„\nØ¯) Ø§Ù„Ù…Ø±ÙŠØ®",
                "description": "ØªØºÙŠÙŠØ± Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª ÙƒØ§Ù…Ù„Ø§Ù‹"
            },
            {
                "name": "ØªØºÙŠÙŠØ± ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¨) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¬) Ø§Ù„Ø£Ù‚ØµØ±\nØ¯) Ø£Ø³ÙˆØ§Ù†",
                "description": "Ù†ÙØ³ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø§Øª Ù„ÙƒÙ† ØªØ±ØªÙŠØ¨ Ù…Ø®ØªÙ„Ù"
            },
            {
                "name": "Ø¥Ø¶Ø§ÙØ© Ø³Ø¤Ø§Ù„ Ø¬Ø¯ÙŠØ¯",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±\n\nØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø«Ø§Ù†ÙŠ: ÙƒÙ… Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø§Ø±Ø§ØªØŸ\nØ£) 5\nØ¨) 6\nØ¬) 7\nØ¯) 8",
                "description": "Ø¥Ø¶Ø§ÙØ© Ø³Ø¤Ø§Ù„ Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø£ØµÙ„ÙŠ"
            },
            {
                "name": "Ø­Ø°Ù Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ",
                "text1": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©\nØ¬) Ø£Ø³ÙˆØ§Ù†\nØ¯) Ø§Ù„Ø£Ù‚ØµØ±",
                "text2": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ø§ Ù‡Ùˆ Ø¹Ø§ØµÙ…Ø© Ù…ØµØ±ØŸ\nØ£) Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©\nØ¨) Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©",
                "description": "Ø­Ø°Ù Ø¥Ø¬Ø§Ø¨ØªÙŠÙ† Ù…Ù† Ø§Ù„Ø£ØµÙ„"
            }
        ]
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
        for i, test_case in enumerate(test_cases):
            print(f"\nğŸ“‹ Ø§Ø®ØªØ¨Ø§Ø± {i+1}: {test_case['name']}")
            print(f"ğŸ“ Ø§Ù„ÙˆØµÙ: {test_case['description']}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØ±
            img1_path = self.create_test_image(test_case['text1'], f"test_{i+1}_original.png")
            img2_path = self.create_test_image(test_case['text2'], f"test_{i+1}_modified.png")
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
            similarity_result = self.calculate_visual_similarity(img1_path, img2_path)
            
            if "error" in similarity_result:
                print(f"âŒ Ø®Ø·Ø£: {similarity_result['error']}")
                continue
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            print(f"ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            print(f"   ğŸ¯ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ù…Ø±ÙƒØ¨: {similarity_result['combined_similarity']:.3f} ({similarity_result['combined_similarity']*100:.1f}%)")
            print(f"   ğŸ—ï¸  PSNR: {similarity_result['psnr_similarity']:.3f} ({similarity_result['psnr_similarity']*100:.1f}%)")
            print(f"   ğŸ“ SSIM: {similarity_result['ssim_similarity']:.3f} ({similarity_result['ssim_similarity']*100:.1f}%)")
            print(f"   ğŸ¨ Histogram: {similarity_result['histogram_similarity']:.3f} ({similarity_result['histogram_similarity']*100:.1f}%)")
            print(f"   ğŸ” Pixels: {similarity_result['pixel_similarity']:.3f} ({similarity_result['pixel_similarity']*100:.1f}%)")
            print(f"   ğŸ“ Edges: {similarity_result['edge_similarity']:.3f} ({similarity_result['edge_similarity']*100:.1f}%)")
            print(f"   ğŸ“Š MSE: {similarity_result['mse']}")
            print(f"   ğŸ”¢ Ø¨ÙƒØ³Ù„ Ù…Ø®ØªÙ„Ù: {similarity_result['different_pixels']:,} / {similarity_result['total_pixels']:,} ({similarity_result['diff_percentage']}%)")
            
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†ØªÙŠØ¬Ø©
            combined_score = similarity_result['combined_similarity']
            if combined_score >= 0.95:
                evaluation = "ğŸŸ¢ ØªØ·Ø§Ø¨Ù‚ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹ - ØªØºÙŠÙŠØ± Ø¶Ø¦ÙŠÙ„ Ø¬Ø¯Ø§Ù‹ Ø£Ùˆ Ù…Ø¹Ø¯ÙˆÙ…"
            elif combined_score >= 0.85:
                evaluation = "ğŸŸ¡ ØªØ·Ø§Ø¨Ù‚ Ø¹Ø§Ù„ÙŠ - ØªØºÙŠÙŠØ± Ø·ÙÙŠÙ"
            elif combined_score >= 0.70:
                evaluation = "ğŸŸ  ØªØ·Ø§Ø¨Ù‚ Ù…ØªÙˆØ³Ø· - ØªØºÙŠÙŠØ± ÙˆØ§Ø¶Ø­"
            elif combined_score >= 0.50:
                evaluation = "ğŸ”´ ØªØ·Ø§Ø¨Ù‚ Ù…Ù†Ø®ÙØ¶ - ØªØºÙŠÙŠØ± ÙƒØ¨ÙŠØ±"
            else:
                evaluation = "âš« ØªØ·Ø§Ø¨Ù‚ Ø¶Ø¹ÙŠÙ - ØªØºÙŠÙŠØ± Ø¬Ø°Ø±ÙŠ"
            
            print(f"   ğŸ“ˆ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {evaluation}")
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
            result = {
                "test_name": test_case['name'],
                "description": test_case['description'],
                "similarity_metrics": similarity_result,
                "evaluation": evaluation,
                "images": {
                    "original": img1_path,
                    "modified": img2_path
                }
            }
            self.results.append(result)
        
        # Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.print_summary()
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self.save_results()
    
    def print_summary(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        print("\n" + "="*70)
        print("ğŸ“Š Ù…Ù„Ø®Øµ Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ´Ù ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙˆØµ")
        print("="*70)
        
        scores = [r['similarity_metrics']['combined_similarity'] for r in self.results if 'similarity_metrics' in r]
        
        if not scores:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†ØªØ§Ø¦Ø¬ ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„")
            return
        
        avg_score = np.mean(scores)
        max_score = np.max(scores)
        min_score = np.min(scores)
        
        print(f"ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {avg_score:.3f} ({avg_score*100:.1f}%)")
        print(f"â¬†ï¸  Ø£Ø¹Ù„Ù‰ ØªØ´Ø§Ø¨Ù‡: {max_score:.3f} ({max_score*100:.1f}%)")
        print(f"â¬‡ï¸  Ø£Ù‚Ù„ ØªØ´Ø§Ø¨Ù‡: {min_score:.3f} ({min_score*100:.1f}%)")
        
        print(f"\nğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„ØªØºÙŠÙŠØ±:")
        for result in self.results:
            if 'similarity_metrics' in result:
                score = result['similarity_metrics']['combined_similarity']
                print(f"   ğŸ“ {result['test_name']}: {score:.3f} ({score*100:.1f}%)")
        
        # ØªØ­Ù„ÙŠÙ„ Ù‚Ø¯Ø±Ø© Ø§Ù„ÙƒØ´Ù
        print(f"\nğŸ” ØªØ­Ù„ÙŠÙ„ Ù‚Ø¯Ø±Ø© ÙƒØ´Ù Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª:")
        
        # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ø·ÙÙŠÙ
        minor_changes = [r for r in self.results if any(keyword in r['test_name'] for keyword in ['ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©', 'Ø±Ù‚Ù… Ø§Ù„Ø³Ø¤Ø§Ù„', 'ØªØ±ØªÙŠØ¨'])]
        if minor_changes:
            minor_scores = [r['similarity_metrics']['combined_similarity'] for r in minor_changes]
            avg_minor = np.mean(minor_scores)
            print(f"   ğŸŸ¡ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø·ÙÙŠÙØ©: Ù…ØªÙˆØ³Ø· {avg_minor:.3f} ({avg_minor*100:.1f}%)")
        
        # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„ÙƒØ¨ÙŠØ±
        major_changes = [r for r in self.results if any(keyword in r['test_name'] for keyword in ['Ø§Ù„Ø³Ø¤Ø§Ù„ ÙƒØ§Ù…Ù„Ø§Ù‹', 'Ø¥Ø¶Ø§ÙØ©', 'Ø­Ø°Ù'])]
        if major_changes:
            major_scores = [r['similarity_metrics']['combined_similarity'] for r in major_changes]
            avg_major = np.mean(major_scores)
            print(f"   ğŸ”´ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©: Ù…ØªÙˆØ³Ø· {avg_major:.3f} ({avg_major*100:.1f}%)")
        
        # Ø®Ù„Ø§ØµØ© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        print(f"\nğŸ‰ Ø§Ù„Ø®Ù„Ø§ØµØ©:")
        if avg_score >= 0.80:
            print("   âš ï¸  Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø­Ø³Ø§Ø³Ø© Ù†Ø³Ø¨ÙŠØ§Ù‹ Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙˆØµ")
            print("   ğŸ’¡ ÙŠÙÙ†ØµØ­ Ø¨Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ OCR Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ø£ÙØ¶Ù„")
        elif avg_score >= 0.60:
            print("   âœ… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© ØªÙƒØ´Ù Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯")
            print("   âš ï¸  Ù‚Ø¯ ØªÙÙˆØª Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø·ÙÙŠÙØ© ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ")
        else:
            print("   âœ… Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ù…Ù…ØªØ§Ø²Ø© ÙÙŠ ÙƒØ´Ù ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙˆØµ")
            print("   ğŸ¯ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠÙ‡Ø§ ÙƒØ£Ø¯Ø§Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù„ÙƒØ´Ù")
    
    def save_results(self):
        """Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ù…Ù„Ù JSON"""
        output_data = {
            "test_date": datetime.now().isoformat(),
            "test_type": "text_change_detection",
            "summary": {
                "total_tests": len(self.results),
                "average_similarity": np.mean([r['similarity_metrics']['combined_similarity'] for r in self.results if 'similarity_metrics' in r]) if self.results else 0
            },
            "detailed_results": self.results
        }
        
        output_path = Path("text_change_detection_results.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {output_path}")
        print(f"ğŸ“ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø© ÙÙŠ: {self.test_images_dir}/")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    tester = TextChangeDetectionTester()
    tester.run_text_change_tests()

if __name__ == "__main__":
    main() 