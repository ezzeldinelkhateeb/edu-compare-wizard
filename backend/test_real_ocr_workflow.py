#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù€ OCR
Comprehensive test for real OCR workflow
"""

import asyncio
import os
import sys
import json
from datetime import datetime
from pathlib import Path

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.landing_ai_service import LandingAIService
from app.services.gemini_service import GeminiService
from loguru import logger

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logger.remove()
logger.add(
    sys.stdout,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
    level="DEBUG",
    colorize=True
)

async def test_real_ocr_workflow():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù€ OCR"""
    
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù€ OCR")
    print("=" * 60)
    
    # Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
    image_path = "103.jpg"
    
    if not os.path.exists(image_path):
        print(f"âŒ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image_path}")
        return
    
    print(f"ğŸ“¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØµÙˆØ±Ø©: {image_path}")
    print(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù: {os.path.getsize(image_path)} Ø¨Ø§ÙŠØª")
    
    try:
        # 1. Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© LandingAI
        print("\nğŸ” Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§Ø®ØªØ¨Ø§Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LandingAI")
        print("-" * 50)
        
        landing_service = LandingAIService()
        
        # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø©
        health = await landing_service.health_check()
        print(f"ğŸ¥ Ø­Ø§Ù„Ø© LandingAI: {health['status']}")
        print(f"ğŸ­ Ø§Ù„ÙˆØ¶Ø¹: {health.get('mode', 'unknown')}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
        print("\nğŸ“ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ...")
        extraction_result = await landing_service.extract_from_file(image_path)
        
        if extraction_result.success:
            print(f"âœ… Ù†Ø¬Ø­ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬!")
            print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {extraction_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            print(f"ğŸ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {extraction_result.confidence_score:.1%}")
            print(f"ğŸ“Š Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {extraction_result.text_elements}")
            print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡: {extraction_result.total_chunks}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
            print(f"\nğŸ“– Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ ({len(extraction_result.markdown_content)} Ø­Ø±Ù):")
            print("-" * 40)
            print(extraction_result.markdown_content[:500] + "..." if len(extraction_result.markdown_content) > 500 else extraction_result.markdown_content)
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù…
            if extraction_result.structured_analysis:
                analysis = extraction_result.structured_analysis
                print(f"\nğŸ§  Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù…:")
                print(f"   ğŸ“š Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹: {analysis.subject}")
                print(f"   ğŸ“ Ø§Ù„Ù…Ø³ØªÙˆÙ‰: {analysis.grade_level}")
                print(f"   ğŸ“– Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ÙØµÙ„: {analysis.chapter_title}")
                print(f"   ğŸ¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù: {len(analysis.learning_objectives)} Ù‡Ø¯Ù")
                print(f"   ğŸ“ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹: {len(analysis.topics)} Ù…ÙˆØ¶ÙˆØ¹")
                print(f"   ğŸ”‘ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…: {len(analysis.key_concepts)} Ù…ÙÙ‡ÙˆÙ…")
                print(f"   ğŸ“Š Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµØ¹ÙˆØ¨Ø©: {analysis.difficulty_level}")
                print(f"   ğŸŒ Ø§Ù„Ù„ØºØ©: {analysis.language}")
            
        else:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {extraction_result.error_message}")
            return
        
        # 2. Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø¯Ù…Ø© Gemini
        print("\nğŸ¤– Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
        print("-" * 50)
        
        gemini_service = GeminiService()
        
        # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø©
        gemini_health = await gemini_service.health_check()
        print(f"ğŸ¥ Ø­Ø§Ù„Ø© Gemini: {gemini_health['status']}")
        print(f"ğŸ­ Ø§Ù„ÙˆØ¶Ø¹: {gemini_health.get('mode', 'unknown')}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        print("\nğŸ§  Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù†Øµ Ù…Ø±Ø¬Ø¹ÙŠ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ù†Øµ Ù…Ø´Ø§Ø¨Ù‡)
        reference_text = """
        Ø§Ù„ÙØµÙ„ Ø§Ù„Ø£ÙˆÙ„: Ù…Ù‚Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª
        
        Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©:
        - ÙÙ‡Ù… Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©
        - ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        - Ø­Ù„ Ø§Ù„Ù…Ø³Ø§Ø¦Ù„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
        
        Ø§Ù„Ù…Ø­ØªÙˆÙ‰:
        ÙŠØªÙ†Ø§ÙˆÙ„ Ù‡Ø°Ø§ Ø§Ù„ÙØµÙ„ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆØ§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ©.
        Ø³Ù†ØªØ¹Ù„Ù… Ø§Ù„Ø¬Ù…Ø¹ ÙˆØ§Ù„Ø·Ø±Ø­ ÙˆØ§Ù„Ø¶Ø±Ø¨ ÙˆØ§Ù„Ù‚Ø³Ù…Ø© Ù…Ø¹ Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ©.
        
        Ø§Ù„ØªÙ…Ø§Ø±ÙŠÙ†:
        1. Ø§Ø­Ø³Ø¨ Ù…Ø¬Ù…ÙˆØ¹ Ø§Ù„Ø£Ø¹Ø¯Ø§Ø¯ Ù…Ù† 1 Ø¥Ù„Ù‰ 10
        2. Ø§ÙˆØ¬Ø¯ Ù†Ø§ØªØ¬ 15 Ã— 7
        3. Ø­Ù„ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø© Ø³ + 5 = 12
        """
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
        comparison_result = await gemini_service.compare_texts(
            reference_text,
            extraction_result.markdown_content
        )
        
        print(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {comparison_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ¯ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {comparison_result.similarity_percentage:.1f}%")
        print(f"ğŸ“Š Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©: {comparison_result.confidence_score:.1%}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ø®Øµ
        print(f"\nğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„:")
        print("-" * 40)
        print(comparison_result.summary)
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        print(f"\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
        print("-" * 40)
        print(comparison_result.recommendation)
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
        if comparison_result.major_differences:
            print(f"\nğŸ”„ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:")
            print("-" * 40)
            for i, diff in enumerate(comparison_result.major_differences[:5], 1):
                print(f"{i}. {diff}")
        
        # 3. Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ’¾ Ø§Ù„Ø®Ø·ÙˆØ© 3: Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        print("-" * 50)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_dir = f"test_results_{timestamp}"
        os.makedirs(results_dir, exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        extracted_text_path = os.path.join(results_dir, "extracted_text.txt")
        with open(extracted_text_path, 'w', encoding='utf-8') as f:
            f.write(extraction_result.markdown_content)
        print(f"ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬: {extracted_text_path}")
        
        # Ø­ÙØ¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù…
        if extraction_result.structured_analysis:
            analysis_path = os.path.join(results_dir, "structured_analysis.json")
            with open(analysis_path, 'w', encoding='utf-8') as f:
                json.dump(extraction_result.structured_analysis.model_dump(), f, ensure_ascii=False, indent=2)
            print(f"ğŸ§  Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø¸Ù…: {analysis_path}")
        
        # Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        comparison_path = os.path.join(results_dir, "comparison_results.json")
        with open(comparison_path, 'w', encoding='utf-8') as f:
            json.dump({
                "similarity_percentage": comparison_result.similarity_percentage,
                "confidence_score": comparison_result.confidence_score,
                "processing_time": comparison_result.processing_time,
                "summary": comparison_result.summary,
                "recommendation": comparison_result.recommendation,
                "major_differences": comparison_result.major_differences,
                "content_changes": comparison_result.content_changes,
                "statistics": {
                    "old_text_length": comparison_result.old_text_length,
                    "new_text_length": comparison_result.new_text_length,
                    "common_words_count": comparison_result.common_words_count,
                    "unique_old_words": comparison_result.unique_old_words,
                    "unique_new_words": comparison_result.unique_new_words
                }
            }, f, ensure_ascii=False, indent=2)
        print(f"ğŸ”„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {comparison_path}")
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„
        report_path = os.path.join(results_dir, "complete_report.md")
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"""# ØªÙ‚Ø±ÙŠØ± Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù€ OCR

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
- **Ø§Ù„ØªØ§Ø±ÙŠØ®**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **Ø§Ù„ØµÙˆØ±Ø©**: {image_path}
- **Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù**: {os.path.getsize(image_path)} Ø¨Ø§ÙŠØª

## Ù†ØªØ§Ø¦Ø¬ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ (LandingAI)
- **Ø§Ù„Ø­Ø§Ù„Ø©**: {'Ù†Ø¬Ø­' if extraction_result.success else 'ÙØ´Ù„'}
- **ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**: {extraction_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©
- **Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©**: {extraction_result.confidence_score:.1%}
- **Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª**: {extraction_result.text_elements}
- **Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡**: {extraction_result.total_chunks}

### Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
```
{extraction_result.markdown_content}
```

## Ù†ØªØ§Ø¦Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ (Gemini)
- **Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡**: {comparison_result.similarity_percentage:.1f}%
- **Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©**: {comparison_result.confidence_score:.1%}
- **ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**: {comparison_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©

### Ø§Ù„Ù…Ù„Ø®Øµ
{comparison_result.summary}

### Ø§Ù„ØªÙˆØµÙŠØ§Øª
{comparison_result.recommendation}

### Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
""")
            
            for i, diff in enumerate(comparison_result.major_differences, 1):
                f.write(f"{i}. {diff}\n")
        
        print(f"ğŸ“Š Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙƒØ§Ù…Ù„: {report_path}")
        
        print(f"\nğŸ‰ ØªÙ… Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {results_dir}")
        
        # 4. Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
        print("=" * 60)
        print(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {'Ù†Ø¬Ø­' if extraction_result.success else 'ÙØ´Ù„'}")
        print(f"âœ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {'Ù†Ø¬Ø­' if comparison_result else 'ÙØ´Ù„'}")
        print(f"ğŸ“ˆ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {comparison_result.similarity_percentage:.1f}%")
        print(f"ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {(extraction_result.confidence_score + comparison_result.confidence_score) / 2:.1%}")
        print(f"â±ï¸ Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {extraction_result.processing_time + comparison_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        
        return {
            "extraction_result": extraction_result,
            "comparison_result": comparison_result,
            "results_dir": results_dir
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}")
        logger.exception("Ø®Ø·Ø£ ÙÙŠ Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„")
        return None

async def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸ”¬ Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„Ù„Ù€ OCR Ù…Ø¹ Ø§Ù„ØµÙˆØ±Ø© 103.jpg")
    print("=" * 80)
    
    result = await test_real_ocr_workflow()
    
    if result:
        print("\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {result['results_dir']}")
    else:
        print("\nâŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    asyncio.run(main()) 