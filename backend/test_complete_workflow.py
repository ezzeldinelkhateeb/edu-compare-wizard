#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø´Ø§Ù…Ù„ Ù„Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙƒØ§Ù…Ù„
Complete Workflow Test
"""

import os
import sys
import json
import asyncio
from pathlib import Path
from datetime import datetime

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø³Ø§Ø± Ù„Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.landing_ai_service import LandingAIService
from app.services.gemini_service import GeminiService

async def test_complete_workflow():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙƒØ§Ù…Ù„"""
    
    # Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
    image_path = Path("../103.jpg")
    if not image_path.exists():
        print(f"âŒ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image_path.absolute()}")
        return False
    
    print(f"ğŸ–¼ï¸ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©: {image_path.absolute()}")
    
    try:
        # 1. Ø§Ø®ØªØ¨Ø§Ø± LandingAI Service
        print("\nğŸ“¡ Ø§Ø®ØªØ¨Ø§Ø± LandingAI Service...")
        landing_ai = LandingAIService()
        
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©
        with open(image_path, 'rb') as f:
            image_data = f.read()
        
        print(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©: {len(image_data)} bytes")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
        print("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©...")
        extraction_result = await landing_ai.extract_from_file(
            file_path=str(image_path.absolute())
        )
        
        if not extraction_result or not extraction_result.success:
            error_msg = extraction_result.error_message if extraction_result else "ÙØ´Ù„ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
            print(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† LandingAI: {error_msg}")
            return False
        
        print("âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù† LandingAI")
        print(f"ğŸ“„ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©: {len(extraction_result.markdown_content)}")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {extraction_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {extraction_result.total_chunks}")
        
        # Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© LandingAI
        landing_result_file = "landing_ai_result.json"
        result_dict = extraction_result.model_dump()
        with open(landing_result_file, 'w', encoding='utf-8') as f:
            json.dump(result_dict, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© LandingAI ÙÙŠ: {landing_result_file}")
        
        # Ø­ÙØ¸ Ù…Ù„Ù Markdown Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        markdown_file = "landing_ai_result.md"
        with open(markdown_file, 'w', encoding='utf-8') as f:
            f.write(extraction_result.markdown_content)
        print(f"ğŸ“ ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù Markdown ÙÙŠ: {markdown_file}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ØªÙØµÙŠÙ„ÙŠ
        report_content = f"""# ØªÙ‚Ø±ÙŠØ± Ø§Ø³ØªØ®Ø±Ø§Ø¬ LandingAI - 103.jpg

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
- **Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù**: {extraction_result.file_name}
- **Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù**: {len(image_data)} bytes
- **ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©**: {extraction_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©
- **Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬**: {'Ù†Ø¬Ø­' if extraction_result.success else 'ÙØ´Ù„'}

## Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±**: {extraction_result.total_chunks}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Øµ**: {extraction_result.text_elements}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„**: {extraction_result.table_elements}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„ØµÙˆØ±**: {extraction_result.image_elements}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†**: {extraction_result.title_elements}
- **Ù†Ù‚Ø§Ø· Ø§Ù„Ø«Ù‚Ø©**: {extraction_result.confidence_score:.2f}

## Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
{json.dumps(extraction_result.chunks_by_type, ensure_ascii=False, indent=2)}

## Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
{extraction_result.markdown_content}

---
*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙÙŠ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
        
        report_file = "landing_ai_report.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        print(f"ğŸ“‹ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙØµÙŠÙ„ÙŠ ÙÙŠ: {report_file}")
        
        # 2. Ø§Ø®ØªØ¨Ø§Ø± Gemini Service
        print("\nğŸ¤– Ø§Ø®ØªØ¨Ø§Ø± Gemini Service...")
        gemini = GeminiService()
        
        extracted_text = extraction_result.markdown_content
        if not extracted_text.strip():
            print("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù…Ø³ØªØ®Ø±Ø¬ Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡ Ø¥Ù„Ù‰ Gemini")
            return True  # LandingAI Ù†Ø¬Ø­ØŒ Ù„ÙƒÙ† Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ
        
        print(f"ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Gemini (Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ù: {len(extracted_text)})")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
        analysis_prompt = f"""
        ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† ØµÙˆØ±Ø©:
        
        Ø§Ù„Ù†Øµ:
        {extracted_text}
        
        ÙŠØ±Ø¬Ù‰ ØªÙ‚Ø¯ÙŠÙ…:
        1. Ù…Ù„Ø®Øµ Ù„Ù„Ù…Ø­ØªÙˆÙ‰
        2. Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
        3. Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù‡Ù…Ø©
        4. ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
        """
        
        gemini_result = await gemini.analyze_text(analysis_prompt)
        
        if not gemini_result:
            print("âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
            return False
        
        print("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
        
        # Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Gemini
        gemini_result_data = {
            "original_text": extracted_text,
            "analysis": gemini_result,
            "timestamp": datetime.now().isoformat(),
            "source_file": "103.jpg",
            "processing_time": extraction_result.processing_time,
            "extraction_stats": {
                "total_chunks": extraction_result.total_chunks,
                "confidence_score": extraction_result.confidence_score,
                "text_elements": extraction_result.text_elements
            }
        }
        
        gemini_result_file = "gemini_analysis_result.json"
        with open(gemini_result_file, 'w', encoding='utf-8') as f:
            json.dump(gemini_result_data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© Gemini ÙÙŠ: {gemini_result_file}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Markdown Ù„Ù„ØªØ­Ù„ÙŠÙ„
        analysis_markdown = f"""# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ - Gemini AI

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±
- **Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ØµÙ„ÙŠ**: 103.jpg
- **Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬**: LandingAI
- **ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ù„ÙŠÙ„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ÙˆÙ‚Øª Ù…Ø¹Ø§Ù„Ø¬Ø© LandingAI**: {extraction_result.processing_time:.2f} Ø«Ø§Ù†ÙŠØ©
- **Ù†Ù‚Ø§Ø· Ø§Ù„Ø«Ù‚Ø©**: {extraction_result.confidence_score:.2f}

## Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ±**: {extraction_result.total_chunks}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Øµ**: {extraction_result.text_elements}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„**: {extraction_result.table_elements}
- **Ø¹Ù†Ø§ØµØ± Ø§Ù„ØµÙˆØ±**: {extraction_result.image_elements}

## Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬
```
{extracted_text}
```

## ØªØ­Ù„ÙŠÙ„ Gemini AI
{gemini_result}

---
*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©*
"""
        
        analysis_markdown_file = "gemini_analysis_result.md"
        with open(analysis_markdown_file, 'w', encoding='utf-8') as f:
            f.write(analysis_markdown)
        print(f"ğŸ“ ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù ØªØ­Ù„ÙŠÙ„ Markdown ÙÙŠ: {analysis_markdown_file}")
        
        # 3. Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        print("\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù†Ø¬Ø§Ø­!")
        print("ğŸ“‹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙÙ†Ø´Ø£Ø©:")
        print(f"   - {landing_result_file}")
        print(f"   - {markdown_file}")
        print(f"   - {report_file}")
        print(f"   - {gemini_result_file}")
        print(f"   - {analysis_markdown_file}")
        
        print("\nğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print(f"   - LandingAI: âœ… Ø§Ø³ØªØ®Ø±Ø¬ {len(extracted_text)} Ø­Ø±Ù")
        print(f"   - Gemini: âœ… Ø­Ù„Ù„ Ø§Ù„Ù†Øµ ÙˆÙ‚Ø¯Ù… ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„")
        
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {e}")
        import traceback
        print(f"ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„: {traceback.format_exc()}")
        return False

async def test_services_health():
    """Ø§Ø®ØªØ¨Ø§Ø± ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª"""
    print("ğŸ¥ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª...")
    
    try:
        # Ø§Ø®ØªØ¨Ø§Ø± LandingAI
        landing_ai = LandingAIService()
        print("âœ… LandingAI Service: Ø¬Ø§Ù‡Ø²")
        
        # Ø§Ø®ØªØ¨Ø§Ø± Gemini
        gemini = GeminiService()
        print("âœ… Gemini Service: Ø¬Ø§Ù‡Ø²")
        
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙØ­Øµ Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {e}")
        return False

if __name__ == "__main__":
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ÙƒØ§Ù…Ù„...")
    print("=" * 50)
    
    async def main():
        # ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        if not await test_services_health():
            print("ğŸ’¥ ÙØ´Ù„ ÙÙŠ ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª")
            return
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„
        success = await test_complete_workflow()
        
        if success:
            print("\nğŸ‰ ØªÙ… Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        else:
            print("\nğŸ’¥ ÙØ´Ù„ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª")
    
    asyncio.run(main()) 