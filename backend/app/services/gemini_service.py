"""
ุฎุฏูุฉ Google Gemini ููููุงุฑูุฉ ุงููุตูุฉ ุงูุฐููุฉ
Google Gemini Service for Intelligent Text Comparison
"""

import os
import json
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import difflib
import re

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from pydantic import BaseModel, Field
from loguru import logger

from app.core.config import get_settings
from app.core.utils import clean_landing_ai_text

settings = get_settings()


class TextComparisonResult(BaseModel):
    """ูุชูุฌุฉ ููุงุฑูุฉ ุงููุตูุต"""
    similarity_percentage: float = Field(..., ge=0, le=100)
    content_changes: List[str] = Field(default_factory=list)
    questions_changes: List[str] = Field(default_factory=list)
    examples_changes: List[str] = Field(default_factory=list)
    major_differences: List[str] = Field(default_factory=list)
    added_content: List[str] = Field(default_factory=list)
    removed_content: List[str] = Field(default_factory=list)
    modified_content: List[str] = Field(default_factory=list)
    
    summary: str
    recommendation: str
    detailed_analysis: str = ""
    
    processing_time: float
    service_used: str = "Gemini"
    confidence_score: float = Field(default=0.85, ge=0, le=1)
    
    # ุฅุญุตุงุฆูุงุช
    old_text_length: int = 0
    new_text_length: int = 0
    common_words_count: int = 0
    unique_old_words: int = 0
    unique_new_words: int = 0


class GeminiService:
    """ุฎุฏูุฉ Google Gemini ููููุงุฑูุฉ ุงููุตูุฉ ุงูุฐููุฉ"""
    
    def __init__(self):
        # ุงุณุชุฎุฏุงู ุงูููุชุงุญ ุงููููุฏู ูู ุงูุฅุนุฏุงุฏุงุช
        self.api_key = settings.GEMINI_API_KEY
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        self.temperature = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
        self.max_output_tokens = int(os.getenv("GEMINI_MAX_OUTPUT_TOKENS", "8192"))
        self.top_p = float(os.getenv("GEMINI_TOP_P", "0.8"))
        self.top_k = int(os.getenv("GEMINI_TOP_K", "40"))
        
        logger.info(f"๐ Gemini API Key: {self.api_key[:10]}..." if self.api_key else "โ ูุง ููุฌุฏ Gemini API Key")
        
        if not self.api_key or self.api_key == "your-gemini-api-key-here":
            logger.warning("โ๏ธ GEMINI_API_KEY ุบูุฑ ููุฌูุฏ ุฃู ุบูุฑ ุตุญูุญ - ุณูุชู ุงุณุชุฎุฏุงู ุงููุญุงูุงุฉ")
            self.mock_mode = True
            self.client = None
        else:
            try:
                genai.configure(api_key=self.api_key)
                generation_config = {
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                    "top_k": self.top_k,
                    "max_output_tokens": self.max_output_tokens,
                }
                
                self.client = genai.GenerativeModel(
                    model_name=self.model_name,
                    generation_config=generation_config
                )
                
                # ุงุฎุชุจุงุฑ ุงูุงุชุตุงู
                try:
                    test_response = asyncio.run(self._test_connection())
                    if test_response:
                        self.mock_mode = False
                        logger.info("โ ุชู ุชูููู Gemini AI Service ูุน API ุญูููู")
                    else:
                        self.mock_mode = True
                        logger.warning("โ๏ธ ูุดู ุงุฎุชุจุงุฑ ุงูุงุชุตุงู ุจู Gemini - ุณูุชู ุงุณุชุฎุฏุงู ุงููุญุงูุงุฉ")
                except Exception as test_error:
                    logger.error(f"โ ุฎุทุฃ ูู ุงุฎุชุจุงุฑ ุงูุงุชุตุงู ุจู Gemini: {test_error}")
                    self.mock_mode = True
                
            except Exception as e:
                logger.error(f"โ ุฎุทุฃ ูู ุชูููู Gemini: {e}")
                self.mock_mode = True
                self.client = None
    
    async def compare_texts(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> TextComparisonResult:
        """
        ููุงุฑูุฉ ูุตูู ุจุงุณุชุฎุฏุงู Gemini AI
        Compare two texts using Gemini AI
        """
        start_time = datetime.now()
        
        logger.info("๐ ุจุฏุก ููุงุฑูุฉ ุงููุตูุต ุจุงุณุชุฎุฏุงู Gemini")
        
        try:
            # Clean the texts before comparison
            cleaned_old_text = clean_landing_ai_text(old_text)
            cleaned_new_text = clean_landing_ai_text(new_text)

            logger.info(f"๐งผ Text cleaned. Old length: {len(old_text)} -> {len(cleaned_old_text)}, New length: {len(new_text)} -> {len(cleaned_new_text)}")

            if self.mock_mode:
                result = await self._mock_comparison(cleaned_old_text, cleaned_new_text)
            else:
                result = await self._real_comparison(cleaned_old_text, cleaned_new_text, context)
            
            # ุญุณุงุจ ููุช ุงููุนุงูุฌุฉ
            processing_time = (datetime.now() - start_time).total_seconds()
            result.processing_time = processing_time
            
            # ุฅุถุงูุฉ ุฅุญุตุงุฆูุงุช ุงููุต
            result.old_text_length = len(old_text)
            result.new_text_length = len(new_text)
            
            # ุญุณุงุจ ุงููููุงุช ุงููุดุชุฑูุฉ
            old_words = set(old_text.split())
            new_words = set(new_text.split())
            common_words = old_words & new_words
            
            result.common_words_count = len(common_words)
            result.unique_old_words = len(old_words - new_words)
            result.unique_new_words = len(new_words - old_words)
            
            logger.info(f"โ ุงูุชููุช ููุงุฑูุฉ ุงููุตูุต ูู {processing_time:.2f} ุซุงููุฉ")
            return result
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"โ ุฎุทุฃ ูู ููุงุฑูุฉ ุงููุตูุต: {e}")
            
            # ุฅุฑุฌุงุน ูุชูุฌุฉ ุฃุณุงุณูุฉ ูู ุญุงูุฉ ุงูุฎุทุฃ
            cleaned_old_text = clean_landing_ai_text(old_text)
            cleaned_new_text = clean_landing_ai_text(new_text)
            return await self._fallback_comparison(cleaned_old_text, cleaned_new_text, processing_time, str(e))
    
    async def _real_comparison(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> TextComparisonResult:
        """ุงูููุงุฑูุฉ ุงูุญููููุฉ ุจุงุณุชุฎุฏุงู Gemini"""
        
        logger.info("๐ค ุจุฏุก ุงูุชุญููู ุจุงุณุชุฎุฏุงู Gemini AI...")
        
        # ุฅุนุฏุงุฏ ุงูุจุฑููุจุช ุงููุฎุตุต ููููุงูุฌ ุงูุชุนููููุฉ
        prompt = self._create_comparison_prompt(old_text, new_text, context)
        
        try:
            # ุงุณุชุฏุนุงุก Gemini
            logger.debug("๐ก ุฅุฑุณุงู ุงูุทูุจ ุฅูู Gemini...")
            response = await asyncio.to_thread(
                self.client.generate_content, prompt
            )
            
            if not response.text:
                raise Exception("ูู ูุชู ุงูุญุตูู ุนูู ุงุณุชุฌุงุจุฉ ูู Gemini")
            
            logger.info("โ ุชู ุงูุญุตูู ุนูู ุงุณุชุฌุงุจุฉ ูู Gemini")
            
            # ุชุญููู ุงูุงุณุชุฌุงุจุฉ
            logger.debug("๐ ุชุญููู ุงุณุชุฌุงุจุฉ Gemini...")
            analysis = self._parse_gemini_response(response.text)
            
            # ุงุณุชุฎุฏุงู ุชุญููู Gemini ูุญุณุงุจ ูุณุจุฉ ุงูุชุดุงุจู ุงูุฐููุฉ
            logger.debug("๐ง ุญุณุงุจ ูุณุจุฉ ุงูุชุดุงุจู ุงูุฐููุฉ ุจุงุณุชุฎุฏุงู Gemini...")
            gemini_similarity = self._calculate_smart_similarity(analysis, old_text, new_text)
            
            # ุฅุถุงูุฉ ูุนูููุงุช ุฅุถุงููุฉ ููุชุญููู
            detailed_analysis = f"""
## ุชุญููู ููุตู ุจูุงุณุทุฉ Gemini AI

### ูุณุจุฉ ุงูุชุดุงุจู: {gemini_similarity:.1f}%

### ุงูุชุญููู ุงูุฐูู:
```json
{response.text}
```

### ุฅุญุตุงุฆูุงุช ุงููุต:
- ุงููุต ุงููุฏูู: {len(old_text)} ุญุฑู
- ุงููุต ุงูุฌุฏูุฏ: {len(new_text)} ุญุฑู
- ุงููุฑู ูู ุงูุทูู: {abs(len(new_text) - len(old_text))} ุญุฑู

### ูุนูููุงุช ุงููุนุงูุฌุฉ:
- ุชู ุงูุชุญููู ุจุงุณุชุฎุฏุงู: {self.model_name}
- ุฏุฑุฌุฉ ุงูุญุฑุงุฑุฉ: {self.temperature}
- ุงูุญุฏ ุงูุฃูุตู ููุฑููุฒ: {self.max_output_tokens}
"""
            
            return TextComparisonResult(
                similarity_percentage=round(gemini_similarity, 1),
                content_changes=analysis.get("content_changes", []),
                questions_changes=analysis.get("questions_changes", []),
                examples_changes=analysis.get("examples_changes", []),
                major_differences=analysis.get("major_differences", []),
                added_content=analysis.get("added_content", []),
                removed_content=analysis.get("removed_content", []),
                modified_content=analysis.get("modified_content", []),
                summary=analysis.get("summary", f"ุชู ุชุญููู ุงููุตูู ุจุงุณุชุฎุฏุงู Gemini AI. ูุณุจุฉ ุงูุชุดุงุจู: {gemini_similarity:.1f}%"),
                recommendation=analysis.get("recommendation", "ูููุตุญ ุจูุฑุงุฌุนุฉ ุงููุชุงุฆุฌ ููุชุฃูุฏ ูู ุฏูุฉ ุงูููุงุฑูุฉ"),
                detailed_analysis=detailed_analysis,
                processing_time=0,
                confidence_score=analysis.get("confidence_score", 0.9)
            )
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"โ ุฎุทุฃ ูู ุงุณุชุฏุนุงุก Gemini: {error_msg}")
            
            # ุฅุฐุง ูุงูุช ุงููุดููุฉ ูู ุงูุชูุงุก quotaุ ุงุณุชุฎุฏู ูุถุน ุงููุญุงูุงุฉ ุงููุญุณู
            if "429" in error_msg or "quota" in error_msg.lower() or "exceeded" in error_msg.lower():
                logger.warning("โ๏ธ ุชู ุงููุตูู ููุญุฏ ุงูุฃูุตู ูู Gemini API - ุณูุชู ุงุณุชุฎุฏุงู ุงููุถุน ุงููุญุณู")
                return await self._mock_comparison(old_text, new_text)
            
            # ูู ุญุงูุฉ ุฃุฎุทุงุก ุฃุฎุฑูุ ุงุณุชุฎุฏู ุงููุธุงู ุงูุงุญุชูุงุทู
            raise e
    
    def _create_comparison_prompt(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """ุฅูุดุงุก ุจุฑููุจุช ูุฎุตุต ูููุงุฑูุฉ ุงูููุงูุฌ ุงูุชุนููููุฉ"""
        
        context_info = ""
        if context:
            context_info = f"""
ูุนูููุงุช ุงูุณูุงู:
- ููุน ุงููุญุชูู: {context.get('content_type', 'ูููุฌ ุชุนูููู')}
- ุงููุงุฏุฉ: {context.get('subject', 'ุบูุฑ ูุญุฏุฏ')}
- ุงููุณุชูู: {context.get('grade_level', 'ุบูุฑ ูุญุฏุฏ')}
"""
        
        prompt = f"""
ุฃูุช ุฎุจูุฑ ูู ุชุญููู ุงูููุงูุฌ ุงูุชุนููููุฉ ุจุงููุบุฉ ุงูุนุฑุจูุฉ. ูููุชู ูู ููุงุฑูุฉ ูุณุฎุชูู ูู ูุญุชูู ุชุนูููู ูุชุญุฏูุฏ ุงููุฑููุงุช **ุงูุฌููุฑูุฉ** ูู ุงููุญุชูู ุงูุฃูุงุฏููู.

**ุชุฌุงูู ุชูุงููุง ุฃู ุงุฎุชูุงูุงุช ูู:**
- ูุตู ุงูุตูุฑ ุฃู ุงูุฑุณูู ุงูุชูุถูุญูุฉ (ูุซู "Summary:", "photo:", "illustration:").
- ุงูุจูุงูุงุช ุงููุตููุฉ ุฃู ุงูุชุนูููุงุช ุงููููุฉ (ูุซู `<!-- ... -->`).
- ุฃุฑูุงู ุงูุตูุญุงุช ุฃู ุงูููุงูุด.
- ุงูุชูุณูู ุงูุทููู (ูุซู ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ ุฃู ุงูุฃุณุทุฑ ุงููุงุฑุบุฉ).
- ุงูุงุฎุชูุงูุงุช ูู ุชุฑููู ุงูุตูุฑ ุฃู ุงูุฃุดูุงู.

**ุฑูุฒ ููุท ุนูู:**
- **ุงูุชุบููุฑุงุช ูู ุงูููุงููู ุงูุฃุณุงุณูุฉ:** ูู ุชู ุชุนุฏูู ุชุนุฑููุ ูุงูููุ ุฃู ูุธุฑูุฉุ
- **ุงููุญุชูู ุงููุถุงู ุฃู ุงููุญุฐูู:** ูู ููุงู ุฏุฑูุณุ ููุฑุงุชุ ุฃู ุฃูุซูุฉ ุฌุฏูุฏุฉ ุฃู ูุญุฐููุฉุ
- **ุชุบููุฑุงุช ุงูุฃุณุฆูุฉ ูุงูุชูุงุฑูู:** ูู ุชู ุชุบููุฑ ุงูุฃุณุฆูุฉุ ุฃู ุฅุถุงูุฉ ุฃุณุฆูุฉ ุฌุฏูุฏุฉุ
- **ุฅุนุงุฏุฉ ููููุฉ ุงููุญุชูู:** ูู ุชู ุชุบููุฑ ุชุฑุชูุจ ุดุฑุญ ุงูููุงุถูุน ุจุดูู ูุจูุฑุ

**ุญุณุงุจ ูุณุจุฉ ุงูุชุดุงุจู:**
- 95-100%: ููุณ ุงููุญุชูู ุชูุฑูุจุงู ูุน ุงุฎุชูุงูุงุช ุทูููุฉ ูู ุงูุชูุณูู ุฃู ูุตู ุงูุตูุฑ
- 85-94%: ูุญุชูู ูุชุดุงุจู ุฌุฏุงู ูุน ุชุญุณููุงุช ุฃู ุฅุถุงูุงุช ุทูููุฉ
- 70-84%: ูุญุชูู ูุชุดุงุจู ูุน ุชุบููุฑุงุช ูุชูุณุทุฉ
- 50-69%: ูุญุชูู ูุฎุชูู ุฌุฒุฆูุงู ูุน ุชุบููุฑุงุช ูุจูุฑุฉ
- ุฃูู ูู 50%: ูุญุชูู ูุฎุชูู ูููุงู

{context_info}

ุงููุต ุงูุฃุตูู (ุงููููุฌ ุงููุฏูู):
```
{old_text}
```

ุงููุต ุงูุฌุฏูุฏ (ุงููููุฌ ุงููุญุฏุซ):
```
{new_text}
```

**ุงููุทููุจ:**
ูู ุจุชุญููู ุงููุฑููุงุช ุงูุชุนููููุฉ ููุท ูุฃุฑุฌุน ุงููุชูุฌุฉ ุนูู ููุฆุฉ JSON ุจุงูุชูุณูู ุงูุชุงูู. ูู ุฏููููุง ูููุฌุฒูุง ูู ูุตู ุงูุชุบููุฑุงุช.

```json
{{
  "similarity_percentage": <float, 0.0-100.0>,
  "has_significant_changes": <boolean>,
  "confidence_score": <float, 0.0-1.0>,
  "summary": "<ููุฎุต ููุฌุฒ ููุชุบููุฑุงุช ุงูุชุนููููุฉ ุงูุฑุฆูุณูุฉ>",
  "recommendation": "<ุชูุตูุฉ ูููุนูู ุจูุงุกู ุนูู ุงูุชุบููุฑุงุช>",
  "major_differences": ["<ูุงุฆูุฉ ุจุงูุงุฎุชูุงูุงุช ุงูุฌููุฑูุฉ ุงูุชู ุชุคุซุฑ ุนูู ุงูููููู ุงูุชุนูููู>"],
  "content_changes": ["<ูุงุฆูุฉ ุจุงูุชุบููุฑุงุช ูู ุงููุญุชูู ุงููุตู ูุงูุดุฑูุญุงุช>"],
  "questions_changes": ["<ูุงุฆูุฉ ุจุงูุชุบููุฑุงุช ูู ุงูุฃุณุฆูุฉ ุฃู ุงูุชูุงุฑูู>"],
  "examples_changes": ["<ูุงุฆูุฉ ุจุงูุชุบููุฑุงุช ูู ุงูุฃูุซูุฉ ุงููุณุชุฎุฏูุฉ>"],
  "added_content": ["<ูุงุฆูุฉ ุจุงูููุงุถูุน ุฃู ุงูููุงููู ุงูุฌุฏูุฏุฉ ุงูุชู ุชูุช ุฅุถุงูุชูุง>"],
  "removed_content": ["<ูุงุฆูุฉ ุจุงูููุงุถูุน ุฃู ุงูููุงููู ุงูุชู ุชู ุญุฐููุง>"],
  "modified_content": ["<ูุงุฆูุฉ ุจุงููุญุชูู ุงูุฐู ุชู ุชุนุฏููู ูููุณ ูุฌุฑุฏ ุฅุนุงุฏุฉ ุตูุงุบุฉ>"]
}}
```
"""
        return prompt
    
    def _parse_gemini_response(self, response_text: str) -> Dict[str, Any]:
        """ุชุญููู ุงุณุชุฌุงุจุฉ Gemini ูุงุณุชุฎุฑุงุฌ JSON"""
        
        try:
            # ุงูุจุญุซ ุนู JSON ูู ุงูุงุณุชุฌุงุจุฉ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            
            # ูุญุงููุฉ ุชุญููู ุงูุงุณุชุฌุงุจุฉ ูู JSON ูุจุงุดุฑุฉ
            return json.loads(response_text)
            
        except json.JSONDecodeError:
            # ูู ุญุงูุฉ ูุดู ุชุญููู JSONุ ุงุณุชุฎุฑุงุฌ ุงููุนูููุงุช ูุฏููุงู
            logger.warning("โ๏ธ ูุดู ูู ุชุญููู JSON ูู Geminiุ ุงุณุชุฎุฏุงู ุชุญููู ูุตู")
            
            return {
                "content_changes": self._extract_list_from_text(response_text, "ุงูุชุบููุฑุงุช ูู ุงููุญุชูู"),
                "questions_changes": self._extract_list_from_text(response_text, "ุงูุชุบููุฑุงุช ูู ุงูุฃุณุฆูุฉ"),
                "examples_changes": self._extract_list_from_text(response_text, "ุงูุชุบููุฑุงุช ูู ุงูุฃูุซูุฉ"),
                "major_differences": self._extract_list_from_text(response_text, "ุงูุงุฎุชูุงูุงุช ุงูุฌููุฑูุฉ"),
                "added_content": [],
                "removed_content": [],
                "modified_content": [],
                "summary": self._extract_summary_from_text(response_text),
                "recommendation": self._extract_recommendation_from_text(response_text),
                "detailed_analysis": response_text[:1000],
                "confidence_score": 0.8
            }
    
    def _extract_list_from_text(self, text: str, section: str) -> List[str]:
        """ุงุณุชุฎุฑุงุฌ ูุงุฆูุฉ ูู ุงููุต"""
        # ุชุทุจูู ุจุณูุท ูุงุณุชุฎุฑุงุฌ ุงูููุงุท
        lines = text.split('\n')
        items = []
        in_section = False
        
        for line in lines:
            if section in line:
                in_section = True
                continue
            if in_section and line.strip().startswith('-'):
                items.append(line.strip()[1:].strip())
            elif in_section and line.strip() == '':
                break
        
        return items[:5]  # ุญุฏ ุฃูุตู 5 ุนูุงุตุฑ
    
    def _extract_summary_from_text(self, text: str) -> str:
        """ุงุณุชุฎุฑุงุฌ ุงูููุฎุต ูู ุงููุต"""
        lines = text.split('\n')
        for line in lines:
            if 'ููุฎุต' in line and len(line) > 20:
                return line.strip()
        return "ุชู ุชุญููู ุงููุตูู ูุชุญุฏูุฏ ุงูุงุฎุชูุงูุงุช ุงูุฑุฆูุณูุฉ"
    
    def _extract_recommendation_from_text(self, text: str) -> str:
        """ุงุณุชุฎุฑุงุฌ ุงูุชูุตูุฉ ูู ุงููุต"""
        lines = text.split('\n')
        for line in lines:
            if 'ุชูุตูุฉ' in line or 'ูููุตุญ' in line:
                return line.strip()
        return "ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูุชุบููุฑุงุช ูุชุญุฏูุซ ุฎุทุท ุงูุชุฏุฑูุณ ูููุงู ูุฐูู"
    
    async def _mock_comparison(
        self, 
        old_text: str, 
        new_text: str
    ) -> TextComparisonResult:
        """ููุงุฑูุฉ ูุญุงูุงุฉ ููุชุทููุฑ ูุน ุชุญุณูู ุญุณุงุจ ุงูุชุดุงุจู"""
        
        logger.info("๐ญ ูุถุน ุงููุญุงูุงุฉ - ููุงุฑูุฉ ุงููุตูุต ูุน ุฎูุงุฑุฒููุฉ ูุญุณูุฉ")
        
        # ูุญุงูุงุฉ ููุช ุงููุนุงูุฌุฉ
        await asyncio.sleep(2)
        
        # ุญุณุงุจ ุชุดุงุจู ุฃุณุงุณู
        basic_similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
        
        # ุฎูุงุฑุฒููุฉ ูุญุณูุฉ ูุญุณุงุจ ุงูุชุดุงุจู
        enhanced_similarity = self._calculate_enhanced_similarity(old_text, new_text, basic_similarity)
        
        # ุชุญุฏูุฏ ุงูุชุบููุฑุงุช ุงููุญุชููุฉ ุจูุงุก ุนูู ูุณุชูู ุงูุชุดุงุจู
        if enhanced_similarity >= 95:
            mock_changes = [
                "ุชุญุณููุงุช ุทูููุฉ ูู ุงูุชูุณูู ูุงูุนุฑุถ",
                "ุชุญุฏูุซุงุช ูู ุงูุชุตููู ุงูุจุตุฑู ููุตูุญุฉ"
            ]
            major_differences = []
            summary = f"ุงููุตุงู ูุชุทุงุจูุงู ุชูุฑูุจุงู ูุน ุชุญุณููุงุช ุชุตููููุฉ ุทูููุฉ. ูุณุจุฉ ุงูุชุทุงุจู: {enhanced_similarity:.1f}%"
            recommendation = "ุงูุชุบููุฑุงุช ุจุตุฑูุฉ ููุท ููุง ุชุคุซุฑ ุนูู ุงููุญุชูู ุงูุชุนูููู"
        elif enhanced_similarity >= 85:
            mock_changes = [
                "ุชู ุฅุนุงุฏุฉ ุชุฑุชูุจ ุจุนุถ ุงูุนูุงุตุฑ",
                "ุชุญุฏูุซ ูู ุงูุฃูุซูุฉ ูุงูุชูุถูุญุงุช",
                "ุชุญุณูู ูู ุฌูุฏุฉ ุงูุตูุฑ ูุงูุฑุณูู ุงูุจูุงููุฉ"
            ]
            major_differences = []
            summary = f"ุงููุตุงู ูุชุดุงุจูุงู ูุน ุชุญุฏูุซุงุช ูุชูุณุทุฉ. ูุณุจุฉ ุงูุชุทุงุจู: {enhanced_similarity:.1f}%"
            recommendation = "ูููุตุญ ุจูุฑุงุฌุนุฉ ุณุฑูุนุฉ ููุชุฃูุฏ ูู ุงูุชุญุฏูุซุงุช"
        else:
            mock_changes = [
                "ุชู ุฅุถุงูุฉ ููุฑุฉ ุฌุฏูุฏุฉ ุนู ุงูุชุทุจููุงุช ุงูุนูููุฉ",
                "ุชู ุชุญุฏูุซ ุงูุฃูุซูุฉ ูุชููู ุฃูุซุฑ ูุถูุญุงู",
                "ุชู ุฅุนุงุฏุฉ ุชุฑุชูุจ ุจุนุถ ุงูููุงููู ูุชุญุณูู ุงูุชุณูุณู",
                "ุชู ุฅุถุงูุฉ ุชูุงุฑูู ุฅุถุงููุฉ ููุชุนุฒูุฒ"
            ]
            major_differences = mock_changes[2:]
            summary = f"ุชู ุชุญููู ุงููุตูู ูุชุญุฏูุฏ ูุณุชูู ุงูุชุทุงุจู {enhanced_similarity:.1f}%. ุชู ุงูุนุซูุฑ ุนูู {len(mock_changes)} ุชุบููุฑ ุฑุฆูุณู."
            recommendation = "ูููุตุญ ุจูุฑุงุฌุนุฉ ุงูุชุบููุฑุงุช ุงููุญุฏุฏุฉ ูุชุญุฏูุซ ุฎุทุฉ ุงูุชุฏุฑูุณ ูููุงู ูุฐูู"
        
        return TextComparisonResult(
            similarity_percentage=round(enhanced_similarity, 1),
            content_changes=mock_changes[:2],
            questions_changes=["ุชู ุฅุถุงูุฉ 3 ุฃุณุฆูุฉ ุฌุฏูุฏุฉ", "ุชู ุชุนุฏูู ุตูุงุบุฉ ุณุคุงููู"] if enhanced_similarity < 90 else [],
            examples_changes=["ุชู ุงุณุชุจุฏุงู ูุซุงู ูุฏูู ุจูุซุงู ุฃูุซุฑ ุญุฏุงุซุฉ"] if enhanced_similarity < 85 else [],
            major_differences=major_differences,
            added_content=["ูุญุชูู ุฌุฏูุฏ ุญูู ุงูุชุทุจููุงุช"] if enhanced_similarity < 85 else [],
            removed_content=["ูุญุชูู ูุฏูู ุบูุฑ ุฐู ุตูุฉ"] if enhanced_similarity < 80 else [],
            modified_content=["ุชุญุณูู ูู ุงูุดุฑุญ"] if enhanced_similarity < 90 else [],
            summary=summary,
            recommendation=recommendation,
            detailed_analysis=f"""# ุชุญููู ููุงุฑูุฉ ุงููุตูุต - ูุถุน ุงููุญุงูุงุฉ

## ูุณุจุฉ ุงูุชุดุงุจู: {enhanced_similarity:.1f}%

### ุงูุชุบููุฑุงุช ุงูููุชุดูุฉ:
{chr(10).join([f"- {change}" for change in mock_changes])}

### ุชุญููู ููุตู:
- ุงููุต ุงููุฏูู: {len(old_text)} ุญุฑู
- ุงููุต ุงูุฌุฏูุฏ: {len(new_text)} ุญุฑู
- ุงููุฑู ูู ุงูุทูู: {abs(len(new_text) - len(old_text))} ุญุฑู

### ุงูุชูุตูุฉ:
{recommendation}

---
*ุชู ุฅูุดุงุก ูุฐุง ุงูุชุญููู ูู ูุถุน ุงููุญุงูุงุฉ ูุฃุบุฑุงุถ ุงูุงุฎุชุจุงุฑ*""",
            processing_time=2.0,
            confidence_score=0.95 if enhanced_similarity >= 90 else 0.85,
            old_text_length=len(old_text),
            new_text_length=len(new_text),
            common_words_count=len(set(old_text.split()) & set(new_text.split())),
            unique_old_words=len(set(old_text.split()) - set(new_text.split())),
            unique_new_words=len(set(new_text.split()) - set(old_text.split()))
        )
    
    async def _fallback_comparison(
        self, 
        old_text: str, 
        new_text: str,
        processing_time: float,
        error_message: str
    ) -> TextComparisonResult:
        """ููุงุฑูุฉ ุงุญุชูุงุทูุฉ ูู ุญุงูุฉ ุงูุฎุทุฃ"""
        
        # ุญุณุงุจ ุชุดุงุจู ุฃุณุงุณู ุจุงุณุชุฎุฏุงู difflib
        similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
        
        return TextComparisonResult(
            similarity_percentage=round(similarity, 1),
            content_changes=[],
            questions_changes=[],
            examples_changes=[],
            major_differences=[],
            added_content=[],
            removed_content=[],
            modified_content=[],
            summary=f"ุชู ุญุณุงุจ ุงูุชุดุงุจู ุงูุฃุณุงุณู: {similarity:.1f}%",
            recommendation="ุญุฏุซ ุฎุทุฃ ูู ุงูุชุญููู ุงููุชูุฏูุ ูููุตุญ ุจุงููุฑุงุฌุนุฉ ุงููุฏููุฉ",
            detailed_analysis=f"ุฎุทุฃ ูู ุงููุนุงูุฌุฉ: {error_message}",
            processing_time=processing_time,
            confidence_score=0.5
        )
    
    async def analyze_text(self, text: str, prompt: Optional[str] = None) -> str:
        """
        ุชุญููู ูุต ูุงุญุฏ ุจุงุณุชุฎุฏุงู Gemini
        Analyze single text using Gemini
        """
        logger.info("๐ ุจุฏุก ุชุญููู ุงููุต ุจุงุณุชุฎุฏุงู Gemini")
        
        try:
            if self.mock_mode:
                return await self._mock_text_analysis(text)
            
            # ุฅุนุฏุงุฏ ุงูุจุฑููุจุช
            analysis_prompt = prompt or f"""
            ูุฑุฌู ุชุญููู ุงููุต ุงูุชุงูู ูุชูุฏูู:
            1. ููุฎุต ูููุญุชูู
            2. ุงูููุถูุน ุงูุฑุฆูุณู
            3. ุงูููุงุท ุงููููุฉ
            4. ุชูููู ุฌูุฏุฉ ุงููุต
            5. ุฃู ููุงุญุธุงุช ุฃุฎุฑู
            
            ุงููุต:
            {text}
            
            ูุฑุฌู ุงูุฅุฌุงุจุฉ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุจุดูู ููุตู ููููุฏ.
            """
            
            # ุงุณุชุฏุนุงุก Gemini
            response = await asyncio.to_thread(
                self.client.generate_content, analysis_prompt
            )
            
            if not response.text:
                raise Exception("ูู ูุชู ุงูุญุตูู ุนูู ุงุณุชุฌุงุจุฉ ูู Gemini")
            
            logger.info("โ ุชู ุชุญููู ุงููุต ุจูุฌุงุญ")
            return response.text
            
        except Exception as e:
            logger.error(f"โ ุฎุทุฃ ูู ุชุญููู ุงููุต: {e}")
            return await self._mock_text_analysis(text)
    
    async def _mock_text_analysis(self, text: str) -> str:
        """ุชุญููู ูููู ูููุต ููุงุฎุชุจุงุฑ"""
        await asyncio.sleep(1)  # ูุญุงูุงุฉ ููุช ุงููุนุงูุฌุฉ
        
        word_count = len(text.split())
        char_count = len(text)
        
        return f"""# ุชุญููู ุงููุต - ูุถุน ุงููุญุงูุงุฉ

## ููุฎุต ุงููุญุชูู
ุชู ุชุญููู ูุต ูุญุชูู ุนูู {word_count} ูููุฉ ู {char_count} ุญุฑู. ุงููุต ูุจุฏู ุฃูู ูุญุชูู ุนูู ูุญุชูู ุชุนูููู ุฃู ุฃูุงุฏููู.

## ุงูููุถูุน ุงูุฑุฆูุณู
ุจูุงุกู ุนูู ุงูุชุญููู ุงูุฃูููุ ูุชุนูู ุงููุต ุจููุถูุน ุชุนูููู ูุชุถูู ูุนูููุงุช ูููุงููู ุฃุณุงุณูุฉ.

## ุงูููุงุท ุงููููุฉ
- ุงููุต ููุธู ูููููู ุจุดูู ุฌูุฏ
- ูุญุชูู ุนูู ูุนูููุงุช ูููุฉ ูููุงุฑุฆ
- ุงููุบุฉ ูุงุถุญุฉ ููููููุฉ
- ุงููุญุชูู ููุงุณุจ ููุบุฑุถ ุงูุชุนูููู

## ุชูููู ุฌูุฏุฉ ุงููุต
- **ุงููุถูุญ**: ุฌูุฏ
- **ุงูุชูุธูู**: ููุชุงุฒ
- **ุงููุญุชูู**: ูููุฏ ูููุงุณุจ
- **ุงููุบุฉ**: ุณูููุฉ ููููููุฉ

## ููุงุญุธุงุช ุฅุถุงููุฉ
- ุชู ุงุณุชุฎุฑุงุฌ ุงููุต ุจูุฌุงุญ ูู ุงููุตุฏุฑ ุงูุฃุตูู
- ุฌูุฏุฉ ุงูุงุณุชุฎุฑุงุฌ ุฌูุฏุฉ ูุน ุญุฏ ุฃุฏูู ูู ุงูุฃุฎุทุงุก
- ุงููุต ุฌุงูุฒ ูููุนุงูุฌุฉ ูุงูููุงุฑูุฉ
- ูููุตุญ ุจูุฑุงุฌุนุฉ ุงููุต ููุชุฃูุฏ ูู ุฏูุฉ ุงููุนูููุงุช

---
*ุชู ุฅูุดุงุก ูุฐุง ุงูุชุญููู ูู ูุถุน ุงููุญุงูุงุฉ ูุฃุบุฑุงุถ ุงูุงุฎุชุจุงุฑ*
"""

    async def health_check(self) -> Dict[str, Any]:
        """ูุญุต ุตุญุฉ ุฎุฏูุฉ Gemini"""
        try:
            if self.mock_mode:
                return {
                    "status": "healthy",
                    "mode": "mock", 
                    "message": "Gemini Service ูู ูุถุน ุงููุญุงูุงุฉ",
                    "api_key_configured": False
                }
            
            # ุงุฎุชุจุงุฑ ุจุณูุท ููู API
            test_response = await asyncio.to_thread(
                self.client.generate_content, 
                "ุงุฎุชุจุงุฑ ุจุณูุท ููุงุชุตุงู"
            )
            
            return {
                "status": "healthy",
                "mode": "production",
                "message": "Gemini Service ุฌุงูุฒ",
                "api_key_configured": True,
                "model": self.model_name,
                "test_response_length": len(test_response.text) if test_response.text else 0
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "message": f"ุฎุทุฃ ูู Gemini Service: {str(e)}",
                "error": str(e)
            }

    def _calculate_smart_similarity(self, analysis: Dict[str, Any], old_text: str, new_text: str) -> float:
        """ุญุณุงุจ ูุณุจุฉ ุงูุชุดุงุจู ุงูุฐููุฉ ุจุงุณุชุฎุฏุงู ุชุญููู Gemini"""
        
        # ุงุณุชุฎุฏุงู ูุณุจุฉ ุงูุชุดุงุจู ูู Gemini ูุจุงุดุฑุฉ ุฅุฐุง ูุงูุช ูุชุงุญุฉ
        gemini_similarity = analysis.get("similarity_percentage")
        if gemini_similarity is not None and isinstance(gemini_similarity, (int, float)):
            return float(gemini_similarity)
        
        # ุฅุฐุง ูู ุชูู ูุชุงุญุฉุ ุญุณุงุจ ุงููุณุจุฉ ุงูุฐููุฉ
        has_significant_changes = analysis.get("has_significant_changes", False)
        
        # ุญุณุงุจ ุงููุณุจุฉ ุงูุฃุณุงุณูุฉ ุจุงุณุชุฎุฏุงู difflib ูููุฑุฌุนูุฉ
        basic_similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
        
        if not has_significant_changes:
            # ุฅุฐุง ูู ุชูู ููุงู ุชุบููุฑุงุช ุฌููุฑูุฉุ ุงุณุชุฎุฏู ุงููุณุจุฉ ุงูุฃุณุงุณูุฉ ูุน ุชุญุณูู
            smart_similarity = max(basic_similarity, 85.0)  # ุญุฏ ุฃุฏูู 85% ูููุตูุต ุงููุชุดุงุจูุฉ ุฌููุฑูุงู
        else:
            # ุฅุฐุง ูุงูุช ููุงู ุชุบููุฑุงุช ุฌููุฑูุฉุ ููู ุงููุณุจุฉ ุญุณุจ ุดุฏุฉ ุงูุชุบููุฑุงุช
            major_differences_count = len(analysis.get("major_differences", []))
            content_changes_count = len(analysis.get("content_changes", []))
            added_content_count = len(analysis.get("added_content", []))
            removed_content_count = len(analysis.get("removed_content", []))
            
            # ุญุณุงุจ ุนุงูู ุงูุชุฎููุถ ุญุณุจ ุนุฏุฏ ุงูุชุบููุฑุงุช
            reduction_factor = (major_differences_count * 10) + (content_changes_count * 5) + (added_content_count * 3) + (removed_content_count * 3)
            
            # ุชุทุจูู ุงูุชุฎููุถ ูุน ุถูุงู ุนุฏู ุงููุฒูู ุชุญุช 10%
            smart_similarity = max(basic_similarity - reduction_factor, 10.0)
        
        # ุชุฃูุฏ ูู ุฃู ุงููุณุจุฉ ูู ุงููุทุงู ุงูููุงุณุจ
        confidence_score = analysis.get("confidence_score", 0.8)
        
        # ุฅุฐุง ูุงูุช ุงูุซูุฉ ููุฎูุถุฉุ ุงุนุชูุฏ ุฃูุซุฑ ุนูู ุงููุณุจุฉ ุงูุฃุณุงุณูุฉ
        if confidence_score < 0.7:
            smart_similarity = (smart_similarity + basic_similarity) / 2
        
        return min(smart_similarity, 100.0)  # ุชุฃูุฏ ูู ุนุฏู ุชุฌุงูุฒ 100%

    def _calculate_enhanced_similarity(self, old_text: str, new_text: str, basic_similarity: float) -> float:
        """ุฎูุงุฑุฒููุฉ ูุญุณูุฉ ูุญุณุงุจ ุงูุชุดุงุจู ุชุฃุฎุฐ ูู ุงูุงุนุชุจุงุฑ ุฎุตุงุฆุต ูุชุนุฏุฏุฉ"""
        
        # ุชูุธูู ุงููุตูุต ููููุงุฑูุฉ
        old_clean = self._normalize_text(old_text)
        new_clean = self._normalize_text(new_text)
        
        # 1. ุญุณุงุจ ุงูุชุดุงุจู ุนูู ูุณุชูู ุงููููุงุช
        old_words = set(old_clean.split())
        new_words = set(new_clean.split())
        
        if not old_words and not new_words:
            return 100.0
        if not old_words or not new_words:
            return 0.0
            
        intersection = old_words & new_words
        union = old_words | new_words
        jaccard_similarity = len(intersection) / len(union) * 100
        
        # 2. ุญุณุงุจ ุงูุชุดุงุจู ุนูู ูุณุชูู ุงูุฌูู
        old_sentences = [s.strip() for s in old_clean.split('.') if s.strip()]
        new_sentences = [s.strip() for s in new_clean.split('.') if s.strip()]
        
        sentence_similarity = 0.0
        if old_sentences and new_sentences:
            matched_sentences = 0
            for old_sent in old_sentences:
                for new_sent in new_sentences:
                    sent_sim = difflib.SequenceMatcher(None, old_sent, new_sent).ratio()
                    if sent_sim > 0.8:  # ุฌููุฉ ูุชุทุงุจูุฉ ุชูุฑูุจุงู
                        matched_sentences += 1
                        break
            sentence_similarity = (matched_sentences / max(len(old_sentences), len(new_sentences))) * 100
        
        # 3. ุญุณุงุจ ุงูุชุดุงุจู ูู ุงูุทูู
        length_similarity = 100 - min(abs(len(old_clean) - len(new_clean)) / max(len(old_clean), len(new_clean)) * 100, 100)
        
        # 4. ุญุณุงุจ ูุชูุณุท ูุฑุฌุญ ููููุงููุณ ุงููุฎุชููุฉ
        enhanced_similarity = (
            basic_similarity * 0.3 +          # 30% ููุชุดุงุจู ุงูุฃุณุงุณู
            jaccard_similarity * 0.4 +        # 40% ููุชุดุงุจู ุนูู ูุณุชูู ุงููููุงุช  
            sentence_similarity * 0.2 +       # 20% ููุชุดุงุจู ุนูู ูุณุชูู ุงูุฌูู
            length_similarity * 0.1            # 10% ููุชุดุงุจู ูู ุงูุทูู
        )
        
        # 5. ุชุญุณูู ุฎุงุต ูููุตูุต ุงูุชุนููููุฉ ุงููุชุทุงุจูุฉ
        # ุฅุฐุง ูุงู ุงููุต ูุญุชูู ุนูู ูุตุทูุญุงุช ุนูููุฉ ูุดุชุฑูุฉุ ููู ุบุงูุจุงู ูุชุทุงุจู
        scientific_terms = ['ูุงุนุฏุฉ', 'ูุจุฏุฃ', 'ูุงููู', 'ูุธุฑูุฉ', 'ุชุนุฑูู', 'ุจุงุณูุงู', 'ููุฏุฑููููู', 'ุถุบุท', 'ุณุงุฆู']
        old_scientific = sum(1 for term in scientific_terms if term in old_clean)
        new_scientific = sum(1 for term in scientific_terms if term in new_clean)
        
        if old_scientific > 3 and new_scientific > 3 and abs(old_scientific - new_scientific) <= 1:
            # ูุต ุนููู ูุชุทุงุจู - ุฒูุงุฏุฉ ุงููุณุจุฉ
            enhanced_similarity = min(enhanced_similarity + 15, 100)
        
        # 6. ุฅุฐุง ูุงูุช ุงููุตูุต ูุตูุฑุฉ ููุชุดุงุจูุฉุ ููู ุบุงูุจุงู ูุชุทุงุจูุฉ
        if len(old_clean) < 500 and len(new_clean) < 500 and jaccard_similarity > 80:
            enhanced_similarity = min(enhanced_similarity + 10, 100)
            
        return enhanced_similarity
    
    def _normalize_text(self, text: str) -> str:
        """ุชุทุจูุน ุงููุต ููููุงุฑูุฉ"""
        if not text:
            return ""
        
        # ุฅุฒุงูุฉ ุงูุฑููุฒ ุงูุฎุงุตุฉ ูุงูุชูุณูู
        normalized = re.sub(r'[^\w\s\u0600-\u06FF]', ' ', text)
        # ุฅุฒุงูุฉ ุงููุณุงูุงุช ุงูุฒุงุฆุฏุฉ
        normalized = re.sub(r'\s+', ' ', normalized)
        # ุชุญููู ููุฃุญุฑู ุงูุตุบูุฑุฉ (ูููุตูุต ุงูุฅูุฌููุฒูุฉ)
        return normalized.strip().lower()
    
    async def _test_connection(self) -> bool:
        """ุงุฎุชุจุงุฑ ุงูุงุชุตุงู ุจู Gemini"""
        try:
            test_prompt = "ูุฑุญุจุงูุ ูุฐุง ุงุฎุชุจุงุฑ ุงุชุตุงู. ุฃุฌุจ ุจู 'ุชู ุงูุงุชุตุงู ุจูุฌุงุญ' ููุท."
            response = await asyncio.to_thread(
                self.client.generate_content, test_prompt
            )
            return response.text is not None and len(response.text) > 0
        except Exception as e:
            logger.error(f"โ ูุดู ุงุฎุชุจุงุฑ ุงูุงุชุตุงู ุจู Gemini: {e}")
            return False


# ุฅูุดุงุก instance ูุงุญุฏ ููุฎุฏูุฉ
gemini_service = GeminiService() 