"""
Ø®Ø¯Ù…Ø© Google Gemini Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©
Google Gemini Service for Intelligent Text Comparison
"""

import os
import json
import asyncio
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import difflib
import re

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
from pydantic import BaseModel, Field
from loguru import logger

from app.core.config import get_settings

settings = get_settings()


class TextComparisonResult(BaseModel):
    """Ù†ØªÙŠØ¬Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ"""
    similarity_percentage: float = Field(..., ge=0, le=100)
    content_changes: List[str] = Field(default_factory=list)
    questions_changes: List[str] = Field(default_factory=list)
    examples_changes: List[str] = Field(default_factory=list)
    major_differences: List[str] = Field(default_factory=list)
    added_content: List[str] = Field(default_factory=list)
    removed_content: List[str] = Field(default_factory=list)
    modified_content: List[str] = Field(default_factory=list)
    
    summary: str
    recommendation: str
    detailed_analysis: str = ""
    
    processing_time: float
    service_used: str = "Gemini"
    confidence_score: float = Field(default=0.85, ge=0, le=1)
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    old_text_length: int = 0
    new_text_length: int = 0
    common_words_count: int = 0
    unique_old_words: int = 0
    unique_new_words: int = 0


class GeminiService:
    """Ø®Ø¯Ù…Ø© Google Gemini Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©"""
    
    def __init__(self):
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ù…ÙÙ‚Ø¯Ù…
        self.api_key = "AIzaSyCDO-0puQQN79BJ4u503O31g16ww8CAycg"
        self.model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        self.temperature = float(os.getenv("GEMINI_TEMPERATURE", "0.3"))
        self.max_output_tokens = int(os.getenv("GEMINI_MAX_OUTPUT_TOKENS", "8192"))
        self.top_p = float(os.getenv("GEMINI_TOP_P", "0.8"))
        self.top_k = int(os.getenv("GEMINI_TOP_K", "40"))
        
        if not self.api_key:
            logger.warning("âš ï¸ GEMINI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ - Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©")
            self.mock_mode = True
            self.client = None
        else:
            try:
                genai.configure(api_key=self.api_key)
                generation_config = {
                    "temperature": self.temperature,
                    "top_p": self.top_p,
                    "top_k": self.top_k,
                    "max_output_tokens": self.max_output_tokens,
                }
                
                self.client = genai.GenerativeModel(
                    model_name=self.model_name,
                    generation_config=generation_config
                )
                
                self.mock_mode = False
                logger.info("âœ… ØªÙ… ØªÙƒÙˆÙŠÙ† Gemini AI Service Ù…Ø¹ API Ø­Ù‚ÙŠÙ‚ÙŠ")
                
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙƒÙˆÙŠÙ† Gemini: {e}")
                self.mock_mode = True
                self.client = None
    
    async def compare_texts(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> TextComparisonResult:
        """
        Ù…Ù‚Ø§Ø±Ù†Ø© Ù†ØµÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI
        Compare two texts using Gemini AI
        """
        start_time = datetime.now()
        
        logger.info("ğŸ“ Ø¨Ø¯Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
        
        try:
            if self.mock_mode:
                result = await self._mock_comparison(old_text, new_text)
            else:
                result = await self._real_comparison(old_text, new_text, context)
            
            # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            processing_time = (datetime.now() - start_time).total_seconds()
            result.processing_time = processing_time
            
            # Ø¥Ø¶Ø§ÙØ© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Øµ
            result.old_text_length = len(old_text)
            result.new_text_length = len(new_text)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªØ±ÙƒØ©
            old_words = set(old_text.split())
            new_words = set(new_text.split())
            common_words = old_words & new_words
            
            result.common_words_count = len(common_words)
            result.unique_old_words = len(old_words - new_words)
            result.unique_new_words = len(new_words - old_words)
            
            logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ ÙÙŠ {processing_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            return result
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ: {e}")
            
            # Ø¥Ø±Ø¬Ø§Ø¹ Ù†ØªÙŠØ¬Ø© Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£
            return await self._fallback_comparison(old_text, new_text, processing_time, str(e))
    
    async def _real_comparison(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> TextComparisonResult:
        """Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini"""
        
        logger.info("ğŸ¤– Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI...")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù…Ø®ØµØµ Ù„Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©
        prompt = self._create_comparison_prompt(old_text, new_text, context)
        
        try:
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini
            logger.debug("ğŸ“¡ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ Gemini...")
            response = await asyncio.to_thread(
                self.client.generate_content, prompt
            )
            
            if not response.text:
                raise Exception("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Gemini")
            
            logger.info("âœ… ØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Gemini")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            logger.debug("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Gemini...")
            analysis = self._parse_gemini_response(response.text)
            
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… difflib ÙƒÙ…Ø±Ø¬Ø¹
            logger.debug("ğŸ“Š Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡...")
            similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªØ­Ù„ÙŠÙ„
            detailed_analysis = f"""
## ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ø¨ÙˆØ§Ø³Ø·Ø© Gemini AI

### Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {similarity:.1f}%

### Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ:
{response.text}

### Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Øµ:
- Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {len(old_text)} Ø­Ø±Ù
- Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯: {len(new_text)} Ø­Ø±Ù
- Ø§Ù„ÙØ±Ù‚ ÙÙŠ Ø§Ù„Ø·ÙˆÙ„: {abs(len(new_text) - len(old_text))} Ø­Ø±Ù

### Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:
- ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…: {self.model_name}
- Ø¯Ø±Ø¬Ø© Ø§Ù„Ø­Ø±Ø§Ø±Ø©: {self.temperature}
- Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø±Ù…ÙˆØ²: {self.max_output_tokens}
"""
            
            result = TextComparisonResult(
                similarity_percentage=round(similarity, 1),
                content_changes=analysis.get("content_changes", []),
                questions_changes=analysis.get("questions_changes", []),
                examples_changes=analysis.get("examples_changes", []),
                major_differences=analysis.get("major_differences", []),
                added_content=analysis.get("added_content", []),
                removed_content=analysis.get("removed_content", []),
                modified_content=analysis.get("modified_content", []),
                summary=analysis.get("summary", "ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠÙ† Ø¨Ù†Ø¬Ø§Ø­"),
                recommendation=analysis.get("recommendation", "ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª"),
                detailed_analysis=detailed_analysis,
                processing_time=0,  # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡
                confidence_score=analysis.get("confidence_score", 0.9)
            )
            
            logger.info(f"ğŸ¯ ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„: {similarity:.1f}% ØªØ´Ø§Ø¨Ù‡")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini: {e}")
            raise
    
    def _create_comparison_prompt(
        self, 
        old_text: str, 
        new_text: str,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø±ÙˆÙ…Ø¨Øª Ù…Ø®ØµØµ Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©"""
        
        context_info = ""
        if context:
            context_info = f"""
Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚:
- Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {context.get('content_type', 'Ù…Ù†Ù‡Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠ')}
- Ø§Ù„Ù…Ø§Ø¯Ø©: {context.get('subject', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
- Ø§Ù„Ù…Ø³ØªÙˆÙ‰: {context.get('grade_level', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}
"""
        
        prompt = f"""
Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©. Ù…Ù‡Ù…ØªÙƒ Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ø³Ø®ØªÙŠÙ† Ù…Ù† Ù…Ù†Ù‡Ø¬ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ø´Ø±Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯.

{context_info}

Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ (Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ…):
```
{old_text[:3000]}...
```

Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯ (Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù…Ø­Ø¯Ø«):
```
{new_text[:3000]}...
```

Ø±ÙƒØ² ØªØ­Ù„ÙŠÙ„Ùƒ Ø¹Ù„Ù‰:

1. **Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©** (Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©):
   - Ø£Ø³Ø¦Ù„Ø© Ù…Ø¶Ø§ÙØ© Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ÙŠØ§Ù‹
   - ØªØ¹Ø¯ÙŠÙ„Ø§Øª Ø¹Ù„Ù‰ ØµÙŠØºØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
   - Ø£Ø³Ø¦Ù„Ø© ØªØ·Ø¨ÙŠÙ‚ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©
   - Ø£Ø³Ø¦Ù„Ø© ØªÙ‚ÙŠÙŠÙ…ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©

2. **Ø§Ù„Ø´Ø±Ø­ ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯** (Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ©):
   - Ø´Ø±ÙˆØ­Ø§Øª Ù…Ø¶Ø§ÙØ© Ù„Ù„Ù…ÙØ§Ù‡ÙŠÙ…
   - Ø£Ù…Ø«Ù„Ø© ØªÙˆØ¶ÙŠØ­ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©
   - Ø·Ø±Ù‚ Ø­Ù„ Ø¬Ø¯ÙŠØ¯Ø©
   - Ù…ÙØ§Ù‡ÙŠÙ… Ø¹Ù„Ù…ÙŠØ© Ù…Ø¶Ø§ÙØ©

3. **Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„ØªÙ…Ø§Ø±ÙŠÙ† ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª**:
   - ØªÙ…Ø§Ø±ÙŠÙ† Ø¬Ø¯ÙŠØ¯Ø©
   - Ù…Ø³Ø§Ø¦Ù„ Ø­Ø³Ø§Ø¨ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø©
   - ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¹Ù…Ù„ÙŠØ© Ù…Ø¶Ø§ÙØ©

4. **Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯**:
   - ØªØ¨Ø³ÙŠØ· Ø§Ù„Ø´Ø±Ø­
   - Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ù…Ù‡Ù…Ø©
   - ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ

5. **Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©** (ÙŠÙ…ÙƒÙ† ØªØ¬Ø§Ù‡Ù„Ù‡Ø§):
   - ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ ÙÙ‚Ø·
   - Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù…Ù„Ø§Ø¦ÙŠØ©
   - ØªØºÙŠÙŠØ±Ø§Øª Ø·ÙÙŠÙØ© ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª

Ø£Ø¹Ø· Ø£ÙˆÙ„ÙˆÙŠØ© Ø®Ø§ØµØ© Ù„Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙˆØ§Ù„Ø´Ø±Ø­ Ø§Ù„Ø¬Ø¯ÙŠØ¯. Ø£Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON:

```json
{{
  "new_questions": ["Ù‚Ø§Ø¦Ù…Ø© Ù…ÙØµÙ„Ø© Ø¨Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"],
  "new_explanations": ["Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø´Ø±ÙˆØ­Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"],
  "modified_questions": ["Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¹Ø¯Ù„Ø©"],
  "new_examples": ["Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"],
  "content_changes": ["Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"],
  "questions_changes": ["Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"],
  "major_differences": ["Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ© ÙÙ‚Ø·"],
  "added_content": ["Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø¶Ø§Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯"],
  "summary": "Ù…Ù„Ø®Øµ ÙŠØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø´Ø±ÙˆØ­Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©",
  "recommendation": "ØªÙˆØµÙŠØ§Øª Ù„Ù„Ù…Ø¹Ù„Ù…ÙŠÙ† Ø­ÙˆÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯",
  "has_significant_changes": true/false,
  "confidence_score": 0.95
}}
```

Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø·ÙÙŠÙØ© Ø£Ùˆ ØºÙŠØ± Ù…Ù‡Ù…Ø©ØŒ Ø§Ø°ÙƒØ± Ø°Ù„Ùƒ Ø¨ÙˆØ¶ÙˆØ­.
"""
        
        return prompt
    
    def _parse_gemini_response(self, response_text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Gemini ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ JSON"""
        
        try:
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† JSON ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                return json.loads(json_str)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© ÙƒÙ€ JSON Ù…Ø¨Ø§Ø´Ø±Ø©
            return json.loads(response_text)
            
        except json.JSONDecodeError:
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ JSONØŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙŠØ¯ÙˆÙŠØ§Ù‹
            logger.warning("âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ JSON Ù…Ù† GeminiØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªØ­Ù„ÙŠÙ„ Ù†ØµÙŠ")
            
            return {
                "content_changes": self._extract_list_from_text(response_text, "Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"),
                "questions_changes": self._extract_list_from_text(response_text, "Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©"),
                "examples_changes": self._extract_list_from_text(response_text, "Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ø£Ù…Ø«Ù„Ø©"),
                "major_differences": self._extract_list_from_text(response_text, "Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠØ©"),
                "added_content": [],
                "removed_content": [],
                "modified_content": [],
                "summary": self._extract_summary_from_text(response_text),
                "recommendation": self._extract_recommendation_from_text(response_text),
                "detailed_analysis": response_text[:1000],
                "confidence_score": 0.8
            }
    
    def _extract_list_from_text(self, text: str, section: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù†Øµ"""
        # ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø³ÙŠØ· Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‚Ø§Ø·
        lines = text.split('\n')
        items = []
        in_section = False
        
        for line in lines:
            if section in line:
                in_section = True
                continue
            if in_section and line.strip().startswith('-'):
                items.append(line.strip()[1:].strip())
            elif in_section and line.strip() == '':
                break
        
        return items[:5]  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 5 Ø¹Ù†Ø§ØµØ±
    
    def _extract_summary_from_text(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù„Ø®Øµ Ù…Ù† Ø§Ù„Ù†Øµ"""
        lines = text.split('\n')
        for line in lines:
            if 'Ù…Ù„Ø®Øµ' in line and len(line) > 20:
                return line.strip()
        return "ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠÙ† ÙˆØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"
    
    def _extract_recommendation_from_text(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªÙˆØµÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        lines = text.split('\n')
        for line in lines:
            if 'ØªÙˆØµÙŠØ©' in line or 'ÙŠÙÙ†ØµØ­' in line:
                return line.strip()
        return "ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª ÙˆØªØ­Ø¯ÙŠØ« Ø®Ø·Ø· Ø§Ù„ØªØ¯Ø±ÙŠØ³ ÙˆÙÙ‚Ø§Ù‹ Ù„Ø°Ù„Ùƒ"
    
    async def _mock_comparison(
        self, 
        old_text: str, 
        new_text: str
    ) -> TextComparisonResult:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ù„ØªØ·ÙˆÙŠØ±"""
        
        logger.info("ğŸ­ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© - Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙˆØµ")
        
        # Ù…Ø­Ø§ÙƒØ§Ø© ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        await asyncio.sleep(2)
        
        # Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø£Ø³Ø§Ø³ÙŠ
        similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
        
        # ØªØºÙŠÙŠØ±Ø§Øª ØªØ¬Ø±ÙŠØ¨ÙŠØ©
        mock_changes = [
            "ØªÙ… Ø¥Ø¶Ø§ÙØ© ÙÙ‚Ø±Ø© Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©",
            "ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ù„ØªÙƒÙˆÙ† Ø£ÙƒØ«Ø± ÙˆØ¶ÙˆØ­Ø§Ù‹",
            "ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªØ³Ù„Ø³Ù„",
            "ØªÙ… Ø¥Ø¶Ø§ÙØ© ØªÙ…Ø§Ø±ÙŠÙ† Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„ØªØ¹Ø²ÙŠØ²"
        ]
        
        return TextComparisonResult(
            similarity_percentage=round(similarity, 1),
            content_changes=mock_changes[:2],
            questions_changes=["ØªÙ… Ø¥Ø¶Ø§ÙØ© 3 Ø£Ø³Ø¦Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©", "ØªÙ… ØªØ¹Ø¯ÙŠÙ„ ØµÙŠØ§ØºØ© Ø³Ø¤Ø§Ù„ÙŠÙ†"],
            examples_changes=["ØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ù…Ø«Ø§Ù„ Ù‚Ø¯ÙŠÙ… Ø¨Ù…Ø«Ø§Ù„ Ø£ÙƒØ«Ø± Ø­Ø¯Ø§Ø«Ø©"],
            major_differences=mock_changes[2:] if similarity < 80 else [],
            added_content=["Ù…Ø­ØªÙˆÙ‰ Ø¬Ø¯ÙŠØ¯ Ø­ÙˆÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª"],
            removed_content=["Ù…Ø­ØªÙˆÙ‰ Ù‚Ø¯ÙŠÙ… ØºÙŠØ± Ø°ÙŠ ØµÙ„Ø©"],
            modified_content=["ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ø´Ø±Ø­"],
            summary=f"ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙŠÙ† ÙˆØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ {similarity:.1f}%. ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(mock_changes)} ØªØºÙŠÙŠØ± Ø±Ø¦ÙŠØ³ÙŠ.",
            recommendation="ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ÙˆØªØ­Ø¯ÙŠØ« Ø®Ø·Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ³ ÙˆÙÙ‚Ø§Ù‹ Ù„Ø°Ù„Ùƒ" if similarity < 85 else "Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø·ÙÙŠÙØ© ÙˆÙ„Ø§ ØªØªØ·Ù„Ø¨ ØªØ­Ø¯ÙŠØ«Ø§Øª ÙƒØ¨ÙŠØ±Ø©",
            detailed_analysis="ØªØ­Ù„ÙŠÙ„ ØªÙØµÙŠÙ„ÙŠ: Ø§Ù„Ù†ØµØ§Ù† Ù…ØªØ´Ø§Ø¨Ù‡Ø§Ù† Ø¥Ù„Ù‰ Ø­Ø¯ ÙƒØ¨ÙŠØ± Ù…Ø¹ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø·ÙÙŠÙØ© ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¬Ø¯ÙŠØ¯",
            processing_time=0,
            confidence_score=0.9
        )
    
    async def _fallback_comparison(
        self, 
        old_text: str, 
        new_text: str,
        processing_time: float,
        error_message: str
    ) -> TextComparisonResult:
        """Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø·Ø£"""
        
        # Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø£Ø³Ø§Ø³ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… difflib
        similarity = difflib.SequenceMatcher(None, old_text, new_text).ratio() * 100
        
        return TextComparisonResult(
            similarity_percentage=round(similarity, 1),
            content_changes=[],
            questions_changes=[],
            examples_changes=[],
            major_differences=[],
            added_content=[],
            removed_content=[],
            modified_content=[],
            summary=f"ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: {similarity:.1f}%",
            recommendation="Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…ØŒ ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©",
            detailed_analysis=f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {error_message}",
            processing_time=processing_time,
            confidence_score=0.5
        )
    
    async def analyze_text(self, text: str, prompt: Optional[str] = None) -> str:
        """
        ØªØ­Ù„ÙŠÙ„ Ù†Øµ ÙˆØ§Ø­Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
        Analyze single text using Gemini
        """
        logger.info("ğŸ” Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
        
        try:
            if self.mock_mode:
                return await self._mock_text_analysis(text)
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª
            analysis_prompt = prompt or f"""
            ÙŠØ±Ø¬Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØªÙ‚Ø¯ÙŠÙ…:
            1. Ù…Ù„Ø®Øµ Ù„Ù„Ù…Ø­ØªÙˆÙ‰
            2. Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
            3. Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©
            4. ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Øµ
            5. Ø£ÙŠ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø£Ø®Ø±Ù‰
            
            Ø§Ù„Ù†Øµ:
            {text}
            
            ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ Ù…ÙØµÙ„ ÙˆÙ…ÙÙŠØ¯.
            """
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Gemini
            response = await asyncio.to_thread(
                self.client.generate_content, analysis_prompt
            )
            
            if not response.text:
                raise Exception("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Gemini")
            
            logger.info("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­")
            return response.text
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ: {e}")
            return await self._mock_text_analysis(text)
    
    async def _mock_text_analysis(self, text: str) -> str:
        """ØªØ­Ù„ÙŠÙ„ ÙˆÙ‡Ù…ÙŠ Ù„Ù„Ù†Øµ Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        await asyncio.sleep(1)  # Ù…Ø­Ø§ÙƒØ§Ø© ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        
        word_count = len(text.split())
        char_count = len(text)
        
        return f"""# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ - ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©

## Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
ØªÙ… ØªØ­Ù„ÙŠÙ„ Ù†Øµ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ {word_count} ÙƒÙ„Ù…Ø© Ùˆ {char_count} Ø­Ø±Ù. Ø§Ù„Ù†Øµ ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ù‡ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ ØªØ¹Ù„ÙŠÙ…ÙŠ Ø£Ùˆ Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ.

## Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ÙŠØŒ ÙŠØªØ¹Ù„Ù‚ Ø§Ù„Ù†Øµ Ø¨Ù…ÙˆØ¶ÙˆØ¹ ØªØ¹Ù„ÙŠÙ…ÙŠ ÙŠØªØ¶Ù…Ù† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆÙ…ÙØ§Ù‡ÙŠÙ… Ø£Ø³Ø§Ø³ÙŠØ©.

## Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù‡Ù…Ø©
- Ø§Ù„Ù†Øµ Ù…Ù†Ø¸Ù… ÙˆÙ…Ù‡ÙŠÙƒÙ„ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯
- ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚ÙŠÙ…Ø© Ù„Ù„Ù‚Ø§Ø±Ø¦
- Ø§Ù„Ù„ØºØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©
- Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„ØºØ±Ø¶ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ

## ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ù†Øµ
- **Ø§Ù„ÙˆØ¶ÙˆØ­**: Ø¬ÙŠØ¯
- **Ø§Ù„ØªÙ†Ø¸ÙŠÙ…**: Ù…Ù…ØªØ§Ø²
- **Ø§Ù„Ù…Ø­ØªÙˆÙ‰**: Ù…ÙÙŠØ¯ ÙˆÙ…Ù†Ø§Ø³Ø¨
- **Ø§Ù„Ù„ØºØ©**: Ø³Ù„ÙŠÙ…Ø© ÙˆÙ…ÙÙ‡ÙˆÙ…Ø©

## Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
- ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù† Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
- Ø¬ÙˆØ¯Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬ÙŠØ¯Ø© Ù…Ø¹ Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ù…Ù† Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
- Ø§Ù„Ù†Øµ Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
- ÙŠÙÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†Øµ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª

---
*ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø© Ù„Ø£ØºØ±Ø§Ø¶ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±*
"""

    async def health_check(self) -> Dict[str, Any]:
        """ÙØ­Øµ ØµØ­Ø© Ø®Ø¯Ù…Ø© Gemini"""
        try:
            if self.mock_mode:
                return {
                    "status": "healthy",
                    "mode": "mock", 
                    "message": "Gemini Service ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ù…Ø­Ø§ÙƒØ§Ø©",
                    "api_key_configured": False
                }
            
            # Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø³ÙŠØ· Ù„Ù„Ù€ API
            test_response = await asyncio.to_thread(
                self.client.generate_content, 
                "Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ø³ÙŠØ· Ù„Ù„Ø§ØªØµØ§Ù„"
            )
            
            return {
                "status": "healthy",
                "mode": "production",
                "message": "Gemini Service Ø¬Ø§Ù‡Ø²",
                "api_key_configured": True,
                "model": self.model_name,
                "test_response_length": len(test_response.text) if test_response.text else 0
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "message": f"Ø®Ø·Ø£ ÙÙŠ Gemini Service: {str(e)}",
                "error": str(e)
            }


# Ø¥Ù†Ø´Ø§Ø¡ instance ÙˆØ§Ø­Ø¯ Ù„Ù„Ø®Ø¯Ù…Ø©
gemini_service = GeminiService() 