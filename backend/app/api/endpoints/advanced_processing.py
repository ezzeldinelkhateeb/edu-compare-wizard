"""
Advanced Processing API Endpoints
Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
"""

import os
import asyncio
import aiofiles
from typing import List, Dict, Optional, Any, Callable
from pathlib import Path
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
from datetime import datetime
import logging
import re
import uuid
import zipfile
import tempfile
from dataclasses import dataclass, asdict
from loguru import logger

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import FileResponse, StreamingResponse
from starlette.responses import Response

from app.core.config import get_settings
from app.services.landing_ai_service import LandingAIService
from app.services.gemini_service import GeminiService
from app.services.enhanced_report_service import EnhancedReportService, ReportData
from app.models.schemas import (
    ProcessingSessionRequest, ProcessingSessionResponse,
    ProcessingStep, ProcessingResult, ComparisonResult
)

settings = get_settings()
router = APIRouter()

# ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
processing_sessions = {}


class AdvancedProcessingSession:
    """Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.created_at = datetime.now()
        self.status = "initializing"
        self.progress = 0
        self.current_step = "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©"
        self.processing_steps = [
            ProcessingStep(
                id="init",
                name="Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©",
                status="processing",
                progress=10
            ),
            ProcessingStep(
                id="upload",
                name="Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª",
                status="pending",
                progress=0
            ),
            ProcessingStep(
                id="ocr_old",
                name="OCR - Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…",
                status="pending",
                progress=0,
                max_attempts=4
            ),
            ProcessingStep(
                id="ocr_new", 
                name="OCR - Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯",
                status="pending",
                progress=0,
                max_attempts=4
            ),
            ProcessingStep(
                id="ai_comparison",
                name="Ù…Ù‚Ø§Ø±Ù†Ø© AI",
                status="pending",
                progress=0
            ),
            ProcessingStep(
                id="report_generation",
                name="Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±",
                status="pending",
                progress=0
            )
        ]
        self.old_files = []
        self.new_files = []
        self.processing_results = []
        self.comparison_results = []
        self.logs = []
        self.session_dir = None
        
    def add_log(self, message: str, level: str = "info"):
        """Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.logs.append(log_entry)
        
        # Ø·Ø¨Ø§Ø¹Ø© ÙÙŠ ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø£ÙŠØ¶Ø§Ù‹
        if level == "error":
            logger.error(message)
        elif level == "warning":
            logger.warning(message)
        else:
            logger.info(message)
    
    def update_step(self, step_id: str, **updates):
        """ØªØ­Ø¯ÙŠØ« Ø®Ø·ÙˆØ© Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        for step in self.processing_steps:
            if step.id == step_id:
                for key, value in updates.items():
                    setattr(step, key, value)
                break
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø£ÙƒØ«Ø± Ø¯Ù‚Ø©
        total_progress = 0
        total_steps = len(self.processing_steps)
        
        for step in self.processing_steps:
            if step.status == "completed":
                total_progress += 100
            elif step.status == "processing":
                # Ø§Ø³ØªØ®Ø¯Ù… ØªÙ‚Ø¯Ù… Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
                total_progress += max(step.progress, 10)  # Ø­Ø¯ Ø£Ø¯Ù†Ù‰ 10% Ù„Ù„Ø®Ø·ÙˆØ§Øª Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            elif step.status == "pending":
                total_progress += 0
            elif step.status == "error":
                total_progress += 0
        
        self.progress = min(total_progress / total_steps, 100)  # ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ØªØ¬Ø§ÙˆØ² 100%
    
    def get_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
        return {
            "session_id": self.session_id,
            "status": self.status,
            "progress": self.progress,
            "current_step": self.current_step,
            "processing_steps": [step.model_dump() for step in self.processing_steps],
            "old_files_count": len(self.old_files),
            "new_files_count": len(self.new_files),
            "processing_results_count": len(self.processing_results),
            "comparison_results_count": len(self.comparison_results),
            "logs": self.logs[-20:],  # Ø¢Ø®Ø± 20 Ø³Ø¬Ù„
            "created_at": self.created_at.isoformat(),
            "updated_at": datetime.now().isoformat()
        }


def sanitize_filename(filename: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©"""
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù ØºÙŠØ± Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø© (Ø¨Ù…Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ø´Ø±Ø·Ø© Ø§Ù„Ù…Ø§Ø¦Ù„Ø©)
    sanitized = re.sub(r'[<>:"/\\|?*]', '_', filename)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© ÙˆØ§Ù„Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø¨Ù€ _
    sanitized = re.sub(r'\s+', '_', sanitized)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
    sanitized = re.sub(r'\.+', '.', sanitized)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø®Ø§ØµØ© Ø§Ù„Ø£Ø®Ø±Ù‰ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
    sanitized = re.sub(r'[^\w\-_\.\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]', '_', sanitized)
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… Ø§Ù„Ø¨Ø¯Ø¡ Ø£Ùˆ Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ø¨Ù†Ù‚Ø·Ø© Ø£Ùˆ Ù…Ø³Ø§ÙØ©
    sanitized = sanitized.strip('. _')
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù…ØªØ¯Ø§Ø¯ ØµØ§Ù„Ø­
    if not sanitized:
        sanitized = "unnamed_file"
    return sanitized[:255]  # ØªØ­Ø¯ÙŠØ¯ Ø·ÙˆÙ„ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù


async def _generate_comprehensive_batch_report(session: AdvancedProcessingSession, individual_reports: List[Dict]) -> Dict:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª ÙÙŠ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©"""
    
    successful_comparisons = [c for c in session.comparison_results if c['status'] == 'completed']
    failed_comparisons = [c for c in session.comparison_results if c['status'] != 'completed']
    
    average_similarity = 0
    if successful_comparisons:
        average_similarity = sum(c['similarity'] for c in successful_comparisons) / len(successful_comparisons)
    
    total_processing_time = sum(r['processing_time'] for r in session.processing_results if r['status'] == 'completed')
    
    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML Ø´Ø§Ù…Ù„
    html_content = f"""<!DOCTYPE html>
<html dir="rtl" lang="ar">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© - {session.session_id}</title>
    <style>
        body {{ font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .header {{ text-align: center; border-bottom: 2px solid #3b82f6; padding-bottom: 20px; margin-bottom: 30px; }}
        .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 30px 0; }}
        .stat-card {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 20px; border-radius: 10px; text-align: center; }}
        .stat-value {{ font-size: 2rem; font-weight: bold; }}
        .stat-label {{ margin-top: 5px; opacity: 0.9; }}
        .comparison-grid {{ display: grid; gap: 20px; margin: 30px 0; }}
        .comparison-card {{ border: 1px solid #e5e7eb; padding: 20px; border-radius: 8px; background: #f9fafb; }}
        .similarity-bar {{ background: #e5e7eb; height: 20px; border-radius: 10px; overflow: hidden; margin: 10px 0; }}
        .similarity-fill {{ background: linear-gradient(90deg, #ef4444, #f59e0b, #10b981); height: 100%; transition: width 0.3s ease; }}
        .file-names {{ font-weight: bold; color: #374151; margin-bottom: 10px; }}
        .summary {{ background: white; padding: 15px; border-left: 4px solid #3b82f6; margin: 10px 0; }}
        .recommendation {{ background: #fef3c7; padding: 15px; border-left: 4px solid #f59e0b; margin: 10px 0; }}
        .error-notice {{ background: #fee2e2; color: #dc2626; padding: 15px; border-radius: 5px; margin: 20px 0; }}
        .footer {{ text-align: center; margin-top: 40px; padding-top: 20px; border-top: 1px solid #e5e7eb; color: #6b7280; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©</h1>
            <p>Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù„Ø³Ø©: {session.session_id}</p>
            <p>ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>

        <div class="stats-grid">
            <div class="stat-card">
                <div class="stat-value">{len(successful_comparisons)}</div>
                <div class="stat-label">Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ù†Ø§Ø¬Ø­Ø©</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{len(failed_comparisons)}</div>
                <div class="stat-label">Ù…Ù‚Ø§Ø±Ù†Ø§Øª ÙØ§Ø´Ù„Ø©</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{average_similarity:.1f}%</div>
                <div class="stat-label">Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{total_processing_time:.1f}s</div>
                <div class="stat-label">ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ</div>
            </div>
        </div>

        {_generate_quota_warning() if failed_comparisons else ''}

        <h2>ğŸ“ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª</h2>
        <div class="comparison-grid">"""
    
    # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©
    for i, comparison in enumerate(successful_comparisons):
        old_file = next((r for r in session.processing_results if r['id'] == comparison['old_file_id']), None)
        new_file = next((r for r in session.processing_results if r['id'] == comparison['new_file_id']), None)
        
        if old_file and new_file:
            html_content += f"""
            <div class="comparison-card">
                <div class="file-names">ğŸ“„ {old_file['filename']} â† {new_file['filename']}</div>
                <div class="similarity-bar">
                    <div class="similarity-fill" style="width: {comparison['similarity']}%"></div>
                </div>
                <div style="text-align: center; font-weight: bold; margin: 10px 0;">
                    Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡: {comparison['similarity']}%
                </div>
                <div class="summary">
                    <strong>Ø§Ù„Ù…Ù„Ø®Øµ:</strong> {comparison['summary']}
                </div>
                <div class="recommendation">
                    <strong>Ø§Ù„ØªÙˆØµÙŠØ©:</strong> {comparison['recommendation']}
                </div>
                <div style="display: grid; grid-template-columns: repeat(3, 1fr); gap: 10px; margin-top: 15px; font-size: 0.9em; color: #6b7280;">
                    <div>âš¡ Ø«Ù‚Ø©: {comparison['confidence']*100:.1f}%</div>
                    <div>â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {comparison['processing_time']:.1f}s</div>
                    <div>ğŸ“Š Ø­Ø§Ù„Ø©: Ù…ÙƒØªÙ…Ù„Ø©</div>
                </div>
            </div>"""
    
    html_content += """
        </div>

        <div class="footer">
            <p>ØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©</p>
            <p>Ø§Ø³ØªØ®Ø¯Ù… Landing.AI Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¨ØµØ±ÙŠ | Google Gemini Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ</p>
        </div>
    </div>
</body>
</html>"""
    
    # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
    comprehensive_html_path = os.path.join(session.session_dir, "comprehensive_report.html")
    with open(comprehensive_html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    return {
        "html_path": comprehensive_html_path,
        "individual_reports_count": len(individual_reports),
        "successful_comparisons": len(successful_comparisons),
        "failed_comparisons": len(failed_comparisons),
        "average_similarity": average_similarity,
        "total_processing_time": total_processing_time
    }


def _generate_quota_warning() -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªØ­Ø°ÙŠØ± Ø®Ø§Øµ Ø¨Ø­Ø¯ÙˆØ¯ Gemini API"""
    return """
    <div class="error-notice">
        <h3>âš ï¸ ØªÙ†Ø¨ÙŠÙ‡ Ù…Ù‡Ù…</h3>
        <p>ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù€ Gemini AI API (50 Ø·Ù„Ø¨/ÙŠÙˆÙ… Ù„Ù„Ø§Ø´ØªØ±Ø§Ùƒ Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ).</p>
        <p>ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·. Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù…ÙØµÙ„ØŒ ÙŠÙØ±Ø¬Ù‰:</p>
        <ul>
            <li>Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø­ØªÙ‰ Ø§Ù„ÙŠÙˆÙ… Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø¯</li>
            <li>Ø£Ùˆ Ø§Ù„ØªØ±Ù‚ÙŠØ© Ø¥Ù„Ù‰ Ø®Ø·Ø© Gemini API Ù…Ø¯ÙÙˆØ¹Ø©</li>
        </ul>
    </div>"""


@router.post("/advanced-processing/create-session", response_model=ProcessingSessionResponse)
async def create_processing_session(request: ProcessingSessionRequest):
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©
    Create new advanced processing session
    """
    try:
        session_id = str(uuid.uuid4())
        session = AdvancedProcessingSession(session_id)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©
        session_dir = os.path.join(settings.UPLOAD_DIR, "advanced_sessions", session_id)
        os.makedirs(session_dir, exist_ok=True)
        session.session_dir = session_dir
        
        # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø©
        processing_sessions[session_id] = session
        
        session.add_log(f"ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©: {session_id}")
        session.update_step("init", status="completed", progress=100)
        session.current_step = "Ø§Ù†ØªØ¸Ø§Ø± Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª"
        session.status = "waiting_for_files"
        
        logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©: {session_id}")
        
        return ProcessingSessionResponse(
            session_id=session_id,
            status="created",
            message="ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­"
        )
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        )


@router.post("/advanced-processing/{session_id}/upload-files")
async def upload_files_to_session(
    session_id: str,
    old_files: List[UploadFile] = File(...),
    new_files: List[UploadFile] = File(...),
    background_tasks: BackgroundTasks = None
):
    """
    Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Upload files to processing session
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    try:
        session.add_log("ğŸ“¤ Ø¨Ø¯Ø¡ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª...")
        session.update_step("upload", status="processing", progress=20)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ù„Ù„Ù…Ù„ÙØ§Øª
        old_files_dir = os.path.join(session.session_dir, "old_files")
        new_files_dir = os.path.join(session.session_dir, "new_files")
        
        session.add_log(f"ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {old_files_dir}")
        session.add_log(f"ğŸ“ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {new_files_dir}")
        
        os.makedirs(old_files_dir, exist_ok=True)
        os.makedirs(new_files_dir, exist_ok=True)
        
        session.add_log("âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        for i, file in enumerate(old_files):
            sanitized_filename = sanitize_filename(file.filename)
            file_path = os.path.join(old_files_dir, f"{i}_{sanitized_filename}")
            
            session.add_log(f"ğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {file.filename} -> {sanitized_filename}")
            session.add_log(f"ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸: {file_path}")
            
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            session.old_files.append({
                "id": f"old_{i}",
                "filename": file.filename,
                "sanitized_filename": sanitized_filename,
                "path": file_path,
                "size": len(content),
                "uploaded_at": datetime.now().isoformat()
            })
            
            session.add_log(f"ğŸ“ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {file.filename}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        for i, file in enumerate(new_files):
            sanitized_filename = sanitize_filename(file.filename)
            file_path = os.path.join(new_files_dir, f"{i}_{sanitized_filename}")
            
            session.add_log(f"ğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {file.filename} -> {sanitized_filename}")
            session.add_log(f"ğŸ“ Ù…Ø³Ø§Ø± Ø§Ù„Ø­ÙØ¸: {file_path}")
            
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            session.new_files.append({
                "id": f"new_{i}",
                "filename": file.filename,
                "sanitized_filename": sanitized_filename,
                "path": file_path,
                "size": len(content),
                "uploaded_at": datetime.now().isoformat()
            })
            
            session.add_log(f"ğŸ“ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {file.filename}")
        
        session.update_step("upload", status="completed", progress=100)
        session.current_step = "Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© OCR"
        session.status = "files_uploaded"
        
        session.add_log(f"âœ… ØªÙ… Ø±ÙØ¹ {len(old_files)} Ù…Ù„Ù Ù‚Ø¯ÙŠÙ… Ùˆ {len(new_files)} Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯")
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
        if background_tasks:
            background_tasks.add_task(process_files_background, session_id)
        
        return {
            "session_id": session_id,
            "status": "files_uploaded",
            "old_files_count": len(old_files),
            "new_files_count": len(new_files),
            "message": "ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"
        }
        
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        session.add_log(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}", "error")
        session.add_log(f"ğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£: {error_details}", "error")
        session.update_step("upload", status="error")
        session.status = "error"
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}"
        )


async def process_files_background(session_id: str):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©"""
    session = processing_sessions[session_id]
    
    try:
        session.add_log("ğŸ” Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© OCR Ù„Ù„Ù…Ù„ÙØ§Øª...")
        session.status = "processing"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        landing_service = LandingAIService()
        gemini_service = GeminiService()
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        session.add_log("ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…...")
        session.update_step("ocr_old", status="processing", progress=10)
        
        # ------- parallel OCR extraction for old files -------
        old_files_count = len(session.old_files)
        semaphore = asyncio.Semaphore(settings.MAX_CONCURRENT_JOBS)
        completed_old = 0

        async def process_old_file(idx: int, file_info: dict):
            nonlocal completed_old
            async with semaphore:
                session.add_log(f"ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {idx+1}: {file_info['filename']}")
                session.update_step("ocr_old", attempts=idx+1, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {file_info['filename']}")
                try:
                    result = await landing_service.extract_from_file(
                        file_info['path'],
                        os.path.join(session.session_dir, "ocr_results")
                    )

                    processing_result = {
                        "id": file_info['id'],
                        "filename": file_info['filename'],
                        "status": "completed" if result.success else "error",
                        "confidence": result.confidence_score,
                        "text_length": len(result.markdown_content),
                        "word_count": result.text_elements,
                        "processing_time": result.processing_time,
                        "language": "ara" if result.success else "unknown",
                        "extracted_text": result.markdown_content,
                        "structured_analysis": result.structured_analysis.model_dump() if result.structured_analysis else None
                    }

                    session.processing_results.append(processing_result)
                    session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {idx+1}: Ø«Ù‚Ø© {result.confidence_score:.1%}")
                except Exception as e:
                    session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {idx+1}: {str(e)}", "error")
                finally:
                    completed_old += 1
                    file_progress = 20 + (70 * completed_old / old_files_count)
                    session.update_step("ocr_old", progress=file_progress, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {completed_old}/{old_files_count}")

        await asyncio.gather(*[process_old_file(i, fi) for i, fi in enumerate(session.old_files)])
        
        session.update_step("ocr_old", status="completed", progress=100)
        session.current_step = "Ø§ÙƒØªÙ…Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        session.add_log("ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯...")
        session.update_step("ocr_new", status="processing", progress=10)
        
        # ------- parallel OCR extraction for new files -------
        new_files_count = len(session.new_files)
        completed_new = 0

        async def process_new_file(idx: int, file_info: dict):
            nonlocal completed_new
            async with semaphore:
                session.add_log(f"ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {idx+1}: {file_info['filename']}")
                session.update_step("ocr_new", attempts=idx+1, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {file_info['filename']}")
                try:
                    result = await landing_service.extract_from_file(
                        file_info['path'],
                        os.path.join(session.session_dir, "ocr_results")
                    )

                    processing_result = {
                        "id": file_info['id'],
                        "filename": file_info['filename'],
                        "status": "completed" if result.success else "error",
                        "confidence": result.confidence_score,
                        "text_length": len(result.markdown_content),
                        "word_count": result.text_elements,
                        "processing_time": result.processing_time,
                        "language": "ara" if result.success else "unknown",
                        "extracted_text": result.markdown_content,
                        "structured_analysis": result.structured_analysis.model_dump() if result.structured_analysis else None
                    }

                    session.processing_results.append(processing_result)
                    session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {idx+1}: Ø«Ù‚Ø© {result.confidence_score:.1%}")
                except Exception as e:
                    session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {idx+1}: {str(e)}", "error")
                finally:
                    completed_new += 1
                    file_progress = 20 + (70 * completed_new / new_files_count)
                    session.update_step("ocr_new", progress=file_progress, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {completed_new}/{new_files_count}")

        await asyncio.gather(*[process_new_file(i, fi) for i, fi in enumerate(session.new_files)])
        
        session.update_step("ocr_new", status="completed", progress=100)
        session.current_step = "Ø§ÙƒØªÙ…Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
        session.add_log("ï¿½ï¿½ Ø¨Ø¯Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI...")
        session.update_step("ai_comparison", status="processing", progress=20)
        session.current_step = "Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI"
        
        old_results = [r for r in session.processing_results if r['id'].startswith('old_')]
        new_results = [r for r in session.processing_results if r['id'].startswith('new_')]
        
        total_comparisons = min(len(old_results), len(new_results))
        for i, (old_result, new_result) in enumerate(zip(old_results, new_results)):
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙ‚Ø¯Ù… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
            comparison_progress = 30 + (60 * i / total_comparisons)  # Ù…Ù† 30% Ø¥Ù„Ù‰ 90%
            session.update_step("ai_comparison", progress=comparison_progress)
            session.current_step = f"Ù…Ù‚Ø§Ø±Ù†Ø© {i+1}/{total_comparisons}: {old_result['filename']} Ù…Ø¹ {new_result['filename']}"
            
            if old_result['status'] == 'completed' and new_result['status'] == 'completed':
                session.add_log(f"ğŸ”„ Ù…Ù‚Ø§Ø±Ù†Ø© {old_result['filename']} Ù…Ø¹ {new_result['filename']}")
                
                try:
                    comparison = await gemini_service.compare_texts(
                        old_result['extracted_text'],
                        new_result['extracted_text']
                    )
                    
                    comparison_result = {
                        "id": f"comparison_{i}",
                        "old_file_id": old_result['id'],
                        "new_file_id": new_result['id'],
                        "similarity": comparison.similarity_percentage,
                        "confidence": comparison.confidence_score,
                        "processing_time": comparison.processing_time,
                        "changes": comparison.content_changes,
                        "summary": comparison.summary,
                        "recommendation": comparison.recommendation,
                        "detailed_analysis": comparison.detailed_analysis,
                        "status": "completed"
                    }
                    
                    session.comparison_results.append(comparison_result)
                    session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: ØªØ´Ø§Ø¨Ù‡ {comparison.similarity_percentage}%")
                    
                except Exception as e:
                    session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}", "error")
        
        session.update_step("ai_comparison", status="completed", progress=100)
        session.current_step = "Ø§ÙƒØªÙ…Ù„Øª Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        session.add_log("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...")
        session.update_step("report_generation", status="processing", progress=25)
        session.current_step = "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        report_service = EnhancedReportService()
        
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø§Ø±ÙŠØ± ÙØ±Ø¯ÙŠØ© Ù„ÙƒÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©
        individual_reports = []
        for i, comparison in enumerate(session.comparison_results):
            if comparison['status'] == 'completed':
                old_file = next((r for r in session.processing_results if r['id'] == comparison['old_file_id']), None)
                new_file = next((r for r in session.processing_results if r['id'] == comparison['new_file_id']), None)
                
                if old_file and new_file:
                    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¯ÙŠ
                    report_data = ReportData(
                        session_id=f"{session_id}_comparison_{i}",
                        old_image_name=old_file['filename'],
                        new_image_name=new_file['filename'],
                        old_extracted_text=old_file.get('extracted_text', ''),
                        new_extracted_text=new_file.get('extracted_text', ''),
                        visual_similarity=95.0,  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¨ØµØ±ÙŠ
                        text_analysis={
                            'similarity_percentage': comparison['similarity'],
                            'summary': comparison['summary'],
                            'recommendation': comparison['recommendation'],
                            'major_differences': [],
                            'content_changes': comparison.get('changes', []),
                            'questions_changes': [],
                            'examples_changes': [],
                            'has_significant_changes': comparison['similarity'] < 80,
                            'detailed_analysis': comparison.get('detailed_analysis', '')
                        },
                        processing_time={
                            'old_ocr': old_file['processing_time'],
                            'new_ocr': new_file['processing_time'],
                            'comparison': comparison['processing_time']
                        },
                        confidence_scores={
                            'old_confidence': old_file['confidence'],
                            'new_confidence': new_file['confidence']
                        }
                    )
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± ÙØ±Ø¯ÙŠ
                    try:
                        report_paths = await report_service.generate_comprehensive_report(
                            session_id=f"{session_id}_comparison_{i}",
                            report_data=report_data,
                            include_extracted_text=True,
                            include_visual_analysis=True
                        )
                        individual_reports.append(report_paths)
                        session.add_log(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© {i+1}")
                    except Exception as e:
                        session.add_log(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¯ÙŠ {i+1}: {str(e)}", "error")
        
        session.update_step("report_generation", status="processing", progress=75)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
        session.add_log("ğŸ“‹ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©...")
        comprehensive_report = await _generate_comprehensive_batch_report(session, individual_reports)
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ JSON (ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©)
        report_path = os.path.join(session.session_dir, "final_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                "session_info": {
                    "session_id": session_id,
                    "created_at": session.created_at.isoformat(),
                    "completed_at": datetime.now().isoformat()
                },
                "processing_results": session.processing_results,
                "comparison_results": session.comparison_results,
                "individual_reports": individual_reports,
                "comprehensive_report": comprehensive_report,
                "logs": session.logs
            }, f, ensure_ascii=False, indent=2)
        
        session.update_step("report_generation", status="completed", progress=100)
        session.status = "completed"
        session.current_step = "Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"
        session.progress = 100  # ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ 100%
        session.add_log("ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        
    except Exception as e:
        session.add_log(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}", "error")
        session.status = "error"
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù„Ø³Ø© {session_id}: {e}")


@router.get("/advanced-processing/{session_id}/status")
async def get_processing_status(session_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Get processing session status
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    return session.get_status()


@router.get("/advanced-processing/{session_id}/results")
async def get_processing_results(session_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    Get complete processing results
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    if session.status != "completed":
        raise HTTPException(
            status_code=400,
            detail="Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯"
        )
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    successful_comparisons = [c for c in session.comparison_results if c['status'] == 'completed']
    failed_comparisons = [c for c in session.comparison_results if c['status'] != 'completed']
    
    average_similarity = 0
    if successful_comparisons:
        average_similarity = sum(c['similarity'] for c in successful_comparisons) / len(successful_comparisons)
    
    total_processing_time = sum(r['processing_time'] for r in session.processing_results if r['status'] == 'completed')
    
    # ØªØ¬Ù‡ÙŠØ² Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ÙØ±Ø¯ÙŠØ©
    file_results = []
    for comparison in successful_comparisons:
        old_file = next((r for r in session.processing_results if r['id'] == comparison['old_file_id']), None)
        new_file = next((r for r in session.processing_results if r['id'] == comparison['new_file_id']), None)
        
        if old_file and new_file:
            file_results.append({
                "old_filename": old_file['filename'],
                "new_filename": new_file['filename'],
                "similarity": comparison['similarity'],
                "confidence": comparison['confidence'],
                "processing_time": comparison['processing_time'],
                "summary": comparison['summary'],
                "recommendation": comparison['recommendation'],
                "changes": comparison['changes'],
                "old_extracted_text": old_file.get('extracted_text', ''),
                "new_extracted_text": new_file.get('extracted_text', '')
            })
    
    return {
        "session_id": session_id,
        "status": session.status,
        "total_files": len(session.old_files) + len(session.new_files),
        "successful_comparisons": len(successful_comparisons),
        "failed_comparisons": len(failed_comparisons),
        "average_similarity": average_similarity,
        "total_processing_time": total_processing_time,
        "file_results": file_results,
        "processing_results": session.processing_results,
        "comparison_results": session.comparison_results,
        "statistics": {
            "total_files": len(session.old_files) + len(session.new_files),
            "completed_files": len([r for r in session.processing_results if r['status'] == 'completed']),
            "average_confidence": sum(r['confidence'] for r in session.processing_results if r['status'] == 'completed') / len([r for r in session.processing_results if r['status'] == 'completed']) if session.processing_results else 0,
            "total_processing_time": total_processing_time,
            "completed_comparisons": len(successful_comparisons),
            "failed_comparisons": len(failed_comparisons),
            "average_similarity": average_similarity
        },
        "logs": session.logs
    }


@router.get("/advanced-processing/{session_id}/download-report")
async def download_processing_report(session_id: str):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒÙ…Ù„Ù Ù…Ø¶ØºÙˆØ·
    Download comprehensive processing report as ZIP file
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    if session.status != "completed":
        raise HTTPException(
            status_code=400,
            detail="Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯"
        )
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù…Ø¶ØºÙˆØ· Ù…Ø¤Ù‚Øª
        temp_zip = tempfile.NamedTemporaryFile(delete=False, suffix='.zip')
        temp_zip.close()
        
        with zipfile.ZipFile(temp_zip.name, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ HTML
            comprehensive_html = os.path.join(session.session_dir, "comprehensive_report.html")
            if os.path.exists(comprehensive_html):
                zipf.write(comprehensive_html, "ØªÙ‚Ø±ÙŠØ±_Ø´Ø§Ù…Ù„.html")
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¯ÙŠØ© ÙˆØ¥Ø¶Ø§ÙØªÙ‡Ø§
            reports_dir = os.path.join(settings.UPLOAD_DIR, "reports")
            if os.path.exists(reports_dir):
                for item in os.listdir(reports_dir):
                    item_path = os.path.join(reports_dir, item)
                    if os.path.isdir(item_path) and session_id in item:
                        # Ø¥Ø¶Ø§ÙØ© Ø¬Ù…ÙŠØ¹ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø¬Ù„Ø¯
                        for file in os.listdir(item_path):
                            file_path = os.path.join(item_path, file)
                            if os.path.isfile(file_path):
                                zipf.write(file_path, f"ØªÙ‚Ø§Ø±ÙŠØ±_ÙØ±Ø¯ÙŠØ©/{file}")
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            extracted_texts_dir = os.path.join(session.session_dir, "ocr_results")
            if os.path.exists(extracted_texts_dir):
                for root, dirs, files in os.walk(extracted_texts_dir):
                    for file in files:
                        if file.endswith('.md'):
                            file_path = os.path.join(root, file)
                            rel_path = os.path.relpath(file_path, extracted_texts_dir)
                            zipf.write(file_path, f"Ù†ØµÙˆØµ_Ù…Ø³ØªØ®Ø±Ø¬Ø©/{rel_path}")
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ù JSON ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
            json_report_path = os.path.join(session.session_dir, "final_report.json")
            if os.path.exists(json_report_path):
                zipf.write(json_report_path, "ØªÙØ§ØµÙŠÙ„_ØªÙ‚Ù†ÙŠØ©.json")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù README ÙŠØ´Ø±Ø­ Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ
            readme_content = f"""# ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©

## Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø©
- Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù„Ø³Ø©: {session_id}
- ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {session.status}

## Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ø£Ø±Ø´ÙŠÙ

### ğŸ“Š Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
- `ØªÙ‚Ø±ÙŠØ±_Ø´Ø§Ù…Ù„.html`: ØªÙ‚Ø±ÙŠØ± HTML ØªÙØ§Ø¹Ù„ÙŠ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

### ğŸ“ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¯ÙŠØ©
Ù…Ø¬Ù„Ø¯ `ØªÙ‚Ø§Ø±ÙŠØ±_ÙØ±Ø¯ÙŠØ©/` ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
- ØªÙ‚Ø§Ø±ÙŠØ± HTML/MD Ù…Ù†ÙØµÙ„Ø© Ù„ÙƒÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©
- ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„ÙƒÙ„ Ø²ÙˆØ¬ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª

### ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©  
Ù…Ø¬Ù„Ø¯ `Ù†ØµÙˆØµ_Ù…Ø³ØªØ®Ø±Ø¬Ø©/` ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
- Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ØµÙˆØ±
- Ù…Ù„ÙØ§Øª Markdown Ø¨Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©

### ğŸ”§ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
- `ØªÙØ§ØµÙŠÙ„_ØªÙ‚Ù†ÙŠØ©.json`: Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø§Ù… Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬

## ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
1. Ø§ÙØªØ­ `ØªÙ‚Ø±ÙŠØ±_Ø´Ø§Ù…Ù„.html` Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©
2. Ø§Ø³ØªØ¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ÙØ±Ø¯ÙŠØ© Ù„Ù„ØªÙØ§ØµÙŠÙ„
3. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ù‚Ø© OCR

---
ØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©
"""
            
            # Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ù README
            readme_path = os.path.join(session.session_dir, "README.md")
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
            zipf.write(readme_path, "README.md")
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„
        zip_filename = f"ØªÙ‚Ø±ÙŠØ±_Ù…Ù‚Ø§Ø±Ù†Ø©_Ø´Ø§Ù…Ù„_{session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        
        def cleanup_temp_file():
            try:
                os.unlink(temp_zip.name)
                os.unlink(readme_path)
            except:
                pass
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… StreamingResponse Ù„Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù…Ù„Ù ÙˆØ­Ø°ÙÙ‡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
        def generate():
            with open(temp_zip.name, 'rb') as f:
                yield from f
            cleanup_temp_file()
        
        return StreamingResponse(
            generate(),
            media_type="application/zip",
            headers={
                "Content-Disposition": f"attachment; filename={zip_filename}",
                "Content-Length": str(os.path.getsize(temp_zip.name))
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø¶ØºÙˆØ·: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"
        )


async def _generate_comprehensive_html_report(session: AdvancedProcessingSession) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    successful_comparisons = [c for c in session.comparison_results if c['status'] == 'completed']
    failed_comparisons = [c for c in session.comparison_results if c['status'] != 'completed']
    
    average_similarity = 0
    if successful_comparisons:
        average_similarity = sum(c['similarity'] for c in successful_comparisons) / len(successful_comparisons)
    
    total_processing_time = sum(r['processing_time'] for r in session.processing_results if r['status'] == 'completed')
    
    html_content = f"""
<!DOCTYPE html>
<html lang="ar" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 40px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
        }}
        .container {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        .header {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }}
        .header h1 {{
            margin: 0;
            font-size: 2.5em;
            text-shadow: 0 2px 10px rgba(0,0,0,0.3);
        }}
        .header p {{
            margin: 10px 0 0;
            opacity: 0.9;
            font-size: 1.1em;
        }}
        .stats {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            padding: 40px;
            background: #f8fafc;
        }}
        .stat-card {{
            background: white;
            padding: 25px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 4px 15px rgba(0,0,0,0.08);
            border-left: 4px solid #667eea;
        }}
        .stat-value {{
            font-size: 2.5em;
            font-weight: bold;
            color: #667eea;
            margin: 0;
        }}
        .stat-label {{
            color: #64748b;
            margin: 5px 0 0;
            font-weight: 500;
        }}
        .content {{
            padding: 40px;
        }}
        .section {{
            margin-bottom: 40px;
        }}
        .section h2 {{
            color: #1e293b;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin-bottom: 25px;
            font-size: 1.8em;
        }}
        .comparison-card {{
            background: #f8fafc;
            border: 1px solid #e2e8f0;
            border-radius: 10px;
            padding: 25px;
            margin-bottom: 20px;
            transition: all 0.3s ease;
        }}
        .comparison-card:hover {{
            box-shadow: 0 8px 25px rgba(0,0,0,0.1);
            transform: translateY(-2px);
        }}
        .comparison-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }}
        .file-names {{
            font-weight: bold;
            color: #1e293b;
            font-size: 1.1em;
        }}
        .similarity {{
            background: #10b981;
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            font-weight: bold;
        }}
        .similarity.medium {{
            background: #f59e0b;
        }}
        .similarity.low {{
            background: #ef4444;
        }}
        .details {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
            margin-top: 20px;
        }}
        .detail-box {{
            background: white;
            padding: 15px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }}
        .detail-title {{
            font-weight: bold;
            color: #475569;
            margin-bottom: 8px;
        }}
        .extracted-text {{
            background: #f1f5f9;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            max-height: 200px;
            overflow-y: auto;
            white-space: pre-wrap;
            border: 1px solid #cbd5e1;
        }}
        .footer {{
            background: #1e293b;
            color: white;
            text-align: center;
            padding: 25px;
            font-size: 0.9em;
        }}
        .warning {{
            background: #fef3c7;
            border: 1px solid #f59e0b;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 20px;
        }}
        .warning-title {{
            font-weight: bold;
            color: #92400e;
            margin-bottom: 8px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©</h1>
            <p>ØªÙ‚Ø±ÙŠØ± Ù…ÙØµÙ„ Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† Ø§Ù„ÙƒØªØ¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯Ø©</p>
            <p>ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ ÙÙŠ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="stats">
            <div class="stat-card">
                <div class="stat-value">{len(session.old_files) + len(session.new_files)}</div>
                <div class="stat-label">Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{len(successful_comparisons)}</div>
                <div class="stat-label">Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ù†Ø§Ø¬Ø­Ø©</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{average_similarity:.1f}%</div>
                <div class="stat-label">Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡</div>
            </div>
            <div class="stat-card">
                <div class="stat-value">{total_processing_time:.1f}s</div>
                <div class="stat-label">ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©</div>
            </div>
        </div>
        
        <div class="content">
    """
    
    # Ø¥Ø¶Ø§ÙØ© ØªØ­Ø°ÙŠØ± API Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ø®Ø·Ø§Ø¡
    if any('Ø®Ø·Ø£' in c.get('summary', '') for c in successful_comparisons):
        html_content += """
            <div class="warning">
                <div class="warning-title">âš ï¸ ØªÙ†Ø¨ÙŠÙ‡ Ù…Ù‡Ù…</div>
                <p>ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù€ Gemini AI API (50 Ø·Ù„Ø¨/ÙŠÙˆÙ…). Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª ØªØ¸Ù‡Ø± Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø· ÙˆÙ„ÙŠØ³ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ù…ÙØµÙ„.</p>
            </div>
        """
    
    html_content += """
            <div class="section">
                <h2>ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©</h2>
    """
    
    # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©
    for i, comparison in enumerate(successful_comparisons):
        old_file = next((r for r in session.processing_results if r['id'] == comparison['old_file_id']), None)
        new_file = next((r for r in session.processing_results if r['id'] == comparison['new_file_id']), None)
        
        if old_file and new_file:
            similarity_class = "high" if comparison['similarity'] > 70 else "medium" if comparison['similarity'] > 50 else "low"
            
            html_content += f"""
                <div class="comparison-card">
                    <div class="comparison-header">
                        <div class="file-names">{old_file['filename']} â† {new_file['filename']}</div>
                        <div class="similarity {similarity_class}">{comparison['similarity']:.1f}%</div>
                    </div>
                    
                    <div class="details">
                        <div class="detail-box">
                            <div class="detail-title">Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„</div>
                            <p>{comparison.get('summary', 'ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·')}</p>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">Ø§Ù„ØªÙˆØµÙŠØ©</div>
                            <p>{comparison.get('recommendation', 'ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ©')}</p>
                        </div>
                    </div>
                    
                    <div class="details">
                        <div>
                            <div class="detail-title">Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø¯ÙŠÙ… ({old_file['filename']})</div>
                            <div class="extracted-text">{old_file.get('extracted_text', 'Ø§Ù„Ù†Øµ ØºÙŠØ± Ù…ØªØ§Ø­')[:500]}{'...' if len(old_file.get('extracted_text', '')) > 500 else ''}</div>
                        </div>
                        <div>
                            <div class="detail-title">Ø§Ù„Ù†Øµ Ø§Ù„Ø¬Ø¯ÙŠØ¯ ({new_file['filename']})</div>
                            <div class="extracted-text">{new_file.get('extracted_text', 'Ø§Ù„Ù†Øµ ØºÙŠØ± Ù…ØªØ§Ø­')[:500]}{'...' if len(new_file.get('extracted_text', '')) > 500 else ''}</div>
                        </div>
                    </div>
                </div>
            """
    
    html_content += """
            </div>
        </div>
        
        <div class="footer">
            <p>ØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©</p>
            <p>Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ù€ Landing.AI Ù„Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¨ØµØ±ÙŠ Ùˆ Gemini AI Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</p>
        </div>
    </div>
</body>
</html>
    """
    
    return html_content


async def _generate_comprehensive_markdown_report(session: AdvancedProcessingSession) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Markdown Ø´Ø§Ù…Ù„ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    successful_comparisons = [c for c in session.comparison_results if c['status'] == 'completed']
    failed_comparisons = [c for c in session.comparison_results if c['status'] != 'completed']
    
    average_similarity = 0
    if successful_comparisons:
        average_similarity = sum(c['similarity'] for c in successful_comparisons) / len(successful_comparisons)
    
    total_processing_time = sum(r['processing_time'] for r in session.processing_results if r['status'] == 'completed')
    
    markdown_content = f"""# ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©

**ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  
**Ù…Ø¹Ø±Ù Ø§Ù„Ø¬Ù„Ø³Ø©:** {session.session_id}  

---

## ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©

| Ø§Ù„Ù…Ø¤Ø´Ø± | Ø§Ù„Ù‚ÙŠÙ…Ø© |
|---------|--------|
| ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª | {len(session.old_files) + len(session.new_files)} |
| âœ… Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ù†Ø§Ø¬Ø­Ø© | {len(successful_comparisons)} |
| âŒ Ù…Ù‚Ø§Ø±Ù†Ø§Øª ÙØ§Ø´Ù„Ø© | {len(failed_comparisons)} |
| ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ´Ø§Ø¨Ù‡ | {average_similarity:.1f}% |
| â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ | {total_processing_time:.1f} Ø«Ø§Ù†ÙŠØ© |

---
"""

    # Ø¥Ø¶Ø§ÙØ© ØªØ­Ø°ÙŠØ± API Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø£Ø®Ø·Ø§Ø¡
    if any('Ø®Ø·Ø£' in c.get('summary', '') for c in successful_comparisons):
        markdown_content += """
## âš ï¸ ØªÙ†Ø¨ÙŠÙ‡ Ù…Ù‡Ù…

ØªÙ… Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„ÙŠÙˆÙ…ÙŠ Ù„Ù€ Gemini AI API (50 Ø·Ù„Ø¨/ÙŠÙˆÙ…). Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª ØªØ¸Ù‡Ø± Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø· ÙˆÙ„ÙŠØ³ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ù…ÙØµÙ„.

---
"""
    
    markdown_content += """
## ğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©

"""
    
    # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ ÙƒÙ„ Ù…Ù‚Ø§Ø±Ù†Ø©
    for i, comparison in enumerate(successful_comparisons):
        old_file = next((r for r in session.processing_results if r['id'] == comparison['old_file_id']), None)
        new_file = next((r for r in session.processing_results if r['id'] == comparison['new_file_id']), None)
        
        if old_file and new_file:
            similarity_emoji = "ğŸŸ¢" if comparison['similarity'] > 70 else "ğŸŸ¡" if comparison['similarity'] > 50 else "ğŸ”´"
            
            markdown_content += f"""
### {similarity_emoji} Ù…Ù‚Ø§Ø±Ù†Ø© {i+1}: {old_file['filename']} â† {new_file['filename']}

**Ù†Ø³Ø¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡:** {comparison['similarity']:.1f}%  
**Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©:** {comparison['confidence']:.1f}%  
**ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:** {comparison['processing_time']:.1f} Ø«Ø§Ù†ÙŠØ©  

#### ğŸ“ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„
{comparison.get('summary', 'ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙÙ‚Ø·')}

#### ğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ©
{comparison.get('recommendation', 'ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙŠØ¯ÙˆÙŠØ© Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª')}

#### ğŸ“„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬

##### Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… ({old_file['filename']})
```
{old_file.get('extracted_text', 'Ø§Ù„Ù†Øµ ØºÙŠØ± Ù…ØªØ§Ø­')[:1000]}{'...' if len(old_file.get('extracted_text', '')) > 1000 else ''}
```

##### Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ ({new_file['filename']})
```
{new_file.get('extracted_text', 'Ø§Ù„Ù†Øµ ØºÙŠØ± Ù…ØªØ§Ø­')[:1000]}{'...' if len(new_file.get('extracted_text', '')) > 1000 else ''}
```

---
"""
    
    markdown_content += f"""

## ğŸ”§ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªÙ‚Ù†ÙŠØ©

- **Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¨ØµØ±ÙŠ:** Landing.AI
- **Ø®Ø¯Ù…Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„:** Gemini AI  
- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…:** {len(session.old_files)}
- **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯:** {len(session.new_files)}
- **Ù…ØªÙˆØ³Ø· Ø«Ù‚Ø© Ø§Ù„ØªØ¹Ø±Ù Ø§Ù„Ø¨ØµØ±ÙŠ:** {sum(r['confidence'] for r in session.processing_results if r['status'] == 'completed') / len([r for r in session.processing_results if r['status'] == 'completed']) * 100:.1f}%

---

*ØªÙ… Ø¥Ù†ØªØ§Ø¬ Ù‡Ø°Ø§ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ù†Ø¸Ø§Ù… Ù…Ù‚Ø§Ø±Ù† Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ©*
"""
    
    return markdown_content


@router.get("/advanced-processing/{session_id}/download-html")
async def download_html_report(session_id: str):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨ØµÙŠØºØ© HTML
    Download comprehensive HTML report
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    if session.status != "completed":
        raise HTTPException(
            status_code=400,
            detail="Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯"
        )
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML Ø´Ø§Ù…Ù„
        html_content = await _generate_comprehensive_html_report(session)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        filename = f"ØªÙ‚Ø±ÙŠØ±_Ù…Ù‚Ø§Ø±Ù†Ø©_Ø´Ø§Ù…Ù„_{session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        
        return Response(
            content=html_content,
            media_type="text/html; charset=utf-8",
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": "text/html; charset=utf-8"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± HTML: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"
        )


@router.get("/advanced-processing/{session_id}/download-markdown")
async def download_markdown_report(session_id: str):
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„ Ø¨ØµÙŠØºØ© Markdown
    Download comprehensive Markdown report
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    if session.status != "completed":
        raise HTTPException(
            status_code=400,
            detail="Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯"
        )
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Markdown Ø´Ø§Ù…Ù„
        markdown_content = await _generate_comprehensive_markdown_report(session)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        filename = f"ØªÙ‚Ø±ÙŠØ±_Ù…Ù‚Ø§Ø±Ù†Ø©_Ø´Ø§Ù…Ù„_{session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        return Response(
            content=markdown_content,
            media_type="text/markdown; charset=utf-8",
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": "text/markdown; charset=utf-8"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Markdown: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"
        )


@router.delete("/advanced-processing/{session_id}")
async def delete_processing_session(session_id: str):
    """
    Ø­Ø°Ù Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Delete processing session
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    # Ø­Ø°Ù Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
    if session.session_dir and os.path.exists(session.session_dir):
        import shutil
        shutil.rmtree(session.session_dir)
    
    # Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    del processing_sessions[session_id]
    
    logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {session_id}")
    
    return {
        "session_id": session_id,
        "status": "deleted",
        "message": "ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­"
    }


@router.get("/advanced-processing/sessions")
async def list_all_sessions():
    """
    Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    List all processing sessions
    """
    sessions_info = []
    
    for session_id, session in processing_sessions.items():
        sessions_info.append({
            "session_id": session_id,
            "status": session.status,
            "progress": session.progress,
            "created_at": session.created_at.isoformat(),
            "files_count": len(session.old_files) + len(session.new_files),
            "results_count": len(session.processing_results)
        })
    
    return {
        "total_sessions": len(sessions_info),
        "sessions": sessions_info
    } 