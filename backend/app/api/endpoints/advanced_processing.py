"""
Advanced Processing API Endpoints
Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, Form, BackgroundTasks
from typing import Dict, Any, List, Optional
import uuid
import os
import json
from datetime import datetime
from pathlib import Path
from loguru import logger

from app.core.config import get_settings
from app.services.landing_ai_service import LandingAIService
from app.services.gemini_service import GeminiService
from app.models.schemas import (
    ProcessingSessionRequest, ProcessingSessionResponse,
    ProcessingStep, ProcessingResult, ComparisonResult
)

settings = get_settings()
router = APIRouter()

# ØªØ®Ø²ÙŠÙ† Ù…Ø¤Ù‚Øª Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
processing_sessions = {}

class AdvancedProcessingSession:
    """Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.created_at = datetime.now()
        self.status = "initializing"
        self.progress = 0
        self.current_step = "Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©"
        self.processing_steps = [
            ProcessingStep(
                id="init",
                name="Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©",
                status="processing",
                progress=10
            ),
            ProcessingStep(
                id="upload",
                name="Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª",
                status="pending",
                progress=0
            ),
            ProcessingStep(
                id="ocr_old",
                name="OCR - Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…",
                status="pending",
                progress=0,
                max_attempts=4
            ),
            ProcessingStep(
                id="ocr_new", 
                name="OCR - Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯",
                status="pending",
                progress=0,
                max_attempts=4
            ),
            ProcessingStep(
                id="ai_comparison",
                name="Ù…Ù‚Ø§Ø±Ù†Ø© AI",
                status="pending",
                progress=0
            ),
            ProcessingStep(
                id="report_generation",
                name="Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±",
                status="pending",
                progress=0
            )
        ]
        self.old_files = []
        self.new_files = []
        self.processing_results = []
        self.comparison_results = []
        self.logs = []
        self.session_dir = None
        
    def add_log(self, message: str, level: str = "info"):
        """Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ Ø¬Ø¯ÙŠØ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.logs.append(log_entry)
        
        # Ø·Ø¨Ø§Ø¹Ø© ÙÙŠ ÙˆØ­Ø¯Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø£ÙŠØ¶Ø§Ù‹
        if level == "error":
            logger.error(message)
        elif level == "warning":
            logger.warning(message)
        else:
            logger.info(message)
    
    def update_step(self, step_id: str, **updates):
        """ØªØ­Ø¯ÙŠØ« Ø®Ø·ÙˆØ© Ù…Ø¹Ø§Ù„Ø¬Ø©"""
        for step in self.processing_steps:
            if step.id == step_id:
                for key, value in updates.items():
                    setattr(step, key, value)
                break
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
        completed_steps = sum(1 for step in self.processing_steps if step.status == "completed")
        total_steps = len(self.processing_steps)
        self.progress = (completed_steps / total_steps) * 100
    
    def get_status(self) -> Dict[str, Any]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
        return {
            "session_id": self.session_id,
            "status": self.status,
            "progress": self.progress,
            "current_step": self.current_step,
            "processing_steps": [step.model_dump() for step in self.processing_steps],
            "old_files_count": len(self.old_files),
            "new_files_count": len(self.new_files),
            "processing_results_count": len(self.processing_results),
            "comparison_results_count": len(self.comparison_results),
            "logs": self.logs[-20:],  # Ø¢Ø®Ø± 20 Ø³Ø¬Ù„
            "created_at": self.created_at.isoformat(),
            "updated_at": datetime.now().isoformat()
        }


@router.post("/advanced-processing/create-session", response_model=ProcessingSessionResponse)
async def create_processing_session(request: ProcessingSessionRequest):
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©
    Create new advanced processing session
    """
    try:
        session_id = str(uuid.uuid4())
        session = AdvancedProcessingSession(session_id)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø©
        session_dir = os.path.join(settings.UPLOAD_DIR, "advanced_sessions", session_id)
        os.makedirs(session_dir, exist_ok=True)
        session.session_dir = session_dir
        
        # Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø©
        processing_sessions[session_id] = session
        
        session.add_log(f"ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©: {session_id}")
        session.update_step("init", status="completed", progress=100)
        session.current_step = "Ø§Ù†ØªØ¸Ø§Ø± Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª"
        session.status = "waiting_for_files"
        
        logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙ‚Ø¯Ù…Ø©: {session_id}")
        
        return ProcessingSessionResponse(
            session_id=session_id,
            status="created",
            message="ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ø¨Ù†Ø¬Ø§Ø­"
        )
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
        )


@router.post("/advanced-processing/{session_id}/upload-files")
async def upload_files_to_session(
    session_id: str,
    old_files: List[UploadFile] = File(...),
    new_files: List[UploadFile] = File(...),
    background_tasks: BackgroundTasks = None
):
    """
    Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¥Ù„Ù‰ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Upload files to processing session
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    try:
        session.add_log("ğŸ“¤ Ø¨Ø¯Ø¡ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª...")
        session.update_step("upload", status="processing", progress=20)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ù„Ù„Ù…Ù„ÙØ§Øª
        old_files_dir = os.path.join(session.session_dir, "old_files")
        new_files_dir = os.path.join(session.session_dir, "new_files")
        os.makedirs(old_files_dir, exist_ok=True)
        os.makedirs(new_files_dir, exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        for i, file in enumerate(old_files):
            file_path = os.path.join(old_files_dir, f"{i}_{file.filename}")
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            session.old_files.append({
                "id": f"old_{i}",
                "filename": file.filename,
                "path": file_path,
                "size": len(content),
                "uploaded_at": datetime.now().isoformat()
            })
            
            session.add_log(f"ğŸ“ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ…: {file.filename}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        for i, file in enumerate(new_files):
            file_path = os.path.join(new_files_dir, f"{i}_{file.filename}")
            with open(file_path, "wb") as f:
                content = await file.read()
                f.write(content)
            
            session.new_files.append({
                "id": f"new_{i}",
                "filename": file.filename,
                "path": file_path,
                "size": len(content),
                "uploaded_at": datetime.now().isoformat()
            })
            
            session.add_log(f"ğŸ“ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯: {file.filename}")
        
        session.update_step("upload", status="completed", progress=100)
        session.current_step = "Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© OCR"
        session.status = "files_uploaded"
        
        session.add_log(f"âœ… ØªÙ… Ø±ÙØ¹ {len(old_files)} Ù…Ù„Ù Ù‚Ø¯ÙŠÙ… Ùˆ {len(new_files)} Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯")
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
        if background_tasks:
            background_tasks.add_task(process_files_background, session_id)
        
        return {
            "session_id": session_id,
            "status": "files_uploaded",
            "old_files_count": len(old_files),
            "new_files_count": len(new_files),
            "message": "ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­ ÙˆØ¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"
        }
        
    except Exception as e:
        session.add_log(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}", "error")
        session.update_step("upload", status="error")
        session.status = "error"
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}"
        )


async def process_files_background(session_id: str):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©"""
    session = processing_sessions[session_id]
    
    try:
        session.add_log("ğŸ” Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© OCR Ù„Ù„Ù…Ù„ÙØ§Øª...")
        session.status = "processing"
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        landing_service = LandingAIService()
        gemini_service = GeminiService()
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        session.add_log("ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ù‚Ø¯ÙŠÙ…...")
        session.update_step("ocr_old", status="processing", progress=10)
        
        for i, file_info in enumerate(session.old_files):
            session.add_log(f"ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {i+1}: {file_info['filename']}")
            session.update_step("ocr_old", attempts=i+1, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {file_info['filename']}")
            
            try:
                result = await landing_service.extract_from_file(
                    file_info['path'],
                    os.path.join(session.session_dir, "ocr_results")
                )
                
                processing_result = {
                    "id": file_info['id'],
                    "filename": file_info['filename'],
                    "status": "completed" if result.success else "error",
                    "confidence": result.confidence_score,
                    "text_length": len(result.markdown_content),
                    "word_count": result.text_elements,
                    "processing_time": result.processing_time,
                    "language": "ara" if result.success else "unknown",
                    "extracted_text": result.markdown_content,
                    "structured_analysis": result.structured_analysis.model_dump() if result.structured_analysis else None
                }
                
                session.processing_results.append(processing_result)
                session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {i+1}: Ø«Ù‚Ø© {result.confidence_score:.1%}")
                
            except Exception as e:
                session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… {i+1}: {str(e)}", "error")
        
        session.update_step("ocr_old", status="completed", progress=100)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        session.add_log("ğŸ“„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯...")
        session.update_step("ocr_new", status="processing", progress=10)
        
        for i, file_info in enumerate(session.new_files):
            session.add_log(f"ğŸ” Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {i+1}: {file_info['filename']}")
            session.update_step("ocr_new", attempts=i+1, details=f"Ù…Ø¹Ø§Ù„Ø¬Ø© {file_info['filename']}")
            
            try:
                result = await landing_service.extract_from_file(
                    file_info['path'],
                    os.path.join(session.session_dir, "ocr_results")
                )
                
                processing_result = {
                    "id": file_info['id'],
                    "filename": file_info['filename'],
                    "status": "completed" if result.success else "error",
                    "confidence": result.confidence_score,
                    "text_length": len(result.markdown_content),
                    "word_count": result.text_elements,
                    "processing_time": result.processing_time,
                    "language": "ara" if result.success else "unknown",
                    "extracted_text": result.markdown_content,
                    "structured_analysis": result.structured_analysis.model_dump() if result.structured_analysis else None
                }
                
                session.processing_results.append(processing_result)
                session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {i+1}: Ø«Ù‚Ø© {result.confidence_score:.1%}")
                
            except Exception as e:
                session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯ {i+1}: {str(e)}", "error")
        
        session.update_step("ocr_new", status="completed", progress=100)
        
        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
        session.add_log("ğŸ¤– Ø¨Ø¯Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI...")
        session.update_step("ai_comparison", status="processing", progress=20)
        
        old_results = [r for r in session.processing_results if r['id'].startswith('old_')]
        new_results = [r for r in session.processing_results if r['id'].startswith('new_')]
        
        for i, (old_result, new_result) in enumerate(zip(old_results, new_results)):
            if old_result['status'] == 'completed' and new_result['status'] == 'completed':
                session.add_log(f"ğŸ”„ Ù…Ù‚Ø§Ø±Ù†Ø© {old_result['filename']} Ù…Ø¹ {new_result['filename']}")
                
                try:
                    comparison = await gemini_service.compare_texts(
                        old_result['extracted_text'],
                        new_result['extracted_text']
                    )
                    
                    comparison_result = {
                        "id": f"comparison_{i}",
                        "old_file_id": old_result['id'],
                        "new_file_id": new_result['id'],
                        "similarity": comparison.similarity_percentage,
                        "confidence": comparison.confidence_score,
                        "processing_time": comparison.processing_time,
                        "changes": comparison.content_changes,
                        "summary": comparison.summary,
                        "recommendation": comparison.recommendation,
                        "detailed_analysis": comparison.detailed_analysis,
                        "status": "completed"
                    }
                    
                    session.comparison_results.append(comparison_result)
                    session.add_log(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: ØªØ´Ø§Ø¨Ù‡ {comparison.similarity_percentage}%")
                    
                except Exception as e:
                    session.add_log(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}", "error")
        
        session.update_step("ai_comparison", status="completed", progress=100)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        session.add_log("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ...")
        session.update_step("report_generation", status="processing", progress=50)
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        report_path = os.path.join(session.session_dir, "final_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump({
                "session_info": {
                    "session_id": session_id,
                    "created_at": session.created_at.isoformat(),
                    "completed_at": datetime.now().isoformat()
                },
                "processing_results": session.processing_results,
                "comparison_results": session.comparison_results,
                "logs": session.logs
            }, f, ensure_ascii=False, indent=2)
        
        session.update_step("report_generation", status="completed", progress=100)
        session.status = "completed"
        session.current_step = "Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©"
        session.add_log("ğŸ‰ Ø§ÙƒØªÙ…Ù„Øª Ø¬Ù…ÙŠØ¹ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        
    except Exception as e:
        session.add_log(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}", "error")
        session.status = "error"
        logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¬Ù„Ø³Ø© {session_id}: {e}")


@router.get("/advanced-processing/{session_id}/status")
async def get_processing_status(session_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Get processing session status
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    return session.get_status()


@router.get("/advanced-processing/{session_id}/results")
async def get_processing_results(session_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©
    Get complete processing results
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    if session.status != "completed":
        raise HTTPException(
            status_code=400,
            detail="Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯"
        )
    
    return {
        "session_id": session_id,
        "status": session.status,
        "processing_results": session.processing_results,
        "comparison_results": session.comparison_results,
        "statistics": {
            "total_files": len(session.old_files) + len(session.new_files),
            "completed_files": len([r for r in session.processing_results if r['status'] == 'completed']),
            "average_confidence": sum(r['confidence'] for r in session.processing_results if r['status'] == 'completed') / len([r for r in session.processing_results if r['status'] == 'completed']) if session.processing_results else 0,
            "total_processing_time": sum(r['processing_time'] for r in session.processing_results if r['status'] == 'completed'),
            "completed_comparisons": len([c for c in session.comparison_results if c['status'] == 'completed'])
        },
        "logs": session.logs
    }


@router.delete("/advanced-processing/{session_id}")
async def delete_processing_session(session_id: str):
    """
    Ø­Ø°Ù Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    Delete processing session
    """
    if session_id not in processing_sessions:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
    
    session = processing_sessions[session_id]
    
    # Ø­Ø°Ù Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
    if session.session_dir and os.path.exists(session.session_dir):
        import shutil
        shutil.rmtree(session.session_dir)
    
    # Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    del processing_sessions[session_id]
    
    logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {session_id}")
    
    return {
        "session_id": session_id,
        "status": "deleted",
        "message": "ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø¬Ø§Ø­"
    }


@router.get("/advanced-processing/sessions")
async def list_all_sessions():
    """
    Ø¹Ø±Ø¶ Ø¬Ù…ÙŠØ¹ Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    List all processing sessions
    """
    sessions_info = []
    
    for session_id, session in processing_sessions.items():
        sessions_info.append({
            "session_id": session_id,
            "status": session.status,
            "progress": session.progress,
            "created_at": session.created_at.isoformat(),
            "files_count": len(session.old_files) + len(session.new_files),
            "results_count": len(session.processing_results)
        })
    
    return {
        "total_sessions": len(sessions_info),
        "sessions": sessions_info
    } 