"""
API endpoints Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
Comparison API Endpoints
"""

from fastapi import APIRouter, HTTPException, Depends, UploadFile, File, Form, Response
from typing import Dict, Any, Optional, List
import uuid
from datetime import datetime
from loguru import logger
import asyncio
import os
import json
import math

from app.core.config import get_settings
from app.models.schemas import (
    StartComparisonRequest, StartComparisonResponse, 
    ComparisonSessionResult, ProcessingProgress,
    JobStatus, ErrorResponse, ProcessingStage
)
from celery_app.tasks import process_file_comparison
from app.db.database import SessionLocal
from app.db import crud


settings = get_settings()
router = APIRouter()

# ØªØ®Ø²ÙŠÙ† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ù…Ø¤Ù‚ØªØ§Ù‹ (ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø³ÙŠÙƒÙˆÙ† ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª)
jobs_store = {}

# ØªØ®Ø²ÙŠÙ† Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø§Øª
sessions_store = {}


def clean_json_values(obj):
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚ÙŠÙ… Ù„ØªÙƒÙˆÙ† Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ JSON
    Clean values to be JSON compliant
    """
    if isinstance(obj, dict):
        return {k: clean_json_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_json_values(item) for item in obj]
    elif isinstance(obj, float):
        if math.isnan(obj) or math.isinf(obj):
            return None
        return obj
    elif hasattr(obj, '__dict__'):
        return clean_json_values(obj.__dict__)
    else:
        return obj


@router.post("/compare/start", response_model=StartComparisonResponse)
async def start_comparison(request: StartComparisonRequest):
    """
    Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    Start comparison process
    """
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
        if not request.old_files or not request.new_files:
            raise HTTPException(
                status_code=400, 
                detail="ÙŠØ¬Ø¨ ØªØ­Ø¯ÙŠØ¯ Ù…Ù„ÙØ§Øª Ù„Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙˆØ§Ù„Ø¬Ø¯ÙŠØ¯"
            )
        
        if len(request.old_files) != len(request.new_files):
            raise HTTPException(
                status_code=400,
                detail="Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ³Ø§ÙˆÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"
            )
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ÙˆØ¸ÙŠÙØ© Ø¬Ø¯ÙŠØ¯
        job_id = str(uuid.uuid4())
        
        logger.info(f"ðŸš€ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ø¯ÙŠØ¯Ø© - Job: {job_id}, Session: {request.session_id}")
        logger.info(f"ðŸ“ Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª: {len(request.old_files)} Ù‚Ø¯ÙŠÙ…, {len(request.new_files)} Ø¬Ø¯ÙŠØ¯")
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙˆØ¸ÙŠÙØ©
        job_info = {
            "job_id": job_id,
            "session_id": request.session_id,
            "status": JobStatus.PENDING,
            "old_files": request.old_files,
            "new_files": request.new_files,
            "comparison_settings": request.comparison_settings,
            "created_at": datetime.now(),
            "updated_at": datetime.now(),
            "progress": 0,
            "current_stage": ProcessingStage.INITIALIZATION.value,
            "current_file": None,
            "error_message": None,
            "result": None
        }
        
        jobs_store[job_id] = job_info
        
        # Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Celery
        try:
            task = process_file_comparison.delay(
                job_id=job_id,
                session_id=request.session_id,
                old_files=request.old_files,
                new_files=request.new_files
            )
            
            # Ø­ÙØ¸ Ù…Ø¹Ø±Ù Ø§Ù„Ù…Ù‡Ù…Ø©
            job_info["celery_task_id"] = task.id
            job_info["status"] = JobStatus.PROCESSING
            
            logger.info(f"âœ… ØªÙ… Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Celery: {task.id} Ù„Ù„ÙˆØ¸ÙŠÙØ© {job_id}")
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ù…Ù‡Ù…Ø© Celery: {e}")
            job_info["status"] = JobStatus.FAILED
            job_info["error_message"] = f"ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}"
            raise HTTPException(
                status_code=500,
                detail=f"ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}"
            )
        
        return StartComparisonResponse(
            job_id=job_id,
            session_id=request.session_id,
            status=JobStatus.PROCESSING,
            message="ØªÙ… Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ø¬Ø§Ø­"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}"
        )


@router.get("/compare/status/{job_id}", response_model=ProcessingProgress)
async def get_comparison_status(job_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    Get comparison status
    """
    logger.debug(f"ðŸ” Ø¬Ù„Ø¨ Ø§Ù„Ø­Ø§Ù„Ø© Ù„Ù„ÙˆØ¸ÙŠÙØ©: {job_id}")
    try:
        if job_id not in jobs_store:
            logger.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© Ø¬Ù„Ø¨ ÙˆØ¸ÙŠÙØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {job_id}")
            raise HTTPException(status_code=404, detail="Ø§Ù„ÙˆØ¸ÙŠÙØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        job_info = jobs_store[job_id]
        logger.debug(f"â„¹ï¸ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù„Ù„ÙˆØ¸ÙŠÙØ©: {job_info}")
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙˆØ¸ÙŠÙØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø© CeleryØŒ ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„ØªÙ‡Ø§
        if "celery_task_id" in job_info:
            from celery_app.worker import celery_app
            task = celery_app.AsyncResult(job_info["celery_task_id"])
            logger.debug(f"ðŸ“Š Ø­Ø§Ù„Ø© Ù…Ù‡Ù…Ø© Celery [{task.id}]: {task.state}")
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Celery
            if task.state == "PENDING":
                job_info["status"] = JobStatus.PENDING
            elif task.state == "PROGRESS":
                job_info["status"] = JobStatus.PROCESSING
                if isinstance(task.info, dict):
                    logger.debug(f"ðŸ“ˆ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù… Ù…Ù† Celery: {task.info}")
                    job_info["progress"] = task.info.get("progress", job_info["progress"])
                    job_info["message"] = task.info.get("message", job_info.get("message"))
                    job_info["current_stage"] = task.info.get("current_stage", job_info.get("current_stage"))
                    job_info["current_file"] = task.info.get("current_file", job_info.get("current_file"))
            elif task.state == "SUCCESS":
                job_info["status"] = JobStatus.COMPLETED
                logger.debug(f"âœ… Ù…Ù‡Ù…Ø© Celery Ù†Ø§Ø¬Ø­Ø©. Ø§Ù„Ù†ØªÙŠØ¬Ø©: {task.result}")
                job_info["result"] = task.result
                job_info["progress"] = 100
                job_info["message"] = "Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­"
            elif task.state == "FAILURE":
                job_info["status"] = JobStatus.FAILED
                logger.error(f"â˜ ï¸ ÙØ´Ù„ Ù…Ù‡Ù…Ø© Celery. Ø§Ù„Ø®Ø·Ø£: {task.info}")
                job_info["error_message"] = str(task.info) if task.info else "ÙØ´Ù„ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"
        
        job_info["updated_at"] = datetime.now()
        
        progress_response = ProcessingProgress(
            job_id=job_id,
            session_id=job_info["session_id"],
            status=job_info["status"],
            current_stage=job_info.get("current_stage", "UNKNOWN"),
            progress_percentage=job_info.get("progress", 0),
            current_file=job_info.get("current_file"),
            files_processed=job_info.get("files_processed", 0),
            total_files=len(job_info["old_files"]) + len(job_info["new_files"]),
            estimated_time_remaining=job_info.get("estimated_time_remaining"),
            message=job_info.get("message"),
            error_message=job_info.get("error_message"),
            created_at=job_info["created_at"],
            updated_at=job_info["updated_at"]
        )
        logger.debug(f"ðŸ“¬ Ø¥Ø±Ø³Ø§Ù„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø­Ø§Ù„Ø©: {progress_response}")
        return progress_response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.opt(exception=True).error(f"âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­ ÙÙŠ Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ© {job_id}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ©: {str(e)}"
        )


@router.get("/compare/result/{job_id}", response_model=ComparisonSessionResult)
async def get_comparison_result(job_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    Get comparison result
    """
    try:
        if job_id not in jobs_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„ÙˆØ¸ÙŠÙØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        job_info = jobs_store[job_id]
        
        if job_info["status"] != JobStatus.COMPLETED:
            raise HTTPException(
                status_code=400,
                detail=f"Ø§Ù„ÙˆØ¸ÙŠÙØ© Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¨Ø¹Ø¯. Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: {job_info['status']}"
            )
        
        if not job_info.get("result"):
            raise HTTPException(status_code=404, detail="Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©")
        
        result = job_info["result"]
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ ComparisonSessionResult
        comparison_result = ComparisonSessionResult(
            session_id=job_info["session_id"],
            job_id=job_id,
            session_name=f"Ù…Ù‚Ø§Ø±Ù†Ø©_{job_id[:8]}",
            status=JobStatus.COMPLETED,
            total_files=result.get("total_files", 0),
            processed_files=result.get("processed_files", 0),
            identical_files=len([r for r in result.get("results", []) if r.get("overall_similarity", 0) > 95]),
            changed_files=len([r for r in result.get("results", []) if r.get("overall_similarity", 0) <= 95]),
            failed_files=result.get("failed_files", 0),
            average_visual_similarity=result.get("summary", {}).get("average_visual_similarity", 0),
            average_text_similarity=result.get("summary", {}).get("average_text_similarity", 0),
            average_overall_similarity=(
                result.get("summary", {}).get("average_visual_similarity", 0) +
                result.get("summary", {}).get("average_text_similarity", 0)
            ) / 2,
            file_results=[],  # Ø³ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ Ù‡Ø°Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
            total_processing_time=sum(r.get("visual_comparison", {}).get("processing_time", 0) + 
                                    r.get("text_comparison", {}).get("processing_time", 0) 
                                    for r in result.get("results", [])),
            created_at=job_info["created_at"],
            completed_at=datetime.fromisoformat(result.get("completed_at", datetime.now().isoformat()))
        )
        
        logger.info(f"ðŸ“Š ØªÙ… Ø¬Ù„Ø¨ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù„Ù„ÙˆØ¸ÙŠÙØ©: {job_id}")
        return comparison_result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙˆØ¸ÙŠÙØ© {job_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}"
        )


@router.delete("/compare/job/{job_id}")
async def cancel_comparison(job_id: str):
    """
    Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    Cancel comparison process
    """
    try:
        if job_id not in jobs_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„ÙˆØ¸ÙŠÙØ© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        job_info = jobs_store[job_id]
        
        # Ø¥Ù„ØºØ§Ø¡ Ù…Ù‡Ù…Ø© Celery Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„
        if "celery_task_id" in job_info and job_info["status"] == JobStatus.PROCESSING:
            from celery_app.worker import celery_app
            celery_app.control.revoke(job_info["celery_task_id"], terminate=True)
            logger.info(f"ðŸ›‘ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ù…Ù‡Ù…Ø© Celery: {job_info['celery_task_id']}")
        
        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„ÙˆØ¸ÙŠÙØ©
        job_info["status"] = JobStatus.CANCELLED
        job_info["updated_at"] = datetime.now()
        job_info["message"] = "ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…"
        
        logger.info(f"ðŸ›‘ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙˆØ¸ÙŠÙØ©: {job_id}")
        
        return {
            "success": True,
            "message": "ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ø¬Ø§Ø­",
            "job_id": job_id,
            "cancelled_at": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙˆØ¸ÙŠÙØ© {job_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ÙˆØ¸ÙŠÙØ©: {str(e)}"
        )


@router.get("/compare/jobs")
async def list_all_jobs():
    """
    Ù‚Ø§Ø¦Ù…Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù
    List all jobs
    """
    try:
        jobs_list = []
        for job_id, job_info in jobs_store.items():
            jobs_list.append({
                "job_id": job_id,
                "session_id": job_info["session_id"],
                "status": job_info["status"],
                "progress": job_info.get("progress", 0),
                "current_stage": job_info.get("current_stage"),
                "total_files": len(job_info["old_files"]),
                "created_at": job_info["created_at"],
                "updated_at": job_info["updated_at"]
            })
        
        return {
            "jobs": jobs_list,
            "total_jobs": len(jobs_list),
            "active_jobs": len([j for j in jobs_list if j["status"] == JobStatus.PROCESSING]),
            "completed_jobs": len([j for j in jobs_list if j["status"] == JobStatus.COMPLETED]),
            "failed_jobs": len([j for j in jobs_list if j["status"] == JobStatus.FAILED])
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆØ¸Ø§Ø¦Ù: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙˆØ¸Ø§Ø¦Ù: {str(e)}"
        )


@router.post("/compare/create-session")
async def create_comparison_session(
    old_image: UploadFile = File(...),
    new_image: UploadFile = File(...)
):
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø¹ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±
    Create new comparison session with image uploads
    """
    try:
        session_id = str(uuid.uuid4())
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù„Ù„Ø¬Ù„Ø³Ø©
        session_dir = os.path.join(settings.UPLOAD_DIR, session_id)
        os.makedirs(session_dir, exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±
        old_image_path = os.path.join(session_dir, f"old_image_{old_image.filename}")
        new_image_path = os.path.join(session_dir, f"new_image_{new_image.filename}")
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„ÙØ§Øª
        with open(old_image_path, "wb") as f:
            content = await old_image.read()
            f.write(content)
            
        with open(new_image_path, "wb") as f:
            content = await new_image.read()
            f.write(content)
        
        # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
        session_info = {
            "session_id": session_id,
            "created_at": datetime.now().isoformat(),
            "status": "created",
            "uploaded_files": {
                "old": {
                    "filename": old_image.filename,
                    "path": old_image_path,
                    "size": os.path.getsize(old_image_path)
                },
                "new": {
                    "filename": new_image.filename,
                    "path": new_image_path,
                    "size": os.path.getsize(new_image_path)
                }
            }
        }
        
        sessions_store[session_id] = session_info
        
        logger.info(f"ðŸ†• ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¬Ø¯ÙŠØ¯Ø©: {session_id}")
        logger.info(f"ðŸ“ ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª: {old_image.filename}, {new_image.filename}")
        
        return {
            "session_id": session_id,
            "status": "created",
            "message": "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ø¬Ø§Ø­",
            "files_uploaded": {
                "old_image": old_image.filename,
                "new_image": new_image.filename
            }
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}"
        )


@router.post("/compare/extract-text/{session_id}/{file_type}")
async def extract_text_from_image(session_id: str, file_type: str):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø©
    Extract text from image using OCR
    """
    try:
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        if file_type not in session["uploaded_files"] or not session["uploaded_files"][file_type]:
            raise HTTPException(
                status_code=400, 
                detail=f"Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ ØµÙˆØ±Ø© {file_type} Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}"
            )
        
        uploaded_file = session["uploaded_files"][file_type]
        image_path = uploaded_file["path"]
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø© Landing AI Ù„Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        from app.services.landing_ai_service import LandingAIService
        
        logger.info(f"ðŸš€ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© {file_type} Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI...")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Landing AI
        landing_ai_service = LandingAIService()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI
        extraction_result = await landing_ai_service.extract_from_file(
            file_path=image_path,
            job_id=session_id
        )
        
        if not extraction_result.success:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {extraction_result.error_message}")
            raise HTTPException(
                status_code=500,
                detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {extraction_result.error_message}"
            )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        ocr_result = {
            "success": True,
            "text": extraction_result.markdown_content or "Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ",
            "confidence": extraction_result.confidence_score,
            "language": "ar",
            "character_count": len(extraction_result.markdown_content or ""),
            "word_count": len((extraction_result.markdown_content or "").split()),
            "processing_time": extraction_result.processing_time,
            "image_info": {
                "width": 800,  # ÙŠÙ…ÙƒÙ† ØªØ­Ø³ÙŠÙ† Ù‡Ø°Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹
                "height": 600,
                "format": "PNG",
                "size_bytes": uploaded_file["size"]
            },
            "extraction_details": {
                "total_chunks": extraction_result.total_chunks,
                "chunks_by_type": extraction_result.chunks_by_type,
                "text_elements": extraction_result.text_elements,
                "table_elements": extraction_result.table_elements,
                "image_elements": extraction_result.image_elements
            }
        }
        
        # Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© OCR ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        session["ocr_results"] = session.get("ocr_results", {})
        session["ocr_results"][file_type] = ocr_result
        
        logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© {file_type} Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")
        logger.info(f"ðŸ“Š ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {extraction_result.word_count if hasattr(extraction_result, 'word_count') else len((extraction_result.markdown_content or '').split())} ÙƒÙ„Ù…Ø©ØŒ Ø«Ù‚Ø©: {extraction_result.confidence_score:.2f}")
        
        return ocr_result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ: {str(e)}"
        )


@router.post("/compare/analyze/{session_id}")
async def analyze_comparison(session_id: str):
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    AI-powered comparison analysis
    """
    try:
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
        ocr_results = session.get("ocr_results", {})
        old_text = ocr_results.get("old")
        new_text = ocr_results.get("new")
        
        if not old_text or not new_text:
            raise HTTPException(
                status_code=400, 
                detail="ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„ØµÙˆØ±ØªÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹"
            )
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø© Gemini Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        from app.services.gemini_service import GeminiService
        
        logger.info(f"ðŸ¤– Ø¨Ø¯Ø¡ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini AI...")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ù†ØªØ§Ø¦Ø¬ OCR
        old_extracted_text = old_text.get("text", "")
        new_extracted_text = new_text.get("text", "")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Gemini
        gemini_service = GeminiService()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        comparison_context = {
            "domain": "education",
            "content_type": "curriculum",
            "language": "arabic",
            "analysis_type": "educational_content_comparison",
            "old_file_info": {
                "character_count": old_text.get("character_count", 0),
                "word_count": old_text.get("word_count", 0),
                "confidence": old_text.get("confidence", 0)
            },
            "new_file_info": {
                "character_count": new_text.get("character_count", 0),
                "word_count": new_text.get("word_count", 0),
                "confidence": new_text.get("confidence", 0)
            }
        }
        
        logger.info(f"ðŸ“ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ: Ø§Ù„Ù‚Ø¯ÙŠÙ… ({len(old_extracted_text)} Ø­Ø±Ù), Ø§Ù„Ø¬Ø¯ÙŠØ¯ ({len(new_extracted_text)} Ø­Ø±Ù)")
        
        # ØªØ´ØºÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini
        comparison_result = await gemini_service.compare_texts(
            old_text=old_extracted_text,
            new_text=new_extracted_text,
            context=comparison_context
        )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        analysis_result = {
            "similarity_percentage": comparison_result.similarity_percentage,
            "content_changes": comparison_result.content_changes,
            "questions_changes": comparison_result.questions_changes,
            "major_differences": comparison_result.major_differences,
            "added_content": comparison_result.added_content,
            "removed_content": comparison_result.removed_content,
            "summary": comparison_result.summary,
            "recommendation": comparison_result.recommendation,
            "detailed_analysis": comparison_result.detailed_analysis,
            "processing_time": comparison_result.processing_time,
            "confidence_score": comparison_result.confidence_score,
            "old_text_length": comparison_result.old_text_length,
            "new_text_length": comparison_result.new_text_length,
            "common_words_count": comparison_result.common_words_count,
            "unique_old_words": comparison_result.unique_old_words,
            "unique_new_words": comparison_result.unique_new_words,
            "service_used": comparison_result.service_used,
            "examples_changes": getattr(comparison_result, 'examples_changes', []),
            "modified_content": getattr(comparison_result, 'modified_content', [])
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        session["analysis_result"] = analysis_result
        session["status"] = "completed"
        
        logger.info(f"âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")
        logger.info(f"ðŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {comparison_result.similarity_percentage:.1f}% ØªØ´Ø§Ø¨Ù‡ØŒ Ø«Ù‚Ø©: {comparison_result.confidence_score:.2f}")
        
        return analysis_result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {str(e)}"
        )


@router.get("/compare/download-report/{session_id}")
async def download_report(session_id: str, format: str = "html"):
    """
    ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØµÙŠØºØ© HTML Ø£Ùˆ Markdown
    Download comparison report in HTML or Markdown format
    """
    try:
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        
        if session["status"] != "completed":
            raise HTTPException(
                status_code=400,
                detail="Ù„Ù… ØªÙƒØªÙ…Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø¹Ø¯"
            )
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø­Ø³Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        from app.services.enhanced_report_service import EnhancedReportService, ReportData
        from app.services.visual_comparison_service import VisualComparisonService
        from fastapi.responses import Response
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©
        ocr_results = session.get("ocr_results", {})
        analysis_result = session.get("analysis_result", {})
        uploaded_files = session.get("uploaded_files", {})
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¨ØµØ±ÙŠ
        from app.services.visual_comparison_service import enhanced_visual_comparison_service
        visual_similarity = 95.0  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©ØŒ Ø³ÙŠØªÙ… Ø­Ø³Ø§Ø¨Ù‡Ø§ Ù…Ù† Ø§Ù„ØµÙˆØ±
        
        if "old" in uploaded_files and "new" in uploaded_files:
            try:
                old_file_path = uploaded_files["old"]["path"]
                new_file_path = uploaded_files["new"]["path"]
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ù…Ø¤Ù‚Øª Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©
                temp_output_dir = os.path.join(settings.UPLOAD_DIR, session_id, "temp_visual")
                os.makedirs(temp_output_dir, exist_ok=True)
                
                visual_result = await enhanced_visual_comparison_service.compare_images(
                    old_image_path=old_file_path, 
                    new_image_path=new_file_path,
                    output_dir=temp_output_dir
                )
                visual_similarity = visual_result.similarity_score
            except Exception as e:
                logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø¨ØµØ±ÙŠ: {e}")
        
        # ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ±
        report_data = ReportData(
            session_id=session_id,
            old_image_name=uploaded_files.get("old", {}).get("filename", "ØµÙˆØ±Ø© Ù‚Ø¯ÙŠÙ…Ø©"),
            new_image_name=uploaded_files.get("new", {}).get("filename", "ØµÙˆØ±Ø© Ø¬Ø¯ÙŠØ¯Ø©"),
            old_extracted_text=ocr_results.get("old", {}).get("text", ""),
            new_extracted_text=ocr_results.get("new", {}).get("text", ""),
            visual_similarity=visual_similarity,
            text_analysis=analysis_result,
            processing_time={
                "old_ocr": ocr_results.get("old", {}).get("processing_time", 0),
                "new_ocr": ocr_results.get("new", {}).get("processing_time", 0),
                "comparison": analysis_result.get("processing_time", 0)
            },
            confidence_scores={
                "old_confidence": ocr_results.get("old", {}).get("confidence", 0),
                "new_confidence": ocr_results.get("new", {}).get("confidence", 0)
            }
        )
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
        report_service = EnhancedReportService()
        
        # Ø¥Ù†ØªØ§Ø¬ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
        report_paths = await report_service.generate_comprehensive_report(
            session_id=session_id,
            report_data=report_data,
            include_extracted_text=True,
            include_visual_analysis=True
        )
        
        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
        if format.lower() == "md" or format.lower() == "markdown":
            file_path = report_paths["markdown_path"]
            media_type = "text/markdown"
            filename = f"ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©_{session_id}.md"
        elif format.lower() == "txt" or format.lower() == "text":
            file_path = report_paths["extracted_text_path"]
            media_type = "text/plain"
            filename = f"Ø§Ù„Ù†ØµÙˆØµ_Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©_{session_id}.md"
        else:  # HTML Ø§ÙØªØ±Ø§Ø¶ÙŠ
            file_path = report_paths["html_path"]
            media_type = "text/html"
            filename = f"ØªÙ‚Ø±ÙŠØ±_Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©_{session_id}.html"
        
        # Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù„Ù
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        logger.info(f"ðŸ“„ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± {format.upper()} Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")

        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­ØªÙ‰ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø±Ø¬ÙˆØ¹ Ø¥Ù„ÙŠÙ‡ Ù„Ø§Ø­Ù‚Ø§Ù‹
        try:
            from app.services.report_storage_service import save_report_to_db
            await save_report_to_db(
                session_id=session_id,
                report_format=format.lower(),
                content=content,
                analysis_result=analysis_result,
            )
        except Exception as save_exc:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {save_exc}")

        return Response(
            content=content.encode('utf-8'),
            media_type=media_type,
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": f"{media_type}; charset=utf-8"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ±: {str(e)}"
        )


@router.post("/compare/visual-analysis/{session_id}")
async def perform_visual_comparison(session_id: str):
    """
    Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ØµØ±ÙŠØ© Ù…Ø­Ø³Ù†Ø© Ù„Ù„ØµÙˆØ±
    Perform enhanced visual comparison of images
    """
    try:
        logger.info(f"ðŸ–¼ï¸ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")
        
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        uploaded_files = session.get("uploaded_files", {})
        
        if "old" not in uploaded_files or "new" not in uploaded_files:
            raise HTTPException(
                status_code=400,
                detail="ÙŠØ¬Ø¨ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„ØµÙˆØ±ØªÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹"
            )
        
        old_file_path = uploaded_files["old"]["path"]
        new_file_path = uploaded_files["new"]["path"]
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª
        if not os.path.exists(old_file_path) or not os.path.exists(new_file_path):
            raise HTTPException(
                status_code=404,
                detail="Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©"
            )
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø®Ø¯Ù…Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        from app.services.visual_comparison_service import enhanced_visual_comparison_service
        
        logger.info(f"ðŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±: {uploaded_files['old']['filename']} vs {uploaded_files['new']['filename']}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        output_dir = os.path.join(settings.UPLOAD_DIR, session_id, "visual_analysis")
        os.makedirs(output_dir, exist_ok=True)
        
        # Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
        visual_result = await enhanced_visual_comparison_service.compare_images(
            old_image_path=old_file_path,
            new_image_path=new_file_path,
            output_dir=output_dir
        )
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ dict Ù„Ù„Ø¥Ø±Ø³Ø§Ù„
        visual_analysis = {
            "similarity_score": visual_result.similarity_score,
            "ssim_score": visual_result.ssim_score,
            "phash_score": visual_result.phash_score,
            "clip_score": visual_result.clip_score,
            "histogram_correlation": visual_result.histogram_correlation,
            "feature_matching_score": visual_result.feature_matching_score,
            "edge_similarity": visual_result.edge_similarity,
            "layout_similarity": visual_result.layout_similarity,
            "text_region_overlap": visual_result.text_region_overlap,
            "weights_used": visual_result.weights_used,
            "processing_time": visual_result.processing_time,
            "old_image_size": visual_result.old_image_size,
            "new_image_size": visual_result.new_image_size,
            "difference_detected": visual_result.difference_detected,
            "major_changes_detected": visual_result.major_changes_detected,
            "changed_regions": visual_result.changed_regions,
            "mean_squared_error": visual_result.mean_squared_error,
            "peak_signal_noise_ratio": visual_result.peak_signal_noise_ratio,
            "content_type_detected": visual_result.content_type_detected,
            "probable_content_match": visual_result.probable_content_match,
            "analysis_summary": visual_result.analysis_summary,
            "recommendations": visual_result.recommendations,
            "confidence_notes": visual_result.confidence_notes,
            "difference_map_path": visual_result.difference_map_path
        }
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        session["visual_analysis"] = visual_analysis
        
        logger.info(f"âœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {visual_result.similarity_score:.1f}% ØªØ·Ø§Ø¨Ù‚")
        logger.info(f"ðŸŽ¯ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {visual_result.analysis_summary}")
        
        return visual_analysis
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {str(e)}"
        )


@router.get("/compare/verify-landingai/{session_id}")
async def verify_landing_ai_usage(session_id: str):
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI ÙØ¹Ù„ÙŠØ§Ù‹ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
    Verify actual Landing AI usage in extraction process
    """
    try:
        logger.info(f"ðŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")
        
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        
        # ÙØ­Øµ Ø®Ø¯Ù…Ø© Landing AI
        from app.services.landing_ai_service import LandingAIService
        
        landing_service = LandingAIService()
        
        # ÙØ­Øµ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø­Ø§Ù„Ø©
        health_check = await landing_service.health_check()
        
        verification_result = {
            "landing_ai_enabled": landing_service.enabled,
            "api_key_configured": bool(landing_service.api_key),
            "agentic_doc_available": landing_service.enabled and hasattr(landing_service, 'enabled'),
            "health_status": health_check,
            "ocr_fallback_available": getattr(landing_service, 'ocr_available', False),
            "mock_mode": getattr(landing_service, 'mock_mode', True),
            "service_priority": "Landing AI" if landing_service.enabled else "Tesseract OCR",
            "configuration": {
                "batch_size": getattr(landing_service, 'batch_size', 0),
                "max_workers": getattr(landing_service, 'max_workers', 0),
                "max_retries": getattr(landing_service, 'max_retries', 0),
                "include_marginalia": getattr(landing_service, 'include_marginalia', False),
                "include_metadata": getattr(landing_service, 'include_metadata', False),
                "save_visual_groundings": getattr(landing_service, 'save_visual_groundings', False)
            }
        }
        
        # ÙØ­Øµ Ù†ØªØ§Ø¦Ø¬ OCR Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
        ocr_results = session.get("ocr_results", {})
        if ocr_results:
            verification_result["session_ocr_details"] = {
                "old_image_service": ocr_results.get("old", {}).get("service_used", "unknown"),
                "new_image_service": ocr_results.get("new", {}).get("service_used", "unknown"),
                "old_confidence": ocr_results.get("old", {}).get("confidence", 0),
                "new_confidence": ocr_results.get("new", {}).get("confidence", 0),
                "old_processing_time": ocr_results.get("old", {}).get("processing_time", 0),
                "new_processing_time": ocr_results.get("new", {}).get("processing_time", 0)
            }
        
        logger.info(f"ðŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚: Ø®Ø¯Ù…Ø© Landing AI {'Ù…ÙÙØ¹Ù„Ø©' if landing_service.enabled else 'ØºÙŠØ± Ù…ÙÙØ¹Ù„Ø©'}")
        
        return verification_result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Landing AI: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Landing AI: {str(e)}"
        )


@router.post("/compare/force-landing-ai/{session_id}")
async def force_landing_ai_extraction(session_id: str):
    """
    Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ (ØªØ¬Ø§Ù‡Ù„ Tesseract)
    Force Landing AI usage for text extraction (bypass Tesseract)
    """
    try:
        logger.info(f"ðŸš€ Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI Ù„Ù„Ø¬Ù„Ø³Ø© {session_id}")
        
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø§Ù„Ø¬Ù„Ø³Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        uploaded_files = session.get("uploaded_files", {})
        
        if "old" not in uploaded_files or "new" not in uploaded_files:
            raise HTTPException(
                status_code=400,
                detail="ÙŠØ¬Ø¨ Ø±ÙØ¹ ÙƒÙ„Ø§ Ø§Ù„ØµÙˆØ±ØªÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹"
            )
        
        from app.services.landing_ai_service import LandingAIService
        
        landing_service = LandingAIService()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Landing AI
        if not landing_service.enabled:
            raise HTTPException(
                status_code=503,
                detail="Ø®Ø¯Ù…Ø© Landing AI ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©. ØªØ­Ù‚Ù‚ Ù…Ù† API key ÙˆØªØ«Ø¨ÙŠØª agentic-doc"
            )
        
        # Ø¥Ø¬Ø¨Ø§Ø± ØªØ¹Ø·ÙŠÙ„ OCR Ø§Ù„Ù…Ø­Ù„ÙŠ Ù…Ø¤Ù‚ØªØ§Ù‹
        original_ocr_available = landing_service.ocr_available
        landing_service.ocr_available = False
        landing_service.mock_mode = False
        
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            logger.info("ðŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI ÙÙ‚Ø·...")
            old_result = await landing_service.extract_from_file(uploaded_files["old"]["path"])
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
            logger.info("ðŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI ÙÙ‚Ø·...")
            new_result = await landing_service.extract_from_file(uploaded_files["new"]["path"])
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            ocr_results = {
                "old": {
                    "success": old_result.success,
                    "text": old_result.markdown_content,
                    "confidence": old_result.confidence_score,
                    "character_count": len(old_result.markdown_content),
                    "word_count": len(old_result.markdown_content.split()),
                    "processing_time": old_result.processing_time,
                    "service_used": "LandingAI_Forced",
                    "extraction_details": {
                        "total_chunks": old_result.total_chunks,
                        "chunks_by_type": old_result.chunks_by_type,
                        "text_elements": old_result.text_elements,
                        "table_elements": old_result.table_elements,
                        "image_elements": old_result.image_elements
                    },
                    "error_message": old_result.error_message if not old_result.success else None
                },
                "new": {
                    "success": new_result.success,
                    "text": new_result.markdown_content,
                    "confidence": new_result.confidence_score,
                    "character_count": len(new_result.markdown_content),
                    "word_count": len(new_result.markdown_content.split()),
                    "processing_time": new_result.processing_time,
                    "service_used": "LandingAI_Forced",
                    "extraction_details": {
                        "total_chunks": new_result.total_chunks,
                        "chunks_by_type": new_result.chunks_by_type,
                        "text_elements": new_result.text_elements,
                        "table_elements": new_result.table_elements,
                        "image_elements": new_result.image_elements
                    },
                    "error_message": new_result.error_message if not new_result.success else None
                }
            }
            
            # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            session["ocr_results"] = ocr_results
            session["forced_landing_ai"] = True
            
            logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI ÙÙ‚Ø·")
            logger.info(f"ðŸ“Š Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {len(old_result.markdown_content)} Ø­Ø±ÙØŒ Ø«Ù‚Ø©: {old_result.confidence_score:.2f}")
            logger.info(f"ðŸ“Š Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {len(new_result.markdown_content)} Ø­Ø±ÙØŒ Ø«Ù‚Ø©: {new_result.confidence_score:.2f}")
            
            return {
                "message": "ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI ÙÙ‚Ø·",
                "old_image_result": ocr_results["old"],
                "new_image_result": ocr_results["new"],
                "service_verification": "LandingAI_Only",
                "success": old_result.success and new_result.success
            }
            
        finally:
            # Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©
            landing_service.ocr_available = original_ocr_available
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ø¬Ø¨Ø§Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Landing AI: {str(e)}"
        )


@router.get("/compare/session-status/{session_id}")
async def get_session_status(session_id: str):
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ÙˆØ¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… fallback
    Get session status and fallback availability
    """
    try:
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Tesseract
        from app.services.landing_ai_service import landing_ai_service
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
        extraction_failed = False
        if "ocr_results" in session:
            old_failed = not session["ocr_results"]["old"]["success"]
            new_failed = not session["ocr_results"]["new"]["success"]
            extraction_failed = old_failed or new_failed
        
        return {
            "session_id": session_id,
            "status": session.get("status", "unknown"),
            "extraction_failed": extraction_failed,
            "fallback_used": session.get("fallback_ocr_used", False),
            "fallback_available": landing_ai_service.ocr_available,
            "fallback_endpoint": f"/api/v1/compare/fallback-ocr/{session_id}" if extraction_failed else None,
            "message": "ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ OCR Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ" if extraction_failed and landing_ai_service.ocr_available else None,
            "warning": "âš ï¸ OCR Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ Ø£Ù‚Ù„ Ø¯Ù‚Ø© Ù…Ù† LandingAI" if extraction_failed else None
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©: {str(e)}"
        )

@router.post("/compare/fallback-ocr/{session_id}")
async def fallback_ocr_extraction(session_id: str):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR ÙƒØ¨Ø¯ÙŠÙ„ Ø¨Ø¹Ø¯ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    Extract text using Tesseract OCR as fallback after user approval
    """
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ù„Ø³Ø©
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        old_image_path = session["uploaded_files"]["old"]["path"]
        new_image_path = session["uploaded_files"]["new"]["path"]
        
        logger.info(f"ðŸ”„ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR Ù„Ù„Ø¬Ù„Ø³Ø©: {session_id}")
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø©
        from app.services.landing_ai_service import landing_ai_service
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Tesseract
        if not landing_ai_service.ocr_available:
            raise HTTPException(
                status_code=503, 
                detail="Tesseract OCR ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…"
            )
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±ØªÙŠÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract
        logger.info("ðŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract...")
        old_result = await landing_ai_service._fallback_ocr_extraction(
            old_image_path, 
            os.path.dirname(old_image_path), 
            os.path.basename(old_image_path)
        )
        
        logger.info("ðŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract...")
        new_result = await landing_ai_service._fallback_ocr_extraction(
            new_image_path, 
            os.path.dirname(new_image_path), 
            os.path.basename(new_image_path)
        )
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¬Ù„Ø³Ø©
        session["ocr_results"] = {
            "old": {
                "success": old_result.success,
                "text": old_result.markdown_content,
                "confidence": old_result.confidence_score,
                "character_count": len(old_result.markdown_content),
                "word_count": len(old_result.markdown_content.split()),
                "processing_time": old_result.processing_time,
                "service_used": "Tesseract_OCR",
                "extraction_method": "Tesseract_Fallback",
                "error_message": old_result.error_message if not old_result.success else None
            },
            "new": {
                "success": new_result.success,
                "text": new_result.markdown_content,
                "confidence": new_result.confidence_score,
                "character_count": len(new_result.markdown_content),
                "word_count": len(new_result.markdown_content.split()),
                "processing_time": new_result.processing_time,
                "service_used": "Tesseract_OCR",
                "extraction_method": "Tesseract_Fallback",
                "error_message": new_result.error_message if not new_result.success else None
            }
        }
        
        session["fallback_ocr_used"] = True
        session["status"] = "completed_with_fallback"
        
        logger.info(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR Ù„Ù„Ø¬Ù„Ø³Ø©: {session_id}")
        
        return {
            "message": "ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR ÙƒØ¨Ø¯ÙŠÙ„",
            "session_id": session_id,
            "old_image_result": session["ocr_results"]["old"],
            "new_image_result": session["ocr_results"]["new"],
            "warning": "âš ï¸ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ - Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø¯Ù‚Ø© Ø£Ù‚Ù„ Ù…Ù† LandingAI",
            "success": old_result.success and new_result.success,
            "extraction_method": "Tesseract_Fallback"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract: {str(e)}"
        )

@router.post("/compare/full-comparison/{session_id}")
async def full_comparison(session_id: str):
    """
    Ø¥Ø¬Ø±Ø§Ø¡ Ù…Ù‚Ø§Ø±Ù†Ø© ÙƒØ§Ù…Ù„Ø© Ù„Ù„ØµÙˆØ± ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©
    Perform full comparison of images in session
    """
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¬Ù„Ø³Ø©
        if session_id not in sessions_store:
            raise HTTPException(status_code=404, detail="Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
        session = sessions_store[session_id]
        old_image_path = session["uploaded_files"]["old"]["path"]
        new_image_path = session["uploaded_files"]["new"]["path"]
        
        logger.info(f"ðŸ”„ Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø¬Ù„Ø³Ø©: {session_id}")
        
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
        from app.services.landing_ai_service import landing_ai_service
        from app.services.gemini_service import gemini_service
        from app.services.visual_comparison_service import enhanced_visual_comparison_service
        
        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        old_result = None
        new_result = None
        
        try:
            logger.info("ðŸ“ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©...")
            old_result = await landing_ai_service.extract_from_file(old_image_path)
            if old_result.success:
                logger.info(f"âœ… Ù†Ø¬Ø­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {len(old_result.markdown_content)} Ø­Ø±Ù")
            else:
                logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {old_result.error_message}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {e}")
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© ÙØ§Ø´Ù„Ø©
            from app.services.landing_ai_service import LandingAIExtractionResult
            old_result = LandingAIExtractionResult(
                file_path=old_image_path,
                file_name=os.path.basename(old_image_path),
                processing_time=0,
                success=False,
                error_message=str(e)
            )
        
        try:
            logger.info("ðŸ“ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©...")
            new_result = await landing_ai_service.extract_from_file(new_image_path)
            if new_result.success:
                logger.info(f"âœ… Ù†Ø¬Ø­ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {len(new_result.markdown_content)} Ø­Ø±Ù")
            else:
                logger.warning(f"âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {new_result.error_message}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {e}")
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†ØªÙŠØ¬Ø© ÙØ§Ø´Ù„Ø©
            from app.services.landing_ai_service import LandingAIExtractionResult
            new_result = LandingAIExtractionResult(
                file_path=new_image_path,
                file_name=os.path.basename(new_image_path),
                processing_time=0,
                success=False,
                error_message=str(e)
            )
        
        # 2. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        comparison_result = None
        if old_result and new_result and old_result.success and new_result.success:
            try:
                logger.info("ðŸ¤– ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini...")
                comparison_result = await gemini_service.compare_texts(
                    old_result.markdown_content, 
                    new_result.markdown_content
                )
                logger.info("âœ… ØªÙ…Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¨Ù†Ø¬Ø§Ø­")
            except Exception as e:
                logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ©: {e}")
                comparison_result = None
        else:
            logger.warning("âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµØŒ ØªØ®Ø·ÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ©")
        
        # 3. Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£ÙØ¶Ù„ Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
        visual_result = None
        try:
            logger.info("ðŸ‘ï¸ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©...")
            visual_result = await enhanced_visual_comparison_service.compare_images(
                old_image_path, new_image_path
            )
            if visual_result:
                logger.info(f"âœ… ØªÙ…Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­: {visual_result.similarity_score:.1f}% ØªØ·Ø§Ø¨Ù‚")
            else:
                logger.warning("âš ï¸ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©: {e}")
            visual_result = None
        
        # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† LandingAI
        landing_ai_verification = {
            "landing_ai_enabled": not landing_ai_service.mock_mode,
            "api_key_configured": bool(landing_ai_service.api_key),
            "agentic_doc_available": landing_ai_service.agentic_doc_available,
            "health_status": {"status": "healthy"},
            "ocr_fallback_available": landing_ai_service.ocr_available,
            "mock_mode": landing_ai_service.mock_mode,
            "service_priority": "tesseract_ocr" if landing_ai_service.mock_mode else "landing_ai",
            "configuration": {
                "batch_size": 4,
                "max_workers": 5,
                "max_retries": 3,
                "include_marginalia": True,
                "include_metadata": True,
                "save_visual_groundings": False
            }
        }
        
        if old_result.success and new_result.success:
            landing_ai_verification["session_ocr_details"] = {
                "old_image_service": "tesseract" if landing_ai_service.mock_mode else "landing_ai",
                "new_image_service": "tesseract" if landing_ai_service.mock_mode else "landing_ai",
                "old_confidence": old_result.confidence_score,
                "new_confidence": new_result.confidence_score,
                "old_processing_time": old_result.processing_time,
                "new_processing_time": new_result.processing_time
            }
        
        # ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
        session["status"] = "completed"
        session["completed_at"] = datetime.now().isoformat()
        
        logger.info(f"âœ… ØªÙ…Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø¨Ù†Ø¬Ø§Ø­ Ù„Ù„Ø¬Ù„Ø³Ø©: {session_id}")
        
        # ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ø¬Ø§Ø­ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
        session_status = "completed"
        if not (old_result and new_result):
            session_status = "failed"
        elif not (old_result.success or new_result.success):
            session_status = "partial_failure"
        
        response_data = {
            "session_id": session_id,
            "status": session_status,
            "old_image_result": {
                "success": old_result.success if old_result else False,
                "text": old_result.markdown_content if old_result and old_result.success else "",
                "confidence": old_result.confidence_score if old_result and old_result.success else 0,
                "language": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if old_result and old_result.success else "unknown",
                "character_count": len(old_result.markdown_content) if old_result and old_result.success else 0,
                "word_count": len(old_result.markdown_content.split()) if old_result and old_result.success else 0,
                "processing_time": old_result.processing_time if old_result else 0,
                "error_message": old_result.error_message if old_result and not old_result.success else None,
                "extraction_method": "LandingAI" if old_result and old_result.success else "Failed",
                "image_info": {
                    "width": 0,
                    "height": 0,
                    "format": "JPEG",
                    "size_bytes": session["uploaded_files"]["old"]["size"]
                }
            },
            "new_image_result": {
                "success": new_result.success if new_result else False,
                "text": new_result.markdown_content if new_result and new_result.success else "",
                "confidence": new_result.confidence_score if new_result and new_result.success else 0,
                "language": "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" if new_result and new_result.success else "unknown",
                "character_count": len(new_result.markdown_content) if new_result and new_result.success else 0,
                "word_count": len(new_result.markdown_content.split()) if new_result and new_result.success else 0,
                "processing_time": new_result.processing_time if new_result else 0,
                "error_message": new_result.error_message if new_result and not new_result.success else None,
                "extraction_method": "LandingAI" if new_result and new_result.success else "Failed",
                "image_info": {
                    "width": 0,
                    "height": 0,
                    "format": "JPEG",
                    "size_bytes": session["uploaded_files"]["new"]["size"]
                }
            },
            "comparison_result": clean_json_values(comparison_result.__dict__) if comparison_result else None,
            "visual_comparison_result": clean_json_values(visual_result.__dict__) if visual_result else None,
            "landing_ai_verification": landing_ai_verification,
            "summary": {
                "text_extraction_success": bool(old_result and new_result and old_result.success and new_result.success),
                "text_comparison_success": bool(comparison_result),
                "visual_comparison_success": bool(visual_result),
                "overall_success": bool(old_result and new_result and (old_result.success or new_result.success) and visual_result),
                "errors": []
            }
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ø®Øµ
        fallback_available = False
        if old_result and not old_result.success:
            response_data["summary"]["errors"].append(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {old_result.error_message}")
            fallback_available = True
        if new_result and not new_result.success:
            response_data["summary"]["errors"].append(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©: {new_result.error_message}")
            fallback_available = True
        if not comparison_result and old_result and new_result and old_result.success and new_result.success:
            response_data["summary"]["errors"].append("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†ØµÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini")
        if not visual_result:
            response_data["summary"]["errors"].append("ÙØ´Ù„ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ©")
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª fallback
        if fallback_available:
            response_data["fallback_options"] = {
                "tesseract_available": landing_ai_service.ocr_available,
                "fallback_endpoint": f"/api/v1/compare/fallback-ocr/{session_id}",
                "message": "ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹ OCR Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ (Ø£Ù‚Ù„ Ø¯Ù‚Ø©) Ø¨Ø¹Ø¯ Ù…ÙˆØ§ÙÙ‚ØªÙƒ",
                "warning": "âš ï¸ OCR Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ Ø£Ù‚Ù„ Ø¯Ù‚Ø© Ù…Ù† LandingAI"
            }
        else:
            response_data["fallback_options"] = None
        
        return clean_json_values(response_data)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ÙØ´Ù„ ÙÙŠ Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©: {str(e)}"
        )


# ---------------------------------------------
# Endpoints Ù„Ø¥Ø¯Ø§Ø±Ø© ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
# ---------------------------------------------


@router.get("/compare/reports")
async def list_saved_reports(
    skip: int = 0,
    limit: int = 50,
    session_id: Optional[str] = None,
):
    """Ø¹Ø±Ø¶ Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØµÙÙŠØ© Ø­Ø³Ø¨ session_id"""
    try:
        db = SessionLocal()
        reports = crud.list_reports(db, skip=skip, limit=limit, session_id=session_id)
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø®ØªØµØ±Ø© Ø¨Ø¯ÙˆÙ† Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
        results: List[dict] = [
            {
                "id": r.id,
                "session_id": r.session_id,
                "report_format": r.report_format,
                "created_at": r.created_at,
            }
            for r in reports
        ]
        return {
            "total": len(results),
            "results": results,
        }
    finally:
        db.close()


@router.get("/compare/report/{report_id}")
async def get_saved_report(report_id: int):
    """ØªÙ†Ø²ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ù…Ø­ÙÙˆØ¸ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¹Ø±ÙÙ‡"""
    db = SessionLocal()
    try:
        report = crud.get_report(db, report_id)
        if not report:
            raise HTTPException(status_code=404, detail="Ø§Ù„ØªÙ‚Ø±ÙŠØ± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")

        media_type = (
            "text/markdown"
            if report.report_format in {"md", "markdown"}
            else "text/html" if report.report_format == "html" else "text/plain"
        )
        filename = f"comparison_report_{report.id}.{report.report_format}"

        return Response(
            content=report.content.encode("utf-8"),
            media_type=media_type,
            headers={
                "Content-Disposition": f"attachment; filename={filename}",
                "Content-Type": f"{media_type}; charset=utf-8",
            },
        )
    finally:
        db.close()