#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¨Ø§Ù„ØªÙØµÙŠÙ„
Test script for detailed visual comparison between two images
"""

import cv2
import numpy as np
import imagehash
from PIL import Image
from skimage.metrics import structural_similarity as ssim
from skimage.feature import match_descriptors, ORB
import json
import time
from pathlib import Path

class VisualComparisonTester:
    """ÙØ¦Ø© Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ù…Ø¹ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
    
    def __init__(self):
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© (Ù†ÙØ³ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„Ø¨Ø§Ùƒ Ø¥Ù†Ø¯)
        self.weights = {
            'ssim': 0.33,
            'phash': 0.20,
            'clip': 0.00,  # ØºÙŠØ± Ù…ØªØ§Ø­ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            'histogram': 0.13,
            'features': 0.20,
            'edges': 0.13
        }
        
    def load_and_prepare_image(self, image_path):
        """ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"""
        try:
            # ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ OpenCV
            img_cv = cv2.imread(str(image_path))
            if img_cv is None:
                raise ValueError(f"Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©: {image_path}")
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB
            img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
            
            # ØªØ­Ù…ÙŠÙ„ Ù…Ø¹ PIL Ù„Ù„Ù€ hashing
            img_pil = Image.open(image_path)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø±Ù…Ø§Ø¯ÙŠØ©
            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            
            return {
                'cv': img_cv,
                'rgb': img_rgb,
                'pil': img_pil,
                'gray': img_gray,
                'shape': img_cv.shape,
                'size': img_pil.size
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ {image_path}: {e}")
            return None
    
    def resize_images_to_match(self, img1, img2):
        """ØªØºÙŠÙŠØ± Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ± Ù„ØªØªØ·Ø§Ø¨Ù‚"""
        h1, w1 = img1['gray'].shape
        h2, w2 = img2['gray'].shape
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ØµØºØ± Ø­Ø¬Ù… Ù…Ø´ØªØ±Ùƒ
        target_h = min(h1, h2)
        target_w = min(w1, w2)
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø³Ø¨Ø©
        def resize_image_dict(img_dict, target_size):
            result = {}
            for key, img in img_dict.items():
                if key in ['shape', 'size']:
                    continue
                elif key == 'pil':
                    result[key] = img.resize((target_w, target_h), Image.Resampling.LANCZOS)
                elif len(img.shape) == 2:  # grayscale
                    result[key] = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LANCZOS4)
                else:  # color
                    result[key] = cv2.resize(img, (target_w, target_h), interpolation=cv2.INTER_LANCZOS4)
            
            result['shape'] = (target_h, target_w, 3)
            result['size'] = (target_w, target_h)
            return result
        
        img1_resized = resize_image_dict(img1, (target_w, target_h))
        img2_resized = resize_image_dict(img2, (target_w, target_h))
        
        return img1_resized, img2_resized
    
    def calculate_ssim(self, img1_gray, img2_gray):
        """Ø­Ø³Ø§Ø¨ SSIM (Structural Similarity Index)"""
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ float32 Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
            img1_float = img1_gray.astype(np.float32) / 255.0
            img2_float = img2_gray.astype(np.float32) / 255.0
            
            # Ø­Ø³Ø§Ø¨ SSIM
            ssim_score, ssim_map = ssim(img1_float, img2_float, full=True, data_range=1.0)
            
            return {
                'score': float(ssim_score),
                'map_available': True,
                'mean_map': float(np.mean(ssim_map)),
                'std_map': float(np.std(ssim_map))
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ SSIM: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_phash(self, img1_pil, img2_pil):
        """Ø­Ø³Ø§Ø¨ Perceptual Hash"""
        try:
            hash1 = imagehash.phash(img1_pil, hash_size=16)
            hash2 = imagehash.phash(img2_pil, hash_size=16)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© (Ø£Ù‚Ù„ = Ø£ÙƒØ«Ø± ØªØ´Ø§Ø¨Ù‡Ø§Ù‹)
            distance = hash1 - hash2
            max_distance = 16 * 16  # Ø£Ù‚ØµÙ‰ Ù…Ø³Ø§ÙØ© Ù…Ù…ÙƒÙ†Ø©
            similarity = 1.0 - (distance / max_distance)
            
            return {
                'score': float(similarity),
                'hash1': str(hash1),
                'hash2': str(hash2),
                'distance': int(distance),
                'max_distance': max_distance
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ pHash: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_histogram_correlation(self, img1_rgb, img2_rgb):
        """Ø­Ø³Ø§Ø¨ Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ù‡Ø³ØªÙˆØ¬Ø±Ø§Ù…"""
        try:
            # Ø­Ø³Ø§Ø¨ Ù‡Ø³ØªÙˆØ¬Ø±Ø§Ù… Ù„ÙƒÙ„ Ù‚Ù†Ø§Ø© Ù„ÙˆÙ†
            hist1_r = cv2.calcHist([img1_rgb], [0], None, [256], [0, 256])
            hist1_g = cv2.calcHist([img1_rgb], [1], None, [256], [0, 256])
            hist1_b = cv2.calcHist([img1_rgb], [2], None, [256], [0, 256])
            
            hist2_r = cv2.calcHist([img2_rgb], [0], None, [256], [0, 256])
            hist2_g = cv2.calcHist([img2_rgb], [1], None, [256], [0, 256])
            hist2_b = cv2.calcHist([img2_rgb], [2], None, [256], [0, 256])
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ù„ÙƒÙ„ Ù‚Ù†Ø§Ø©
            corr_r = cv2.compareHist(hist1_r, hist2_r, cv2.HISTCMP_CORREL)
            corr_g = cv2.compareHist(hist1_g, hist2_g, cv2.HISTCMP_CORREL)
            corr_b = cv2.compareHist(hist1_b, hist2_b, cv2.HISTCMP_CORREL)
            
            # Ø§Ù„Ù…ØªÙˆØ³Ø·
            avg_correlation = (corr_r + corr_g + corr_b) / 3.0
            
            return {
                'score': float(avg_correlation),
                'r_channel': float(corr_r),
                'g_channel': float(corr_g),
                'b_channel': float(corr_b),
                'method': 'HISTCMP_CORREL'
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ø³ØªÙˆØ¬Ø±Ø§Ù…: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_feature_matching(self, img1_gray, img2_gray):
        """Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ORB"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ detector ORB
            orb = cv2.ORB_create(nfeatures=1000)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© ÙˆØ§Ù„ÙˆØ§ØµÙØ§Øª
            kp1, des1 = orb.detectAndCompute(img1_gray, None)
            kp2, des2 = orb.detectAndCompute(img2_gray, None)
            
            if des1 is None or des2 is None:
                return {
                    'score': 0.0,
                    'matches': 0,
                    'keypoints1': len(kp1) if kp1 else 0,
                    'keypoints2': len(kp2) if kp2 else 0,
                    'error': 'No descriptors found'
                }
            
            # Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª
            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
            matches = bf.match(des1, des2)
            
            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ©
            matches = sorted(matches, key=lambda x: x.distance)
            
            # Ø­Ø³Ø§Ø¨ Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©
            good_matches = [m for m in matches if m.distance < 50]  # threshold Ù„Ù„Ù…Ø·Ø§Ø¨Ù‚Ø§Øª Ø§Ù„Ø¬ÙŠØ¯Ø©
            max_possible_matches = min(len(kp1), len(kp2))
            
            if max_possible_matches > 0:
                similarity = len(good_matches) / max_possible_matches
            else:
                similarity = 0.0
            
            return {
                'score': float(min(similarity, 1.0)),  # ØªØ­Ø¯ÙŠØ¯ Ø£Ù‚ØµÙ‰ 1.0
                'total_matches': len(matches),
                'good_matches': len(good_matches),
                'keypoints1': len(kp1),
                'keypoints2': len(kp2),
                'avg_distance': float(np.mean([m.distance for m in matches]) if matches else 0),
                'threshold': 50
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_edge_similarity(self, img1_gray, img2_gray):
        """Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø­ÙˆØ§Ù"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Canny
            edges1 = cv2.Canny(img1_gray, 50, 150)
            edges2 = cv2.Canny(img2_gray, 50, 150)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ·Ø§Ø¨Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ø­ÙˆØ§Ù
            # Ø·Ø±ÙŠÙ‚Ø© 1: XOR Ù„Ù„Ø­ÙˆØ§Ù
            xor_edges = cv2.bitwise_xor(edges1, edges2)
            total_edge_pixels = np.sum(edges1 > 0) + np.sum(edges2 > 0)
            different_pixels = np.sum(xor_edges > 0)
            
            if total_edge_pixels > 0:
                similarity_xor = 1.0 - (different_pixels / total_edge_pixels)
            else:
                similarity_xor = 1.0
            
            # Ø·Ø±ÙŠÙ‚Ø© 2: Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ø­ÙˆØ§Ù
            if np.std(edges1) > 0 and np.std(edges2) > 0:
                correlation = np.corrcoef(edges1.flatten(), edges2.flatten())[0, 1]
                if np.isnan(correlation):
                    correlation = 0.0
            else:
                correlation = 1.0 if np.array_equal(edges1, edges2) else 0.0
            
            # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø·Ø±ÙŠÙ‚ØªÙŠÙ†
            final_score = (similarity_xor + abs(correlation)) / 2.0
            
            return {
                'score': float(final_score),
                'xor_similarity': float(similarity_xor),
                'correlation': float(correlation),
                'edges1_pixels': int(np.sum(edges1 > 0)),
                'edges2_pixels': int(np.sum(edges2 > 0)),
                'different_pixels': int(different_pixels)
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø­ÙˆØ§Ù: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_mse_psnr(self, img1_gray, img2_gray):
        """Ø­Ø³Ø§Ø¨ MSE Ùˆ PSNR"""
        try:
            # Ø­Ø³Ø§Ø¨ MSE
            mse = np.mean((img1_gray.astype(np.float32) - img2_gray.astype(np.float32)) ** 2)
            
            # Ø­Ø³Ø§Ø¨ PSNR
            if mse == 0:
                psnr = float('inf')
            else:
                max_pixel = 255.0
                psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
            
            return {
                'mse': float(mse),
                'psnr': float(psnr),
                'max_pixel': 255.0
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ MSE/PSNR: {e}")
            return {'mse': 0.0, 'psnr': 0.0, 'error': str(e)}
    
    def detect_changed_regions(self, img1_gray, img2_gray, threshold=30):
        """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØºÙŠØ±Ø©"""
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ±Ù‚ Ø§Ù„Ù…Ø·Ù„Ù‚
            diff = cv2.absdiff(img1_gray, img2_gray)
            
            # ØªØ·Ø¨ÙŠÙ‚ threshold
            _, thresh = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)
            
            # Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ†ØªÙˆØ±Ø§Øª (Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØºÙŠØ±Ø©)
            contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # ØªØµÙÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØµØºÙŠØ±Ø©
            min_area = 100  # Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¯Ù†ÙŠØ§ Ù„Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø©
            significant_contours = [c for c in contours if cv2.contourArea(c) > min_area]
            
            changed_regions = []
            for i, contour in enumerate(significant_contours):
                x, y, w, h = cv2.boundingRect(contour)
                area = cv2.contourArea(contour)
                
                changed_regions.append({
                    'id': f'region_{i+1}',
                    'x': int(x),
                    'y': int(y),
                    'width': int(w),
                    'height': int(h),
                    'area': float(area),
                    'center': {
                        'x': int(x + w/2),
                        'y': int(y + h/2)
                    }
                })
            
            # Ø­Ø³Ø§Ø¨ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ØªØºÙŠØ±Ø©
            total_changed_area = sum(region['area'] for region in changed_regions)
            total_image_area = img1_gray.shape[0] * img1_gray.shape[1]
            change_percentage = (total_changed_area / total_image_area) * 100
            
            return {
                'regions': changed_regions,
                'total_regions': len(changed_regions),
                'total_changed_area': float(total_changed_area),
                'total_image_area': float(total_image_area),
                'change_percentage': float(change_percentage),
                'threshold_used': threshold
            }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØºÙŠØ±Ø©: {e}")
            return {'regions': [], 'error': str(e)}
    
    def run_comprehensive_comparison(self, image1_path, image2_path):
        """ØªØ´ØºÙŠÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ø´Ø§Ù…Ù„Ø© Ø¨ÙŠÙ† ØµÙˆØ±ØªÙŠÙ†"""
        start_time = time.time()
        
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©...")
        print(f"ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {image1_path}")
        print(f"ğŸ“· Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: {image2_path}")
        print("-" * 60)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±
        img1 = self.load_and_prepare_image(image1_path)
        img2 = self.load_and_prepare_image(image2_path)
        
        if not img1 or not img2:
            return None
        
        print(f"ğŸ“ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰: {img1['shape']}")
        print(f"ğŸ“ Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: {img2['shape']}")
        
        # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù… Ù„Ù„ØªØ·Ø§Ø¨Ù‚
        img1_resized, img2_resized = self.resize_images_to_match(img1, img2)
        print(f"ğŸ“ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø©: {img1_resized['shape']}")
        print("-" * 60)
        
        # Ø¥Ø¬Ø±Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª
        results = {}
        
        print("ğŸ”¬ Ø­Ø³Ø§Ø¨ SSIM...")
        results['ssim'] = self.calculate_ssim(img1_resized['gray'], img2_resized['gray'])
        print(f"   âœ… SSIM Score: {results['ssim']['score']:.4f}")
        
        print("ğŸ”¬ Ø­Ø³Ø§Ø¨ Perceptual Hash...")
        results['phash'] = self.calculate_phash(img1_resized['pil'], img2_resized['pil'])
        print(f"   âœ… pHash Score: {results['phash']['score']:.4f}")
        
        print("ğŸ”¬ Ø­Ø³Ø§Ø¨ Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„Ù‡Ø³ØªÙˆØ¬Ø±Ø§Ù…...")
        results['histogram'] = self.calculate_histogram_correlation(img1_resized['rgb'], img2_resized['rgb'])
        print(f"   âœ… Histogram Correlation: {results['histogram']['score']:.4f}")
        
        print("ğŸ”¬ Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª...")
        results['features'] = self.calculate_feature_matching(img1_resized['gray'], img2_resized['gray'])
        print(f"   âœ… Feature Matching Score: {results['features']['score']:.4f}")
        
        print("ğŸ”¬ Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø§Ù„Ø­ÙˆØ§Ù...")
        results['edges'] = self.calculate_edge_similarity(img1_resized['gray'], img2_resized['gray'])
        print(f"   âœ… Edge Similarity Score: {results['edges']['score']:.4f}")
        
        print("ğŸ”¬ Ø­Ø³Ø§Ø¨ MSE Ùˆ PSNR...")
        results['mse_psnr'] = self.calculate_mse_psnr(img1_resized['gray'], img2_resized['gray'])
        print(f"   âœ… MSE: {results['mse_psnr']['mse']:.2f}, PSNR: {results['mse_psnr']['psnr']:.2f} dB")
        
        print("ğŸ”¬ Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù…ØªØºÙŠØ±Ø©...")
        results['changed_regions'] = self.detect_changed_regions(img1_resized['gray'], img2_resized['gray'])
        print(f"   âœ… Found {results['changed_regions']['total_regions']} changed regions")
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        overall_score = (
            results['ssim']['score'] * self.weights['ssim'] +
            results['phash']['score'] * self.weights['phash'] +
            results['histogram']['score'] * self.weights['histogram'] +
            results['features']['score'] * self.weights['features'] +
            results['edges']['score'] * self.weights['edges']
        ) * 100
        
        processing_time = time.time() - start_time
        
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_results = {
            'overall_score': overall_score,
            'processing_time': processing_time,
            'image_info': {
                'image1_original_size': img1['shape'],
                'image2_original_size': img2['shape'],
                'comparison_size': img1_resized['shape']
            },
            'detailed_scores': results,
            'weights_used': self.weights,
            'analysis': self.generate_analysis(results, overall_score),
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return final_results
    
    def generate_analysis(self, results, overall_score):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª"""
        analysis = {
            'similarity_level': '',
            'major_differences': False,
            'content_type_detected': 'educational_document',
            'recommendations': [],
            'confidence_notes': [],
            'summary': ''
        }
        
        # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
        if overall_score >= 95:
            analysis['similarity_level'] = 'Ù…ØªØ·Ø§Ø¨Ù‚ ØªÙ‚Ø±ÙŠØ¨Ø§Ù‹'
        elif overall_score >= 85:
            analysis['similarity_level'] = 'Ù…ØªØ´Ø§Ø¨Ù‡ Ø¬Ø¯Ø§Ù‹'
        elif overall_score >= 70:
            analysis['similarity_level'] = 'Ù…ØªØ´Ø§Ø¨Ù‡'
        elif overall_score >= 50:
            analysis['similarity_level'] = 'Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ù…ØªÙˆØ³Ø·Ø©'
        else:
            analysis['similarity_level'] = 'Ù…Ø®ØªÙ„Ù Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ±'
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø©
        changed_percentage = results['changed_regions'].get('change_percentage', 0)
        if changed_percentage > 10:
            analysis['major_differences'] = True
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙˆØµÙŠØ§Øª
        if results['ssim']['score'] < 0.8:
            analysis['recommendations'].append('Ù‡Ù†Ø§Ùƒ Ø§Ø®ØªÙ„Ø§ÙØ§Øª Ù‡ÙŠÙƒÙ„ÙŠØ© Ù…Ù„Ø­ÙˆØ¸Ø© Ø¨ÙŠÙ† Ø§Ù„ØµÙˆØ±')
        
        if results['phash']['score'] < 0.9:
            analysis['recommendations'].append('Ø§Ù„ØµÙˆØ± ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ø®ØªÙ„Ø§ÙØ§Øª ÙÙŠ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø¨ØµØ±ÙŠ')
        
        if results['features']['good_matches'] < 50:
            analysis['recommendations'].append('Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…ØªØ·Ø§Ø¨Ù‚Ø© Ù‚Ù„ÙŠÙ„ - Ù‚Ø¯ ØªÙƒÙˆÙ† ØµÙˆØ± Ù…Ø®ØªÙ„ÙØ©')
        
        if changed_percentage > 5:
            analysis['recommendations'].append(f'ØªÙ… Ø§ÙƒØªØ´Ø§Ù {changed_percentage:.1f}% Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ù…ØªØºÙŠØ±Ø©')
        
        # Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø«Ù‚Ø©
        if results['features']['keypoints1'] < 100 or results['features']['keypoints2'] < 100:
            analysis['confidence_notes'].append('Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ù…Ù…ÙŠØ²Ø© Ù‚Ù„ÙŠÙ„ - Ù‚Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø¯Ù‚Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©')
        
        if results['mse_psnr']['mse'] > 1000:
            analysis['confidence_notes'].append('MSE Ù…Ø±ØªÙØ¹ - ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ø®ØªÙ„Ø§ÙØ§Øª ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ø¨ÙƒØ³Ù„')
        
        # Ø§Ù„Ù…Ù„Ø®Øµ
        analysis['summary'] = f"Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ© {overall_score:.1f}% ØªØ´ÙŠØ± Ø¥Ù„Ù‰ {analysis['similarity_level']}. ØªÙ… Ø§ÙƒØªØ´Ø§Ù {results['changed_regions']['total_regions']} Ù…Ù†Ø·Ù‚Ø© Ù…ØªØºÙŠØ±Ø©."
        
        return analysis

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    # Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„ØµÙˆØ±
    image1_path = Path("D:/ezz/compair/edu-compare-wizard/104.jpg")
    image2_path = Path("D:/ezz/compair/edu-compare-wizard/101.jpg")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„ØµÙˆØ±
    if not image1_path.exists():
        print(f"âŒ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image1_path}")
        return
    
    if not image2_path.exists():
        print(f"âŒ Ø§Ù„ØµÙˆØ±Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: {image2_path}")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØ®ØªØ¨Ø± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    tester = VisualComparisonTester()
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
    results = tester.run_comprehensive_comparison(image1_path, image2_path)
    
    if results:
        print("\n" + "=" * 60)
        print("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
        print("=" * 60)
        print(f"ğŸ¯ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {results['overall_score']:.2f}%")
        print(f"â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {results['processing_time']:.2f} Ø«Ø§Ù†ÙŠØ©")
        print(f"ğŸ“ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {results['analysis']['similarity_level']}")
        print(f"ğŸ“„ Ø§Ù„Ù…Ù„Ø®Øµ: {results['analysis']['summary']}")
        
        if results['analysis']['recommendations']:
            print("\nğŸ’¡ Ø§Ù„ØªÙˆØµÙŠØ§Øª:")
            for rec in results['analysis']['recommendations']:
                print(f"   â€¢ {rec}")
        
        if results['analysis']['confidence_notes']:
            print("\nâš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø«Ù‚Ø©:")
            for note in results['analysis']['confidence_notes']:
                print(f"   â€¢ {note}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ©
        output_file = "detailed_comparison_results.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙØµÙŠÙ„ÙŠØ© ÙÙŠ: {output_file}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©
        print("\nğŸ” ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
        print("-" * 40)
        details = results['detailed_scores']
        print(f"SSIM: {details['ssim']['score']:.4f}")
        print(f"pHash: {details['phash']['score']:.4f} (distance: {details['phash']['distance']})")
        print(f"Histogram: {details['histogram']['score']:.4f}")
        print(f"Features: {details['features']['score']:.4f} ({details['features']['good_matches']} good matches)")
        print(f"Edges: {details['edges']['score']:.4f}")
        print(f"MSE: {details['mse_psnr']['mse']:.2f}")
        print(f"PSNR: {details['mse_psnr']['psnr']:.2f} dB")
        print(f"Changed Regions: {details['changed_regions']['total_regions']} ({details['changed_regions']['change_percentage']:.1f}% area)")

if __name__ == "__main__":
    main()
