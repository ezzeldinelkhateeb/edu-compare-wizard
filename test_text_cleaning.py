#!/usr/bin/env python3
"""
Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ù† Landing AI
Enhanced Text Cleaning System Test for Landing AI

ÙŠØ´Ù…Ù„:
1. ØªÙ†Ø¸ÙŠÙ Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ
2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„ÙØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
3. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø©
4. Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
"""

import asyncio
import json
from pathlib import Path
from typing import Dict, Any, List
import time
import re

def clean_landing_ai_text(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† ØªÙØ§ØµÙŠÙ„ Landing AI Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©"""
    import re
    
    # Ø¥Ø²Ø§Ù„Ø© Ø£ÙˆØµØ§Ù Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
    text = re.sub(r'Summary\s*:\s*This[\s\S]*?<!-- figure[\s\S]*?-->', '', text)
    text = re.sub(r'photo:\s*[\s\S]*?Analysis\s*:[\s\S]*?<!-- figure[\s\S]*?-->', '', text)
    text = re.sub(r'illustration:\s*[\s\S]*?Analysis\s*:[\s\S]*?<!-- figure[\s\S]*?-->', '', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù…Ù† Landing AI
    text = re.sub(r'<!-- text,[\s\S]*?-->', '', text)
    text = re.sub(r'<!-- figure,[\s\S]*?-->', '', text)
    text = re.sub(r'<!-- marginalia,[\s\S]*?-->', '', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø§Ù„Ø¹Ø§Ù…
    text = re.sub(r'Scene Overview\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ])', '', text)
    text = re.sub(r'Technical Details\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ])', '', text)
    text = re.sub(r'Spatial Relationships\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ])', '', text)
    text = re.sub(r'Analysis\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ])', '', text)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
    text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
    
    return text.strip()

def clean_landing_ai_text_enhanced(text):
    """ØªÙ†Ø¸ÙŠÙ Ù…Ø­Ø³Ù† Ù„Ù„Ù†ØµÙˆØµ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    if not text:
        return ""
    
    original_length = len(text)
    
    # 1. Ø¥Ø²Ø§Ù„Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª HTML ÙˆØªÙØ§ØµÙŠÙ„ Landing AI
    patterns_to_remove = [
        r'<!--[\s\S]*?-->',
        r'<!-- text,[\s\S]*?-->',
        r'<!-- figure,[\s\S]*?-->',
        r'<!-- marginalia,[\s\S]*?-->',
        r'<!-- illustration,[\s\S]*?-->',
        r'<!-- table,[\s\S]*?-->',
        
        # Ø¥Ø²Ø§Ù„Ø© Ø£Ù‚Ø³Ø§Ù… ÙˆØµÙ Ø§Ù„ØµÙˆØ± Ø§Ù„ÙƒØ§Ù…Ù„Ø©
        r'Summary\s*:\s*This[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'photo\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'illustration\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'Scene Overview\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'Technical Details\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'Spatial Relationships\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'Analysis\s*:[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª ÙˆØ§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ©
        r'from page \d+ \(l=[\d.]+,t=[\d.]+,r=[\d.]+,b=[\d.]+\)',
        r'with ID [a-f0-9\-]+',
        r'\(l=[\d.]+,t=[\d.]+,r=[\d.]+,b=[\d.]+\)',
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø©
        r'The image[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'This figure[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'The figure[\s\S]*?(?=\n\n|\n[Ø£-ÙŠ]|\Z)',
        r'^\s*â€¢\s+The[\s\S]*?(?=\n)',
        r'^\s*â€¢\s+Each[\s\S]*?(?=\n)',
        r'^\s*â€¢\s+No scale[\s\S]*?(?=\n)',
        r'^\s*â€¢\s+Arabic text[\s\S]*?(?=\n)',
    ]
    
    for pattern in patterns_to_remove:
        text = re.sub(pattern, '', text, flags=re.MULTILINE | re.DOTALL)
    
    # 2. ØªÙ†Ø¸ÙŠÙ Ø®Ø§Øµ Ø¨Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„ØºØ±ÙŠØ¨Ø© ÙˆØ§Ù„Ø±Ù…ÙˆØ² ØºÙŠØ± Ø§Ù„Ù…Ø±ØºÙˆØ¨Ø©
    text = re.sub(r'[^\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF\w\s\.\,\!\?\:\;\(\)\[\]\{\}\-\+\=\$\%\@\#\*\/\\\|]', '', text)
    
    # ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø­ÙˆÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    text = re.sub(r'\s*([ØŒØ›ØŸ!])\s*', r'\1 ', text)
    text = re.sub(r'\s*([:])\s*', r'\1 ', text)
    
    # 3. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø³Ø·ÙˆØ± Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø·
    lines = text.split('\n')
    cleaned_lines = []
    
    keywords_to_skip = [
        'summary :', 'photo:', 'illustration:', 'scene overview:', 
        'technical details:', 'spatial relationships:', 'analysis :',
        '---', 'figure', 'image'
    ]
    
    for line in lines:
        line_lower = line.strip().lower()
        
        # ØªØ®Ø·ÙŠ Ø§Ù„Ø³Ø·ÙˆØ± Ø§Ù„ÙØ§Ø±ØºØ© Ø£Ùˆ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© ÙÙ‚Ø·
        if not line_lower or line_lower in keywords_to_skip:
            continue
        
        # ØªØ®Ø·ÙŠ Ø§Ù„Ø³Ø·ÙˆØ± Ø§Ù„ØªÙŠ ØªØ¨Ø¯Ø£ Ø¨Ù€ bullet points ÙˆØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØµÙ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
        if re.match(r'^\s*â€¢\s', line) and any(word in line_lower for word in ['figure', 'image', 'scene', 'shown', 'depicts']):
            continue
        
        cleaned_lines.append(line)
    
    text = '\n'.join(cleaned_lines)
    
    # 4. ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ø£Ø³Ø·Ø± Ø§Ù„ÙØ§Ø±ØºØ©
    text = re.sub(r'\n\s*\n\s*\n+', '\n\n', text)
    text = re.sub(r'^\s+', '', text, flags=re.MULTILINE)
    text = re.sub(r'\s+$', '', text, flags=re.MULTILINE)
    text = text.strip()
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ­Ø³Ù†
    cleaned_length = len(text)
    improvement = ((original_length - cleaned_length) / original_length * 100) if original_length > 0 else 0
    
    return text, improvement

async def test_enhanced_processing():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†"""
    print("\n" + "=" * 60)
    print("ğŸš€ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ")
    print("=" * 60)
    
    try:
        # Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
        from enhanced_text_processing_system import AdvancedTextProcessor, process_single_file, process_directory
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙˆØ§Ø­Ø¯
        test_file = "d:/ezz/compair/edu-compare-wizard/backend/uploads/landingai_results/extraction_20250705_172654/extracted_content.md"
        if Path(test_file).exists():
            print("ğŸ“„ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ÙˆØ§Ø­Ø¯ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†...")
            start_time = time.time()
            
            result = await process_single_file(test_file)
            
            processing_time = time.time() - start_time
            
            print(f"âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†:")
            print(f"   ğŸ“ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£ØµÙ„ÙŠ: {result.metadata['original_length']:,} Ø­Ø±Ù")
            print(f"   ğŸ“ Ø§Ù„Ø·ÙˆÙ„ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {result.metadata['cleaned_length']:,} Ø­Ø±Ù")
            print(f"   ğŸ“Š ØªØ­Ø³Ù†: {result.metadata['reduction_percentage']:.1f}%")
            print(f"   â±ï¸ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {processing_time:.3f}s")
            print(f"   ğŸ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰: {result.content_type.value}")
            print(f"   ğŸ”§ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø­Ø°ÙˆÙØ©: {len(result.chunks_removed)}")
            print(f"   âœ… Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø­ÙÙˆØ¸Ø©: {len(result.chunks_kept)}")
            
            # Ø·Ø¨Ø§Ø¹Ø© Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø¸Ù
            if result.cleaned_text:
                print(f"\nğŸ“ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø¸Ù:")
                print("-" * 30)
                sample = result.cleaned_text[:300] + "..." if len(result.cleaned_text) > 300 else result.cleaned_text
                print(sample)
        
        # Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù„Ø¯
        test_dir = "d:/ezz/compair/edu-compare-wizard/backend/uploads/landingai_results"
        if Path(test_dir).exists():
            print(f"\nğŸ“ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù„Ø¯ Ø¨Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†...")
            start_time = time.time()
            
            batch_result = await process_directory(test_dir, ['.md'])
            
            processing_time = time.time() - start_time
            
            print(f"âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù† - Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…Ø¹Ø©:")
            print(f"   ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {batch_result.total_files}")
            print(f"   âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {batch_result.processed_files}")
            print(f"   âŒ ÙØ´Ù„: {batch_result.failed_files}")
            print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {processing_time:.2f}s")
            print(f"   ğŸš€ Ø§Ù„Ø³Ø±Ø¹Ø©: {batch_result.summary_stats.get('files_per_second', 0):.2f} Ù…Ù„Ù/Ø«Ø§Ù†ÙŠØ©")
            print(f"   ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ø³Ù†: {batch_result.summary_stats.get('average_reduction_percentage', 0):.1f}%")
            
            if 'content_type_distribution' in batch_result.summary_stats:
                print(f"   ğŸ¯ ØªÙˆØ²ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø­ØªÙˆÙ‰:")
                for content_type, count in batch_result.summary_stats['content_type_distribution'].items():
                    print(f"      - {content_type}: {count} Ù…Ù„Ù")
        
    except ImportError as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†: {e}")
        print("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù enhanced_text_processing_system.py")

async def test_fast_folder_processing():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹Ø©"""
    print("\n" + "=" * 60)
    print("âš¡ Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø³Ø±ÙŠØ¹")
    print("=" * 60)
    
    try:
        from fast_folder_processor import FastFolderProcessor, quick_process_folder
        
        test_dir = "d:/ezz/compair/edu-compare-wizard/backend/uploads/landingai_results"
        if Path(test_dir).exists():
            print(f"ğŸ“ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø³Ø±ÙŠØ¹Ø© Ù„Ù„Ù…Ø¬Ù„Ø¯: {test_dir}")
            
            start_time = time.time()
            result = await quick_process_folder(test_dir, max_workers=8)
            processing_time = time.time() - start_time
            
            print(f"âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹:")
            print(f"   ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {result['processing_summary']['total_files']}")
            print(f"   âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø©: {result['processing_summary']['completed_files']}")
            print(f"   âŒ ÙØ´Ù„: {result['processing_summary']['failed_files']}")
            print(f"   ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {result['processing_summary']['success_rate']:.1f}%")
            print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {processing_time:.2f}s")
            print(f"   ğŸš€ Ø§Ù„Ø³Ø±Ø¹Ø©: {result['processing_summary']['files_per_second']:.2f} Ù…Ù„Ù/Ø«Ø§Ù†ÙŠØ©")
            
            if 'optimization_summary' in result and result['optimization_summary']:
                opt = result['optimization_summary']
                print(f"   ğŸ“Š Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ­Ø³Ù†: {opt.get('average_reduction_percentage', 0):.1f}%")
                print(f"   ğŸ’¾ ØªÙˆÙÙŠØ± Ù…Ø³Ø§Ø­Ø©: {opt.get('total_size_saved', 0):,} Ø­Ø±Ù")
            
            if 'performance_metrics' in result:
                perf = result['performance_metrics']
                print(f"   ğŸ§  Ø°Ø±ÙˆØ© Ø§Ù„Ø°Ø§ÙƒØ±Ø©: {perf.get('peak_memory_mb', 0):.1f}MB")
                print(f"   âš™ï¸ Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬: {perf.get('average_cpu_usage', 0):.1f}%")
        
    except ImportError as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹: {e}")
        print("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„Ù fast_folder_processor.py")

def test_cleaning():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©"""
    
    # Ù†Øµ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù…Ø§ ÙŠØ£ØªÙŠ Ù…Ù† Landing AI
    test_text = """
3
Ø§Ù„ÙØµÙ„ <!-- text, from page 0 (l=0.851,t=0.033,r=0.924,b=0.075), with ID 321af0af-bb97-4061-b683-7f701f6c448e -->

* Ù‚Ø§Ù… Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„ÙØ±Ù†Ø³ÙŠ Ø¨Ø§Ø³ÙƒØ§Ù„ Ø¨ØµÙŠØ§ØºØ© Ù‡Ø°Ù‡ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙƒÙ…Ø§ ÙŠÙ„ÙŠ : <!-- text, from page 0 (l=0.462,t=0.087,r=0.931,b=0.113), with ID 221532e8-d6f1-4918-b3f3-cf9026d8fffb -->

Ù‚Ø§Ø¹Ø¯Ø© (Ù…Ø¨Ø¯Ø£) Ø¨Ø§Ø³ÙƒØ§Ù„
Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ¤Ø«Ø± Ø¶ØºØ· Ø¹Ù„Ù‰ Ø³Ø§Ø¦Ù„ Ù…Ø­Ø¨ÙˆØ³ ÙÙŠ Ø¥Ù†Ø§Ø¡ØŒ ÙØ¥Ù† Ø°Ù„Ùƒ Ø§Ù„Ø¶ØºØ· ÙŠÙ†ØªÙ‚Ù„ Ø¨ØªÙ…Ø§Ù…Ù‡ Ø¥Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¦Ù„ØŒ ÙƒÙ…Ø§ ÙŠÙ†ØªÙ‚Ù„ Ø¥Ù„Ù‰ Ø¬Ø¯Ø±Ø§Ù† Ø§Ù„Ø¥Ù†Ø§Ø¡. <!-- text, from page 0 (l=0.071,t=0.118,r=0.928,b=0.194), with ID bfaa5219-276c-4a50-ae54-520cabdc6758 -->

Ù…Ù„Ø§Ø­Ø¸Ø©

ØªØ®Ø¶Ø¹ Ø§Ù„Ø³ÙˆØ§Ø¦Ù„ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø¨Ø§Ø³ÙƒØ§Ù„ Ø¨ÙŠÙ†Ù…Ø§ Ù„Ø§ ØªØ®Ø¶Ø¹ Ø§Ù„ØºØ§Ø²Ø§Øª Ù„Ù‡Ø§ØŒ
Ù„Ø£Ù† Ø§Ù„Ø³ÙˆØ§Ø¦Ù„ ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ù†Ø¶ØºØ§Ø· ÙÙŠÙ†ØªÙ‚Ù„ Ø§Ù„Ø¶ØºØ· Ø§Ù„Ù…Ø¤Ø«Ø± Ø¹Ù„ÙŠÙ‡Ø§ Ø¨ÙƒØ§Ù…Ù„Ù‡ Ø¥Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¦Ù„ØŒ Ø£Ù…Ø§ Ø§Ù„ØºØ§Ø²Ø§Øª ÙÙ‡ÙŠ Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ù†Ø¶ØºØ§Ø· Ù„ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø§ÙØ§Øª Ø¨ÙŠÙ†ÙŠØ© ÙƒØ¨ÙŠØ±Ø© Ù†Ø³Ø¨ÙŠØ§Ù‹ Ø¨ÙŠÙ† Ø¬Ø²ÙŠØ¦Ø§Øª Ø§Ù„ØºØ§Ø² ÙÙŠØ³ØªÙ‡Ù„Ùƒ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ø´ØºÙ„ Ø§Ù„Ù…Ø¨Ø°ÙˆÙ„ Ù„Ø¶ØºØ· Ø¬Ø²ÙŠØ¦Ø§Øª Ø§Ù„ØºØ§Ø² ÙˆØ¨Ø§Ù„ØªØ§Ù„ÙŠ ÙŠÙ†ØªÙ‚Ù„ Ø§Ù„Ø¶ØºØ· Ø¬Ø²Ø¦ÙŠØ§Ù‹ Ø®Ù„Ø§Ù„ Ø§Ù„ØºØ§Ø²Ø§Øª. <!-- text, from page 0 (l=0.071,t=0.208,r=0.940,b=0.345), with ID 35c1e55d-d146-4eaa-afdc-ad13453669f6 -->

ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø¹Ù„Ù‰ Ù‚Ø§Ø¹Ø¯Ø© Ø¨Ø§Ø³ÙƒØ§Ù„ <!-- text, from page 0 (l=0.616,t=0.360,r=0.930,b=0.400), with ID 9c1126ff-68bf-4d00-a4ad-774eaceb4fbe -->

Summary : This image presents two examples of hydraulic systems in use, specifically highlighting a hydraulic jack and hydraulic car brakes, with accompanying photographs and Arabic labels.

photo:
Scene Overview :
  â€¢ The image is divided into two circular sections, each showing a different hydraulic application.
  â€¢ Left circle: Close-up photo of a car's hydraulic brake system, showing the brake disc and caliper.
  â€¢ Right circle: Photo of a hydraulic jack lifting a heavy vehicle (likely a truck or construction vehicle) at a worksite.
  â€¢ Each section is numbered (1 and 2) and has a colored arc above it (red for 1, green for 2).

Technical Details :
  â€¢ Arabic text under the right image: "Ø§Ù„Ù…ÙƒØ¨Ø³ Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆÙ„ÙŠÙƒÙŠ" (The hydraulic jack).
  â€¢ Arabic text under the left image: "Ø§Ù„ÙØ±Ø§Ù…Ù„ Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆÙ„ÙŠÙƒÙŠØ© Ù„Ù„Ø³ÙŠØ§Ø±Ø©" (The hydraulic brakes for the car).
  â€¢ No scale bars or magnification indicators are present.
  â€¢ The images are clear, with the main hydraulic components in focus.

Spatial Relationships :
  â€¢ The two images are presented side by side, separated by a dotted vertical line.
  â€¢ The hydraulic jack (right) is shown in an outdoor, industrial context; the car brake (left) is shown in a mechanical/garage context.
  â€¢ Both images use a circular crop, emphasizing the main subject.

Analysis :
  â€¢ The figure visually contrasts two common uses of hydraulic systems: lifting heavy vehicles and stopping cars.
  â€¢ The layout and numbering suggest a comparison or categorization of hydraulic applications.
  â€¢ The use of clear, labeled photographs aids in understanding the practical implementation of hydraulic technology. <!-- figure, from page 0 (l=0.579,t=0.406,r=0.921,b=0.585), with ID 571f38a7-8703-4517-bfae-c7a9d79f8bb2 -->

ÙˆÙÙŠÙ…Ø§ ÙŠÙ„ÙŠ Ø³ØªØªØ¹Ø±Ø¶ Ø¨Ø´ÙŠØ¡ Ù…Ù† Ø§Ù„ØªÙØµÙŠÙ„ Ù„Ù„Ù…ÙƒØ¨Ø³ Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆÙ„ÙŠÙƒÙŠ. <!-- text, from page 0 (l=0.438,t=0.595,r=0.931,b=0.625), with ID 85a5d707-ad5d-4bab-bbf8-f3d3699d4429 -->

Hydraulic press Ø§Ù„Ù…ÙƒØ¨Ø³ Ø§Ù„Ù‡ÙŠØ¯Ø±ÙˆÙ„ÙŠÙƒÙŠ <!-- text, from page 0 (l=0.513,t=0.635,r=0.931,b=0.670), with ID e1c1a790-4c1f-49e9-94ea-0303e9f93160 -->

Ø£Ù†Ø¨ÙˆØ¨Ø© Ù…ÙˆØµÙ„Ø© Ø¨Ù…ÙƒØ¨Ø³ÙÙŠÙ† Ø£Ø­Ø¯Ù‡Ù…Ø§ ØµØºÙŠØ± Ù…Ø³Ø§Ø­Ø© Ù…Ù‚Ø·Ø¹Ù‡ a  
ÙˆØ§Ù„Ø¢Ø®Ø± ÙƒØ¨ÙŠØ± Ù…Ø³Ø§Ø­Ø© Ù…Ù‚Ø·Ø¹Ù‡ A ÙˆÙŠÙ…ØªÙ„Ø¦ Ø§Ù„Ø­ÙŠØ² Ø¨ÙŠÙ† Ø§Ù„Ù…ÙƒØ¨Ø³ÙŠÙ†  
Ø¨Ø³Ø§Ø¦Ù„ Ù…Ù†Ø§Ø³Ø¨ (Ø³Ø§Ø¦Ù„ Ù‡ÙŠØ¯Ø±ÙˆÙ„ÙŠÙƒÙŠ) ÙƒÙ…Ø§ Ø¨Ø§Ù„Ø´ÙƒÙ„. <!-- text, from page 0 (l=0.405,t=0.676,r=0.949,b=0.781), with ID 6a5beaf4-68a8-4e89-ae48-20c2fc6c65eb -->

$10.4$ <!-- marginalia, from page 0 (l=0.869,t=0.921,r=0.923,b=0.950), with ID 4ea3448d-3d90-42b0-8735-1d4e9a3370f8 -->
"""

    print("ğŸ” Ù…Ù‚Ø§Ø±Ù†Ø© Ø·Ø±Ù‚ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:")
    print("=" * 60)
    
    # 1. Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    start_time = time.time()
    cleaned_original = clean_landing_ai_text(test_text)
    time_original = time.time() - start_time
    
    # 2. Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
    start_time = time.time()
    cleaned_enhanced, improvement = clean_landing_ai_text_enhanced(test_text)
    time_enhanced = time.time() - start_time
    
    print(f"ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©:")
    print(f"   ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {len(test_text):,} Ø­Ø±Ù")
    print()
    print(f"ğŸ”§ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©:")
    print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø©: {len(cleaned_original):,} Ø­Ø±Ù")
    print(f"   ğŸ“Š Ø§Ù„ØªØ­Ø³Ù†: {((len(test_text) - len(cleaned_original)) / len(test_text) * 100):.1f}%")
    print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª: {time_original:.6f}s")
    print()
    print(f"âš¡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©:")
    print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø©: {len(cleaned_enhanced):,} Ø­Ø±Ù")
    print(f"   ğŸ“Š Ø§Ù„ØªØ­Ø³Ù†: {improvement:.1f}%")
    print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª: {time_enhanced:.6f}s")
    print()
    
    # Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø¯Ø§Ø± Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ
    additional_improvement = len(cleaned_original) - len(cleaned_enhanced)
    additional_percentage = (additional_improvement / len(cleaned_original) * 100) if len(cleaned_original) > 0 else 0
    
    print(f"ğŸ¯ Ø§Ù„ØªØ­Ø³Ù† Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©:")
    print(f"   ğŸ“‰ Ø­Ø±ÙˆÙ Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø­Ø°ÙˆÙØ©: {additional_improvement:,}")
    print(f"   ğŸ“Š ØªØ­Ø³Ù† Ø¥Ø¶Ø§ÙÙŠ: {additional_percentage:.1f}%")
    print(f"   âš¡ ØªØ³Ø±ÙŠØ¹: {(time_original / time_enhanced):.1f}x" if time_enhanced > 0 else "âˆ")
    
    print(f"\nğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†:")
    print("-" * 50)
    print(cleaned_enhanced)
    print("-" * 50)

    # Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø± Ù…Ù„ÙØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù‡Ù†Ø§ Ù…Ø¨Ø§Ø´Ø±Ø© (ØºÙŠØ± async)
    print(f"\nğŸ“‚ Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©:")
    print("-" * 50)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Landing AI
    base_dir = Path("d:/ezz/compair/edu-compare-wizard/backend/uploads/landingai_results")
    
    if not base_dir.exists():
        print(f"âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {base_dir}")
        return
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª extracted_content.md
    md_files = list(base_dir.rglob("extracted_content.md"))
    json_files = list(base_dir.rglob("agentic_doc_result.json"))
    
    print(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰:")
    print(f"   ğŸ“„ {len(md_files)} Ù…Ù„Ù .md")
    print(f"   ğŸ“„ {len(json_files)} Ù…Ù„Ù .json")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
    test_files = (md_files + json_files)[:5]  # Ø£ÙˆÙ„ 5 Ù…Ù„ÙØ§Øª
    
    if not test_files:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        return
    
    print(f"\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± {len(test_files)} Ù…Ù„Ù:")
    
    total_original = 0
    total_cleaned_old = 0
    total_cleaned_new = 0
    total_time_old = 0
    total_time_new = 0
    
    for i, file_path in enumerate(test_files, 1):
        try:
            print(f"\n{i}. ğŸ“„ {file_path.name}")
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if file_path.suffix == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    text = data.get('markdown', '') or data.get('text', '')
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            if not text:
                print("   âš ï¸ Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº")
                continue
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            start_time = time.time()
            cleaned_old = clean_landing_ai_text(text)
            time_old = time.time() - start_time
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
            start_time = time.time()
            cleaned_new, improvement = clean_landing_ai_text_enhanced(text)
            time_new = time.time() - start_time
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            print(f"   ğŸ“ Ø§Ù„Ø£ØµÙ„ÙŠ: {len(text):,} â†’ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {len(cleaned_old):,} â†’ Ø§Ù„Ù…Ø­Ø³Ù†: {len(cleaned_new):,}")
            print(f"   ğŸ“Š ØªØ­Ø³Ù† Ù‚Ø¯ÙŠÙ…: {((len(text) - len(cleaned_old)) / len(text) * 100):.1f}% â†’ Ø¬Ø¯ÙŠØ¯: {improvement:.1f}%")
            print(f"   â±ï¸ ÙˆÙ‚Øª Ù‚Ø¯ÙŠÙ…: {time_old:.4f}s â†’ Ø¬Ø¯ÙŠØ¯: {time_new:.4f}s")
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            total_original += len(text)
            total_cleaned_old += len(cleaned_old)
            total_cleaned_new += len(cleaned_new)
            total_time_old += time_old
            total_time_new += time_new
            
        except Exception as e:
            print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {file_path.name}: {e}")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
    if total_original > 0:
        print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©:")
        print(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {total_original:,} Ø­Ø±Ù")
        print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {total_cleaned_old:,} Ø­Ø±Ù ({((total_original - total_cleaned_old) / total_original * 100):.1f}% ØªØ­Ø³Ù†)")
        print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: {total_cleaned_new:,} Ø­Ø±Ù ({((total_original - total_cleaned_new) / total_original * 100):.1f}% ØªØ­Ø³Ù†)")
        print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {total_time_old:.4f}s")
        print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†: {total_time_new:.4f}s")
        print(f"   ğŸš€ ØªØ³Ø±ÙŠØ¹: {(total_time_old / total_time_new):.1f}x" if total_time_new > 0 else "âˆ")
        
        # ØªØ­Ø³Ù† Ø¥Ø¶Ø§ÙÙŠ
        additional_improvement = total_cleaned_old - total_cleaned_new
        additional_percentage = (additional_improvement / total_cleaned_old * 100) if total_cleaned_old > 0 else 0
        print(f"   ğŸ¯ ØªØ­Ø³Ù† Ø¥Ø¶Ø§ÙÙŠ: {additional_improvement:,} Ø­Ø±Ù ({additional_percentage:.1f}%)")

async def test_real_files():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©"""
    print(f"\nğŸ“‚ Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ø­Ù‚ÙŠÙ‚ÙŠØ©:")
    print("-" * 50)
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª Landing AI
    base_dir = Path("d:/ezz/compair/edu-compare-wizard/backend/uploads/landingai_results")
    
    if not base_dir.exists():
        print(f"âŒ Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {base_dir}")
        return
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù„ÙØ§Øª extracted_content.md
    md_files = list(base_dir.rglob("extracted_content.md"))
    json_files = list(base_dir.rglob("agentic_doc_result.json"))
    
    print(f"ğŸ“Š ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰:")
    print(f"   ğŸ“„ {len(md_files)} Ù…Ù„Ù .md")
    print(f"   ğŸ“„ {len(json_files)} Ù…Ù„Ù .json")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
    test_files = (md_files + json_files)[:5]  # Ø£ÙˆÙ„ 5 Ù…Ù„ÙØ§Øª
    
    if not test_files:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„ÙØ§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        return
    
    print(f"\nğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± {len(test_files)} Ù…Ù„Ù:")
    
    total_original = 0
    total_cleaned_old = 0
    total_cleaned_new = 0
    total_time_old = 0
    total_time_new = 0
    
    for i, file_path in enumerate(test_files, 1):
        try:
            print(f"\n{i}. ğŸ“„ {file_path.name}")
            
            # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
            if file_path.suffix == '.json':
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    text = data.get('markdown', '') or data.get('text', '')
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
            
            if not text:
                print("   âš ï¸ Ø§Ù„Ù…Ù„Ù ÙØ§Ø±Øº")
                continue
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
            start_time = time.time()
            cleaned_old = clean_landing_ai_text(text)
            time_old = time.time() - start_time
            
            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©
            start_time = time.time()
            cleaned_new, improvement = clean_landing_ai_text_enhanced(text)
            time_new = time.time() - start_time
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            print(f"   ğŸ“ Ø§Ù„Ø£ØµÙ„ÙŠ: {len(text):,} â†’ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {len(cleaned_old):,} â†’ Ø§Ù„Ù…Ø­Ø³Ù†: {len(cleaned_new):,}")
            print(f"   ğŸ“Š ØªØ­Ø³Ù† Ù‚Ø¯ÙŠÙ…: {((len(text) - len(cleaned_old)) / len(text) * 100):.1f}% â†’ Ø¬Ø¯ÙŠØ¯: {improvement:.1f}%")
            print(f"   â±ï¸ ÙˆÙ‚Øª Ù‚Ø¯ÙŠÙ…: {time_old:.4f}s â†’ Ø¬Ø¯ÙŠØ¯: {time_new:.4f}s")
            
            # Ø¬Ù…Ø¹ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            total_original += len(text)
            total_cleaned_old += len(cleaned_old)
            total_cleaned_new += len(cleaned_new)
            total_time_old += time_old
            total_time_new += time_new
            
        except Exception as e:
            print(f"   âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {file_path.name}: {e}")
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
    if total_original > 0:
        print(f"\nğŸ“Š Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©:")
        print(f"   ğŸ“ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ: {total_original:,} Ø­Ø±Ù")
        print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {total_cleaned_old:,} Ø­Ø±Ù ({((total_original - total_cleaned_old) / total_original * 100):.1f}% ØªØ­Ø³Ù†)")
        print(f"   ğŸ“ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø©: {total_cleaned_new:,} Ø­Ø±Ù ({((total_original - total_cleaned_new) / total_original * 100):.1f}% ØªØ­Ø³Ù†)")
        print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¯ÙŠÙ…: {total_time_old:.4f}s")
        print(f"   â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ø­Ø³Ù†: {total_time_new:.4f}s")
        print(f"   ğŸš€ ØªØ³Ø±ÙŠØ¹: {(total_time_old / total_time_new):.1f}x" if total_time_new > 0 else "âˆ")
        
        # ØªØ­Ø³Ù† Ø¥Ø¶Ø§ÙÙŠ
        additional_improvement = total_cleaned_old - total_cleaned_new
        additional_percentage = (additional_improvement / total_cleaned_old * 100) if total_cleaned_old > 0 else 0
        print(f"   ğŸ¯ ØªØ­Ø³Ù† Ø¥Ø¶Ø§ÙÙŠ: {additional_improvement:,} Ø­Ø±Ù ({additional_percentage:.1f}%)")

async def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸš€ Ù†Ø¸Ø§Ù… Ø§Ø®ØªØ¨Ø§Ø± ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø­Ø³Ù†")
    print("=" * 60)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    test_cleaning()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù†
    await test_enhanced_processing()
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
    await test_fast_folder_processing()
    
    print(f"\nğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±!")
    print(f"ğŸ’¡ ØªÙˆØµÙŠØ§Øª:")
    print(f"   1. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù† Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø¬ÙˆØ¯Ø© ØªÙ†Ø¸ÙŠÙ")
    print(f"   2. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø±ÙŠØ¹ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù„Ø¯Ø§Øª ÙƒØ¨ÙŠØ±Ø©")
    print(f"   3. Ø§Ø¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…ÙŠÙ† Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")

if __name__ == "__main__":
    asyncio.run(main())
