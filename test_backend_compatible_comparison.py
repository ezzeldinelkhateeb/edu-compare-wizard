#!/usr/bin/env python3
"""
ุงุฎุชุจุงุฑ ุงูููุงุฑูุฉ ุงูุจุตุฑูุฉ ุงููุญุณู ูุน ููุงุฑูุฉ ุงููุชุงุฆุฌ ูุน ุงูุจุงู ุฅูุฏ
Enhanced Visual Comparison Test with Backend Results Validation
"""

import cv2
import numpy as np
import imagehash
from PIL import Image, ImageEnhance, ImageOps
from skimage.metrics import structural_similarity as ssim
import json
import time
import requests
import os
from pathlib import Path
from typing import Dict, Any, Optional, Tuple, List
import base64
from datetime import datetime

class EnhancedVisualComparisonTester:
    """ูุฆุฉ ุงุฎุชุจุงุฑ ุงูููุงุฑูุฉ ุงูุจุตุฑูุฉ ุงููุญุณูุฉ ูุน ููุงุฑูุฉ ุงููุชุงุฆุฌ ูุน ุงูุจุงู ุฅูุฏ"""
    
    def __init__(self, backend_url: str = "http://localhost:8000"):
        # ุฃูุฒุงู ุงูููุงุฑูุฉ ุงููุญุณูุฉ (ูุทุงุจูุฉ ููุจุงู ุฅูุฏ)
        self.weights = {
            'ssim': 0.25,
            'phash': 0.15,
            'clip': 0.25,  # ุณูุชู ุชุนุทููู ูู ุงูุงุฎุชุจุงุฑ ุงููุญูู
            'histogram': 0.10,
            'features': 0.15,
            'edges': 0.10
        }
        
        # ุฅุนุงุฏุฉ ุชูุฒูุน ุงูุฃูุฒุงู ุจุฏูู CLIP
        remaining_weight = 1.0 - self.weights['clip']
        factor = 1.0 / remaining_weight
        for key in ['ssim', 'phash', 'histogram', 'features', 'edges']:
            self.weights[key] *= factor
        self.weights['clip'] = 0.0
        
        self.backend_url = backend_url
        self.similarity_threshold = 0.75
        self.high_similarity_threshold = 0.90
        
        # ุฅุนุฏุงุฏ SIFT ููููุฒุงุช
        try:
            self.sift = cv2.SIFT_create(nfeatures=1000)
            self.feature_matching_available = True
        except Exception:
            self.feature_matching_available = False
            
        print(f"๐ง ุฃูุฒุงู ุงูููุงุฑูุฉ ุงููุญุณูุฉ:")
        for key, value in self.weights.items():
            print(f"   {key.upper()}: {value:.2f}")
    
    def load_and_preprocess_image(self, image_path: str) -> Dict[str, Any]:
        """ุชุญููู ููุนุงูุฌุฉ ุงูุตูุฑุฉ (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        try:
            # ุชุญููู ูุน OpenCV
            img_cv = cv2.imread(str(image_path))
            if img_cv is None:
                raise ValueError(f"ูุดู ูู ูุฑุงุกุฉ ุงูุตูุฑุฉ: {image_path}")
            
            # ุชุญููู ุฅูู RGB
            img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
            
            # ุชุญููู ูุน PIL
            img_pil = Image.open(image_path)
            
            # ุฅูุดุงุก ูุณุฎุฉ ุฑูุงุฏูุฉ ูุน ุชุญุณูู (ูุทุงุจู ููุจุงู ุฅูุฏ)
            img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            img_gray = cv2.GaussianBlur(img_gray, (3, 3), 0)  # ุชุญุณูู ุงูุฌูุฏุฉ
            
            return {
                'cv': img_cv,
                'rgb': img_rgb,
                'pil': img_pil,
                'gray': img_gray,
                'shape': img_cv.shape,
                'size': img_pil.size
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุชุญููู {image_path}: {e}")
            return None
    
    def resize_images_to_match(self, img1: Dict, img2: Dict) -> Tuple[Dict, Dict]:
        """ุชุบููุฑ ุญุฌู ุงูุตูุฑ ูุชุชุทุงุจู (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        h1, w1 = img1['gray'].shape
        h2, w2 = img2['gray'].shape
        
        # ุงุณุชุฎุฏุงู ุฃุตุบุฑ ุญุฌู ูุดุชุฑู (ูุทุงุจู ููุจุงู ุฅูุฏ)
        target_h = min(h1, h2)
        target_w = min(w1, w2)
        
        def resize_image_dict(img_dict, target_size):
            result = {}
            for key, img in img_dict.items():
                if key in ['shape', 'size']:
                    continue
                elif key == 'pil':
                    result[key] = img.resize((target_w, target_h), Image.Resampling.LANCZOS)
                elif len(img.shape) == 2:  # grayscale
                    result[key] = cv2.resize(img, (target_w, target_h))
                else:  # color
                    result[key] = cv2.resize(img, (target_w, target_h))
            
            result['shape'] = (target_h, target_w, 3)
            result['size'] = (target_w, target_h)
            return result
        
        img1_resized = resize_image_dict(img1, (target_w, target_h))
        img2_resized = resize_image_dict(img2, (target_w, target_h))
        
        return img1_resized, img2_resized
    
    def calculate_ssim(self, img1_gray: np.ndarray, img2_gray: np.ndarray) -> Dict[str, Any]:
        """ุญุณุงุจ SSIM (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        try:
            # ุญุณุงุจ SSIM ูุน full=True ููุญุตูู ุนูู ุงูุฎุฑูุทุฉ
            score, ssim_map = ssim(img1_gray, img2_gray, full=True)
            score = max(0.0, min(1.0, score))  # ุชุฃูุฏ ูู ุฃู ุงููุชูุฌุฉ ุจูู 0 ู 1
            
            return {
                'score': float(score),
                'map_available': True,
                'mean_map': float(np.mean(ssim_map)),
                'std_map': float(np.std(ssim_map)),
                'min_map': float(np.min(ssim_map)),
                'max_map': float(np.max(ssim_map))
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุญุณุงุจ SSIM: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_phash_similarity(self, img1_pil: Image.Image, img2_pil: Image.Image) -> Dict[str, Any]:
        """ุญุณุงุจ ุชุดุงุจู pHash (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        try:
            # ุญุณุงุจ pHash
            hash1 = imagehash.phash(img1_pil)
            hash2 = imagehash.phash(img2_pil)
            
            # ุญุณุงุจ ุงููุณุงูุฉ ูุงูุชุญููู ุฅูู ุชุดุงุจู
            distance = hash1 - hash2
            max_distance = 64  # ุงูุญุฏ ุงูุฃูุตู ููุณุงูุฉ pHash
            similarity = 1.0 - (distance / max_distance)
            similarity = max(0.0, min(1.0, similarity))
            
            return {
                'score': float(similarity),
                'hash1': str(hash1),
                'hash2': str(hash2),
                'distance': int(distance),
                'max_distance': max_distance
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุญุณุงุจ pHash: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_histogram_correlation(self, img1: np.ndarray, img2: np.ndarray) -> Dict[str, Any]:
        """ุญุณุงุจ ุงุฑุชุจุงุท ุงููุณุชูุฌุฑุงู (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        try:
            # ุชุญููู ุฅูู grayscale ุฅุฐุง ูุฒู ุงูุฃูุฑ
            gray1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY) if len(img1.shape) == 3 else img1
            gray2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY) if len(img2.shape) == 3 else img2
            
            # ุชุญููู ุงูุตูุฑ ุฅูู ูุณุชูุฌุฑุงู
            hist1 = cv2.calcHist([gray1], [0], None, [256], [0, 256])
            hist2 = cv2.calcHist([gray2], [0], None, [256], [0, 256])
            
            # ุญุณุงุจ ุงุฑุชุจุงุท ุงููุณุชูุฌุฑุงู
            correlation = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            correlation = max(0.0, min(1.0, correlation))
            
            return {
                'score': float(correlation),
                'method': 'HISTCMP_CORREL',
                'hist1_mean': float(np.mean(hist1)),
                'hist2_mean': float(np.mean(hist2))
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุญุณุงุจ ุงุฑุชุจุงุท ุงููุณุชูุฌุฑุงู: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_feature_matching(self, img1_gray: np.ndarray, img2_gray: np.ndarray) -> Dict[str, Any]:
        """ุญุณุงุจ ุชุทุงุจู ุงูููุฒุงุช (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        if not self.feature_matching_available:
            return {'score': 0.0, 'error': 'SIFT not available'}
        
        try:
            # ุฅูุดุงุก ูุงุดู SIFT
            kp1, des1 = self.sift.detectAndCompute(img1_gray, None)
            kp2, des2 = self.sift.detectAndCompute(img2_gray, None)
            
            if des1 is None or des2 is None:
                return {
                    'score': 0.0,
                    'keypoints1': len(kp1) if kp1 else 0,
                    'keypoints2': len(kp2) if kp2 else 0,
                    'error': 'No descriptors found'
                }
            
            # ุญุณุงุจ ุชุทุงุจู ุงูููุฒุงุช
            bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)
            matches = bf.match(des1, des2)
            
            # ุญุณุงุจ ูุชูุณุท ุงููุณุงูุฉ ุจูู ุงูููุฒุงุช ุงููุชุทุงุจูุฉ (ูุทุงุจู ููุจุงู ุฅูุฏ)
            if len(matches) > 0:
                distances = [m.distance for m in matches]
                feature_matching_score = 1.0 - (np.mean(distances) / 256.0)
                feature_matching_score = max(0.0, min(1.0, feature_matching_score))
            else:
                feature_matching_score = 0.0
            
            return {
                'score': float(feature_matching_score),
                'total_matches': len(matches),
                'keypoints1': len(kp1),
                'keypoints2': len(kp2),
                'avg_distance': float(np.mean(distances) if matches else 0),
                'min_distance': float(np.min(distances) if matches else 0),
                'max_distance': float(np.max(distances) if matches else 0)
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุญุณุงุจ ุชุทุงุจู ุงูููุฒุงุช: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def calculate_edge_similarity(self, img1_gray: np.ndarray, img2_gray: np.ndarray) -> Dict[str, Any]:
        """ุญุณุงุจ ุชุดุงุจู ุงูุญูุงู (ูุทุงุจู ููุจุงู ุฅูุฏ)"""
        try:
            # ุงุณุชุฎุฑุงุฌ ุงูุญูุงู ุจุงุณุชุฎุฏุงู Canny
            edges1 = cv2.Canny(img1_gray, 100, 200)
            edges2 = cv2.Canny(img2_gray, 100, 200)
            
            # ุญุณุงุจ ุชุดุงุจู ุงูุญูุงู ุจุงุณุชุฎุฏุงู matchShapes (ูุทุงุจู ููุจุงู ุฅูุฏ)
            similarity = cv2.matchShapes(edges1, edges2, cv2.CONTOURS_MATCH_I2, 0)
            similarity = max(0.0, min(1.0, similarity))
            
            return {
                'score': float(similarity),
                'edges1_pixels': int(np.sum(edges1 > 0)),
                'edges2_pixels': int(np.sum(edges2 > 0)),
                'method': 'CONTOURS_MATCH_I2'
            }
        except Exception as e:
            print(f"โ ุฎุทุฃ ูู ุญุณุงุจ ุชุดุงุจู ุงูุญูุงู: {e}")
            return {'score': 0.0, 'error': str(e)}
    
    def run_comprehensive_comparison(self, image1_path: str, image2_path: str) -> Dict[str, Any]:
        """ุชุดุบูู ููุงุฑูุฉ ุดุงููุฉ ุจูู ุตูุฑุชูู (ูุญุณู)"""
        start_time = time.time()
        
        print("๐ ุจุฏุก ุงูููุงุฑูุฉ ุงูุจุตุฑูุฉ ุงูุดุงููุฉ ุงููุญุณูุฉ...")
        print(f"๐ท ุงูุตูุฑุฉ ุงูุฃููู: {image1_path}")
        print(f"๐ท ุงูุตูุฑุฉ ุงูุซุงููุฉ: {image2_path}")
        print("-" * 70)
        
        # ุชุญููู ุงูุตูุฑ
        img1 = self.load_and_preprocess_image(image1_path)
        img2 = self.load_and_preprocess_image(image2_path)
        
        if not img1 or not img2:
            return None
        
        print(f"๐ ุญุฌู ุงูุตูุฑุฉ ุงูุฃููู: {img1['shape']}")
        print(f"๐ ุญุฌู ุงูุตูุฑุฉ ุงูุซุงููุฉ: {img2['shape']}")
        
        # ุชุบููุฑ ุงูุญุฌู ููุชุทุงุจู
        img1_resized, img2_resized = self.resize_images_to_match(img1, img2)
        print(f"๐ ุงูุญุฌู ุงููุณุชุฎุฏู ููููุงุฑูุฉ: {img1_resized['shape']}")
        print("-" * 70)
        
        # ุฅุฌุฑุงุก ุฌููุน ุงูููุงุฑูุงุช
        results = {}
        
        print("๐ฌ ุญุณุงุจ SSIM...")
        results['ssim'] = self.calculate_ssim(img1_resized['gray'], img2_resized['gray'])
        print(f"   โ SSIM Score: {results['ssim']['score']:.4f}")
        
        print("๐ฌ ุญุณุงุจ Perceptual Hash...")
        results['phash'] = self.calculate_phash_similarity(img1_resized['pil'], img2_resized['pil'])
        print(f"   โ pHash Score: {results['phash']['score']:.4f}")
        
        print("๐ฌ ุญุณุงุจ ุงุฑุชุจุงุท ุงููุณุชูุฌุฑุงู...")
        results['histogram'] = self.calculate_histogram_correlation(img1_resized['gray'], img2_resized['gray'])
        print(f"   โ Histogram Correlation: {results['histogram']['score']:.4f}")
        
        print("๐ฌ ูุทุงุจูุฉ ุงูููุฒุงุช...")
        results['features'] = self.calculate_feature_matching(img1_resized['gray'], img2_resized['gray'])
        print(f"   โ Feature Matching Score: {results['features']['score']:.4f}")
        
        print("๐ฌ ุญุณุงุจ ุชุดุงุจู ุงูุญูุงู...")
        results['edges'] = self.calculate_edge_similarity(img1_resized['gray'], img2_resized['gray'])
        print(f"   โ Edge Similarity Score: {results['edges']['score']:.4f}")
        
        # ุญุณุงุจ ุงููุชูุฌุฉ ุงูุฅุฌูุงููุฉ (ูุทุงุจู ููุจุงู ุฅูุฏ)
        overall_score = (
            results['ssim']['score'] * self.weights['ssim'] +
            results['phash']['score'] * self.weights['phash'] +
            results['histogram']['score'] * self.weights['histogram'] +
            results['features']['score'] * self.weights['features'] +
            results['edges']['score'] * self.weights['edges']
        ) * 100
        
        processing_time = time.time() - start_time
        
        # ุชุฌููุน ุงููุชุงุฆุฌ ุงูููุงุฆูุฉ
        final_results = {
            'overall_score': overall_score,
            'processing_time': processing_time,
            'detailed_scores': results,
            'weights_used': self.weights,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        return final_results

def main():
    """ุงูุฏุงูุฉ ุงูุฑุฆูุณูุฉ ููุงุฎุชุจุงุฑ ุงููุญุณู"""
    # ูุณุงุฑุงุช ุงูุตูุฑ
    image1_path = Path("104.jpg")
    image2_path = Path("101.jpg")
    
    # ุงูุชุญูู ูู ูุฌูุฏ ุงูุตูุฑ
    if not image1_path.exists():
        print(f"โ ุงูุตูุฑุฉ ุบูุฑ ููุฌูุฏุฉ: {image1_path}")
        return
    
    if not image2_path.exists():
        print(f"โ ุงูุตูุฑุฉ ุบูุฑ ููุฌูุฏุฉ: {image2_path}")
        return
    
    # ุฅูุดุงุก ููุฎุชุจุฑ ุงูููุงุฑูุฉ ุงููุญุณู
    tester = EnhancedVisualComparisonTester()
    
    # ุชุดุบูู ุงูููุงุฑูุฉ ุงููุญููุฉ
    print("๐ฌ ุชุดุบูู ุงูููุงุฑูุฉ ุงููุญููุฉ...")
    local_results = tester.run_comprehensive_comparison(str(image1_path), str(image2_path))
    
    if local_results:
        print("\n" + "=" * 80)
        print("๐ ุงููุชุงุฆุฌ ุงููุญููุฉ ุงููุญุณูุฉ")
        print("=" * 80)
        print(f"๐ฏ ุงููุชูุฌุฉ ุงูุฅุฌูุงููุฉ: {local_results['overall_score']:.2f}%")
        print(f"โฑ๏ธ ููุช ุงููุนุงูุฌุฉ: {local_results['processing_time']:.2f} ุซุงููุฉ")
        
        # ุนุฑุถ ุชุญููู ุงูููุงููุณ ุงูุชูุตููู
        details = local_results['detailed_scores']
        print(f"\n๐ ุชุญููู ุงูููุงููุณ ุงูุชูุตููู:")
        print(f"   ๐ SSIM: {details['ssim']['score']:.4f}")
        print(f"   ๐ pHash: {details['phash']['score']:.4f}")
        print(f"   ๐ Histogram: {details['histogram']['score']:.4f}")
        print(f"   ๐ฏ Features: {details['features']['score']:.4f}")
        print(f"   ๐ Edges: {details['edges']['score']:.4f}")
        
        # ุญูุธ ุงููุชุงุฆุฌ ุงูุชูุตูููุฉ
        output_file = f"enhanced_backend_compatible_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(local_results, f, ensure_ascii=False, indent=2)
        
        print(f"\n๐พ ุชู ุญูุธ ุงููุชุงุฆุฌ ุงูุชูุตูููุฉ ูู: {output_file}")

if __name__ == "__main__":
    main()
